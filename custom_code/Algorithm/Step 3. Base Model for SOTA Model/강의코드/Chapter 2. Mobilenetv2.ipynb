{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"part3-ch2-mobilenetv2.ipynb","provenance":[],"mount_file_id":"1PiXCA-zXm_G2F5Ll2GseQbCFN3KwZcIA","authorship_tag":"ABX9TyPSuhAeSKbXmrz2IU7YQKGE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["cd /content/drive/MyDrive/lecture"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_y1aX1-IrGvi","executionInfo":{"status":"ok","timestamp":1659849771761,"user_tz":-540,"elapsed":550,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"f924bfa5-6a13-4903-8d93-5168672e52d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/lecture\n"]}]},{"cell_type":"code","source":["mkdir mobinetv2"],"metadata":{"id":"_aXUKW8QwWHl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rmdir mobinetv2"],"metadata":{"id":"3-bKKB6ewaeM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/d-li14/mobilenetv2.pytorch.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8s6lZNlDwgIV","executionInfo":{"status":"ok","timestamp":1659849842707,"user_tz":-540,"elapsed":12339,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"15b827ca-6427-45da-f2cd-ec78f726e00d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'mobilenetv2.pytorch'...\n","remote: Enumerating objects: 125, done.\u001b[K\n","remote: Counting objects: 100% (13/13), done.\u001b[K\n","remote: Compressing objects: 100% (11/11), done.\u001b[K\n","remote: Total 125 (delta 4), reused 8 (delta 2), pack-reused 112\u001b[K\n","Receiving objects: 100% (125/125), 121.14 MiB | 13.93 MiB/s, done.\n","Resolving deltas: 100% (49/49), done.\n","Checking out files: 100% (25/25), done.\n"]}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jCPELoU-wms0","executionInfo":{"status":"ok","timestamp":1659849852353,"user_tz":-540,"elapsed":3,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"9196f70e-9648-4ff8-9756-df455e2f9e45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdatasets\u001b[0m/  \u001b[01;34mmobilenetv2.pytorch\u001b[0m/\n"]}]},{"cell_type":"code","source":["cd mobilenetv2.pytorch/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tPxYnIPlwsB0","executionInfo":{"status":"ok","timestamp":1659849864964,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"693bd3c3-12f4-44ef-96f2-934fe77bae2b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/lecture/mobilenetv2.pytorch\n"]}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aHHhgalEwvJs","executionInfo":{"status":"ok","timestamp":1659849868972,"user_tz":-540,"elapsed":3,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"997a4c50-6319-4575-cee0-87e5ce19572e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["imagenet.py  LICENSE  \u001b[0m\u001b[01;34mmodels\u001b[0m/  \u001b[01;34mpretrained\u001b[0m/  README.md  \u001b[01;34mutils\u001b[0m/\n"]}]},{"cell_type":"code","source":["import torch\n","from models.imagenet import mobilenetv2"],"metadata":{"id":"fy_pWXFUwwJk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = mobilenetv2()\n","#print(model)\n","model.load_state_dict(torch.load('pretrained/mobilenetv2-c5e733a8.pth'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bUmtfs6CxTWN","executionInfo":{"status":"ok","timestamp":1659852163164,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"3c43c5f2-2521-477a-f51c-c92cf30d3504"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["import os\n","import time\n","import copy\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, models, transforms"],"metadata":{"id":"IcUIEK9rybmt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ddir = '/content/drive/MyDrive/AI-NN/datasets/hym_data'\n","\n","batch_size = 64\n","num_workers = 2\n","\n","data_transformers = {\n","    'train': transforms.Compose(\n","        [\n","         transforms.RandomResizedCrop(224), \n","         transforms.RandomHorizontalFlip(),\n","         transforms.ToTensor(),\n","         transforms.Normalize([0.490, 0.449, 0.411], [0.231, 0.221, 0.230])\n","        ]\n","    ),\n","    'val': transforms.Compose(\n","        [\n","         transforms.Resize(256),\n","         transforms.CenterCrop(224),\n","         transforms.ToTensor(),\n","         transforms.Normalize([0.490, 0.449, 0.411],[0.231, 0.221, 0.230])\n","        ]\n","    )\n","}\n","\n","img_data = {\n","    k: datasets.ImageFolder(os.path.join(ddir, k), data_transformers[k])\n","    for k in ['train', 'val']\n","}\n","dloaders = {\n","    k: torch.utils.data.DataLoader(\n","        img_data[k], batch_size=batch_size, shuffle=True, num_workers=num_workers\n","    )\n","    for k in ['train', 'val']\n","}\n","dset_sizes = {x: len(img_data[x]) for x in ['train', 'val']}\n","classes = img_data['train'].classes\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"KA9Efb3FxkEN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, loss_func, optimizer, epochs=10):\n","   start = time.time()\n","\n","   accuracy = 0.0\n","\n","   for e in range(epochs):\n","        print(f'Epoch number {e}/{epochs - 1}')\n","        print('=' * 20)\n","\n","        for dset in ['train', 'val']:\n","            if dset == 'train':\n","                model.train()  \n","            else:\n","                model.eval() \n","\n","            loss = 0.0\n","            successes = 0\n","\n","            for imgs, tgts in dloaders[dset]:\n","                imgs = imgs.to(device)\n","                tgts = tgts.to(device)\n","                optimizer.zero_grad()\n","                \n","                with torch.set_grad_enabled(dset == 'train'):\n","                    ops = model(imgs)\n","                    _, preds = torch.max(ops, 1)\n","                    loss_curr = loss_func(ops, tgts)\n","                    \n","                    if dset == 'train':\n","                        loss_curr.backward()\n","                        optimizer.step()\n","\n","                loss += loss_curr.item() * imgs.size(0)\n","                successes += torch.sum(preds == tgts.data)\n","          \n","            loss_epoch = loss / dset_sizes[dset]\n","            accuracy_epoch = successes.double() / dset_sizes[dset]\n","\n","            print(f'{dset} loss in this epoch: {loss_epoch}, accuracy in this epoch: {accuracy_epoch}')\n","            if dset == 'val' and accuracy_epoch > accuracy:\n","                accuracy = accuracy_epoch      \n","\n","   time_delta = time.time() - start\n","   print(f'Training finished in {time_delta // 60}mins {time_delta % 60}secs')\n","   print(f'Best validation set accuracy: {accuracy}')\n","\n","\n","   return model\n"],"metadata":{"id":"r_eVomTayW2i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test(model):\n","\n","  correct_pred = {classname: 0 for classname in classes}\n","  total_pred = {classname: 0 for classname in classes}\n","\n","\n","  with torch.no_grad():\n","      for images, labels in dloaders['val']:\n","\n","\n","          images = images.to(device)\n","          labels = labels.to(device)\n","        \n","          outputs = model(images)\n","          _, predictions = torch.max(outputs, 1)\n","\n","          for label, prediction in zip(labels, predictions):\n","              if label == prediction:\n","                  correct_pred[classes[label]] += 1\n","              total_pred[classes[label]] += 1\n","\n","\n","\n","  for classname, correct_count in correct_pred.items():\n","      accuracy = 100 * float(correct_count) / total_pred[classname]\n","      print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"],"metadata":{"id":"5qn8CJYKyoAh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1acI2Ogmytec","executionInfo":{"status":"ok","timestamp":1659852178010,"user_tz":-540,"elapsed":12543,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"b6bde98a-9a92-49cc-cc82-3ca7223a0709"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy for class: ants  is 0.0 %\n","Accuracy for class: bees  is 0.0 %\n"]}]},{"cell_type":"code","source":["for name, param in model.named_parameters():\n","    print('layer name:', name)"],"metadata":{"id":"BGYj2XUG4NNc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_ftrs = model.classifier.in_features\n","model.classifier = nn.Linear(num_ftrs, 2)"],"metadata":{"id":"gAYWUUfO5s9R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qhFs1UGD50f7","executionInfo":{"status":"ok","timestamp":1659852274169,"user_tz":-540,"elapsed":12351,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"7845d3f9-5da7-40e3-d3c0-ab023f984001"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy for class: ants  is 12.9 %\n","Accuracy for class: bees  is 81.9 %\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Creates a MobileNetV2 Model as defined in:\n","Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen. (2018). \n","MobileNetV2: Inverted Residuals and Linear Bottlenecks\n","arXiv preprint arXiv:1801.04381.\n","import from https://github.com/tonylins/pytorch-mobilenet-v2\n","\"\"\"\n","\n","import torch.nn as nn\n","import math\n","\n","__all__ = ['mobilenetv2']\n","\n","\n","def _make_divisible(v, divisor, min_value=None):\n","    \"\"\"\n","    This function is taken from the original tf repo.\n","    It ensures that all layers have a channel number that is divisible by 8\n","    It can be seen here:\n","    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n","    :param v:\n","    :param divisor:\n","    :param min_value:\n","    :return:\n","    \"\"\"\n","    if min_value is None:\n","        min_value = divisor\n","    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n","    # Make sure that round down does not go down by more than 10%.\n","    if new_v < 0.9 * v:\n","        new_v += divisor\n","    return new_v\n","\n","\n","def conv_3x3_bn(inp, oup, stride):\n","    return nn.Sequential(\n","        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n","        nn.BatchNorm2d(oup),\n","        nn.ReLU6(inplace=True)\n","    )\n","\n","\n","def conv_1x1_bn(inp, oup):\n","    return nn.Sequential(\n","        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n","        nn.BatchNorm2d(oup),\n","        nn.ReLU6(inplace=True)\n","    )\n","\n","\n","class InvertedResidual(nn.Module):\n","    def __init__(self, inp, oup, stride, expand_ratio):\n","        super(InvertedResidual, self).__init__()\n","        assert stride in [1, 2]\n","\n","        hidden_dim = round(inp * expand_ratio)\n","        self.identity = stride == 1 and inp == oup\n","\n","        if expand_ratio == 1:\n","            self.conv = nn.Sequential(\n","                # dw\n","                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n","                nn.BatchNorm2d(hidden_dim),\n","                nn.ReLU6(inplace=True),\n","                # pw-linear\n","                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n","                nn.BatchNorm2d(oup),\n","            )\n","        else:\n","            self.conv = nn.Sequential(\n","                # pw\n","                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n","                nn.BatchNorm2d(hidden_dim),\n","                nn.ReLU6(inplace=True),\n","                # dw\n","                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n","                nn.BatchNorm2d(hidden_dim),\n","                nn.ReLU6(inplace=True),\n","                # pw-linear\n","                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n","                nn.BatchNorm2d(oup),\n","            )\n","\n","    def forward(self, x):\n","        if self.identity:\n","            return x + self.conv(x)\n","        else:\n","            return self.conv(x)\n","\n","\n","class MobileNetV2(nn.Module):\n","    def __init__(self, num_classes=1000, width_mult=1.):\n","        super(MobileNetV2, self).__init__()\n","        # setting of inverted residual blocks\n","        self.cfgs = [\n","            # t, c, n, s\n","            [1,  16, 1, 1],\n","            [6,  24, 2, 2],\n","            [6,  32, 3, 2],\n","            [6,  64, 4, 2],\n","            [6,  96, 3, 1],\n","            [6, 160, 3, 2],\n","            [6, 320, 1, 1],\n","        ]\n","\n","        # building first layer\n","        input_channel = _make_divisible(32 * width_mult, 4 if width_mult == 0.1 else 8)\n","        layers = [conv_3x3_bn(3, input_channel, 2)]\n","        # building inverted residual blocks\n","        block = InvertedResidual\n","        for t, c, n, s in self.cfgs:\n","            output_channel = _make_divisible(c * width_mult, 4 if width_mult == 0.1 else 8)\n","            for i in range(n):\n","                layers.append(block(input_channel, output_channel, s if i == 0 else 1, t))\n","                input_channel = output_channel\n","        self.features = nn.Sequential(*layers)\n","        # building last several layers\n","        output_channel = _make_divisible(1280 * width_mult, 4 if width_mult == 0.1 else 8) if width_mult > 1.0 else 1280\n","        self.conv = conv_1x1_bn(input_channel, output_channel)\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.classifier = nn.Linear(output_channel, num_classes)\n","\n","        self._initialize_weights()\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.conv(x)\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.classifier(x)\n","        return x\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","            elif isinstance(m, nn.Linear):\n","                m.weight.data.normal_(0, 0.01)\n","                m.bias.data.zero_()\n","\n","def mobilenetv2(**kwargs):\n","    \"\"\"\n","    Constructs a MobileNet V2 model\n","    \"\"\"\n","    return MobileNetV2(**kwargs)\n","\n"],"metadata":{"id":"C_T-oVUY54Pz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["net = MobileNetV2()"],"metadata":{"id":"fFOPI27Y6PkS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test(net)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wvPqCwfr6T5c","executionInfo":{"status":"ok","timestamp":1659852399157,"user_tz":-540,"elapsed":12926,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"f6e3e525-8820-416e-a199-2443fe6648fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy for class: ants  is 0.0 %\n","Accuracy for class: bees  is 0.0 %\n"]}]},{"cell_type":"code","source":["net.load_state_dict(torch.load('pretrained/mobilenetv2-c5e733a8.pth'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XO3f0Izq6Woj","executionInfo":{"status":"ok","timestamp":1659852410460,"user_tz":-540,"elapsed":394,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"b0199b54-f3ab-4906-cfe1-00373dda5ef7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":65}]},{"cell_type":"code","source":["test(net)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vdXo23a_6ckj","executionInfo":{"status":"ok","timestamp":1659852428715,"user_tz":-540,"elapsed":12476,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"ab076925-eb53-4255-8d9a-67e0ef37b789"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy for class: ants  is 0.0 %\n","Accuracy for class: bees  is 0.0 %\n"]}]},{"cell_type":"code","source":["loss_func = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=0.0001)\n","train(net, loss_func, optimizer, epochs=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pXyev_p56d_D","executionInfo":{"status":"ok","timestamp":1659852811784,"user_tz":-540,"elapsed":330278,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"33f4a755-64f2-4a3f-f8ee-2d3030600216"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch number 0/4\n","====================\n","train loss in this epoch: 9.735726622284435, accuracy in this epoch: 0.004098360655737705\n","val loss in this epoch: 13.238346324247473, accuracy in this epoch: 0.0\n","Epoch number 1/4\n","====================\n","train loss in this epoch: 8.41900121970255, accuracy in this epoch: 0.012295081967213115\n","val loss in this epoch: 12.6270499073602, accuracy in this epoch: 0.0\n","Epoch number 2/4\n","====================\n","train loss in this epoch: 7.210822105407715, accuracy in this epoch: 0.05327868852459016\n","val loss in this epoch: 12.087196082071541, accuracy in this epoch: 0.0\n","Epoch number 3/4\n","====================\n","train loss in this epoch: 5.9731017331608, accuracy in this epoch: 0.10655737704918032\n","val loss in this epoch: 11.351400356666714, accuracy in this epoch: 0.0\n","Epoch number 4/4\n","====================\n","train loss in this epoch: 4.635304247746702, accuracy in this epoch: 0.28688524590163933\n","val loss in this epoch: 10.394024761673672, accuracy in this epoch: 0.0196078431372549\n","Training finished in 5.0mins 30.115466594696045secs\n","Best validation set accuracy: 0.0196078431372549\n"]},{"output_type":"execute_result","data":{"text/plain":["MobileNetV2(\n","  (features): Sequential(\n","    (0): Sequential(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU6(inplace=True)\n","    )\n","    (1): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","        (3): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (2): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): ReLU6(inplace=True)\n","        (6): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (3): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): ReLU6(inplace=True)\n","        (6): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (4): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): ReLU6(inplace=True)\n","        (6): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): ReLU6(inplace=True)\n","        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): ReLU6(inplace=True)\n","        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (7): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): ReLU6(inplace=True)\n","        (6): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (8): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): ReLU6(inplace=True)\n","        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (9): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): ReLU6(inplace=True)\n","        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (10): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): ReLU6(inplace=True)\n","        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (11): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): ReLU6(inplace=True)\n","        (6): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (12): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): ReLU6(inplace=True)\n","        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (13): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): ReLU6(inplace=True)\n","        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (14): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): ReLU6(inplace=True)\n","        (6): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (15): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): ReLU6(inplace=True)\n","        (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (16): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): ReLU6(inplace=True)\n","        (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (17): InvertedResidual(\n","      (conv): Sequential(\n","        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU6(inplace=True)\n","        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (5): ReLU6(inplace=True)\n","        (6): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (conv): Sequential(\n","    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU6(inplace=True)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (classifier): Linear(in_features=1280, out_features=1000, bias=True)\n",")"]},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":[""],"metadata":{"id":"ReA9Hnyw6kij"},"execution_count":null,"outputs":[]}]}