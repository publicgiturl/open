{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"part3-1-2-transformer.ipynb","provenance":[],"machine_shape":"hm","mount_file_id":"1hS85gJkbAZxci6h4EUd-kENetzoeCUmp","authorship_tag":"ABX9TyOI6ckibCWebCAnHbh1g5XG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["! pip install einops sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fVxKoSlAHvCz","executionInfo":{"status":"ok","timestamp":1659878853819,"user_tz":-540,"elapsed":3000,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"c2e7135b-d45d-4c67-decd-9f4096e013a4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.4.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n"]}]},{"cell_type":"markdown","source":["Library"],"metadata":{"id":"ogA4h9KSIDdL"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","import numpy as np\n","from einops import rearrange, reduce, repeat\n","\n","from tqdm import tqdm\n","\n","import time\n","import copy\n","from collections import defaultdict\n","import joblib\n","import gc\n","import os\n"],"metadata":{"id":"DUy4oiFjH_a3","executionInfo":{"status":"ok","timestamp":1659878854327,"user_tz":-540,"elapsed":510,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"772Op6d3ICof","executionInfo":{"status":"ok","timestamp":1659878855598,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["N = 2\n","HIDDEN_DIM = 256\n","NUM_HEAD = 8 \n","INNER_DIM = 512\n","\n","PAD_IDX = 0\n","EOS_IDX = 3"],"metadata":{"id":"K6ELfae-IHMP","executionInfo":{"status":"ok","timestamp":1659878857427,"user_tz":-540,"elapsed":1,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Datasets"],"metadata":{"id":"BhYqCueMJWvz"}},{"cell_type":"code","source":["ddir = '/content/drive/MyDrive/lecture/datasets/korean-parallel-corpora/bible/'\n","\n","src_train_path = os.path.join(ddir,'src_train.pkl')\n","src_valid_path = os.path.join(ddir,'src_valid.pkl')\n","trg_train_path = os.path.join(ddir,'trg_train.pkl')\n","trg_valid_path = os.path.join(ddir,'trg_valid.pkl')\n"],"metadata":{"id":"iDmJRAP5ILF3","executionInfo":{"status":"ok","timestamp":1659878859125,"user_tz":-540,"elapsed":1,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["src_train = joblib.load(src_train_path)\n","src_valid = joblib.load(src_valid_path)\n","trg_train = joblib.load(trg_train_path)\n","trg_valid = joblib.load(trg_valid_path)"],"metadata":{"id":"tDaTdTmoIwrl","executionInfo":{"status":"ok","timestamp":1659878864253,"user_tz":-540,"elapsed":3706,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["print(src_valid)"],"metadata":{"id":"hetd3-GQIzbu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["VOCAB_SIZE = 10000\n","SEQ_LEN = 60\n","BATCH_SIZE = 64"],"metadata":{"id":"UzuArbszJhRY","executionInfo":{"status":"ok","timestamp":1659878864253,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Dataloads"],"metadata":{"id":"qptHU29AJsy0"}},{"cell_type":"code","source":["class TrainDataset(Dataset):\n","    def __init__(self, src_data, trg_data):\n","        super().__init__()\n","\n","        assert len(src_data) == len(trg_data)\n","\n","        self.src_data = src_data\n","        self.trg_data = trg_data\n","\n","    def __len__(self):\n","        return len(self.src_data)\n","        \n","    def __getitem__ (self, idx):\n","        src = self.src_data[idx]\n","        trg_input = self.trg_data[idx]\n","        trg_output = trg_input[1:SEQ_LEN]\n","        trg_output = np.pad(trg_output, (0,1), 'constant', constant_values =0)\n","  \n","        return torch.Tensor(src).long(), torch.Tensor(trg_input).long(), torch.Tensor(trg_output).long()\n","\n","train_dataset = TrainDataset(src_train, trg_train)\n","train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle= True, pin_memory=True)"],"metadata":{"id":"VwHbUSAEJR9H","executionInfo":{"status":"ok","timestamp":1659878864253,"user_tz":-540,"elapsed":1,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class ValidDataset(Dataset):\n","    def __init__(self, src_data, trg_data):\n","        super().__init__()\n","\n","        assert len(src_data) == len(trg_data)\n","\n","        self.src_data = src_data\n","        self.trg_data = trg_data\n","\n","    def __len__(self):\n","        return len(self.src_data)\n","        \n","    def __getitem__ (self, idx):\n","        src = self.src_data[idx]\n","        trg_input = self.trg_data[idx]\n","        trg_output = trg_input[1:SEQ_LEN]\n","        trg_output = np.pad(trg_output, (0,1), 'constant',constant_values= 0)\n","\n","        return torch.Tensor(src).long(), torch.Tensor(trg_input).long(), torch.Tensor(trg_output).long()\n","\n","valid_dataset = ValidDataset(src_valid, trg_valid)\n","valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle= False, pin_memory=True)"],"metadata":{"id":"ZRbaeev3J3xg","executionInfo":{"status":"ok","timestamp":1659878866872,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["Transformer"],"metadata":{"id":"qEThgGLQMFU5"}},{"cell_type":"code","source":["class Transformer(nn.Module):\n","    def __init__(self, N = 2, hidden_dim = 256, num_head = 8, inner_dim = 512):\n","        super().__init__()\n","        self.encoder = Encoder(N, hidden_dim, num_head, inner_dim)\n","        self.decoder = Decoder(N, hidden_dim, num_head, inner_dim)\n","\n","    def forward(self, enc_src, dec_src):\n","\n","        enc_output = self.encoder(enc_src)\n","        logits, output = self.decoder(dec_src, enc_src, enc_output)\n","\n","        return logits, output"],"metadata":{"id":"KuwcZdXMLw2P","executionInfo":{"status":"ok","timestamp":1659878869460,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["Encoder"],"metadata":{"id":"SlrYHWUFNLgQ"}},{"cell_type":"code","source":["class Encoder(nn.Module):\n","    def __init__ (self, N, hidden_dim, num_head, inner_dim,max_length=100):\n","        super().__init__()\n","\n","        # N : number of encoder layer repeated \n","        self.N = N\n","        self.hidden_dim = hidden_dim\n","        self.num_head = num_head\n","        self.inner_dim = inner_dim\n","\n","        self.embedding = nn.Embedding(num_embeddings=VOCAB_SIZE, embedding_dim=hidden_dim, padding_idx=0)\n","        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n","        self.enc_layers = nn.ModuleList([EncoderLayer(hidden_dim, num_head, inner_dim) for _ in range(N)])\n","\n","        self.dropout = nn.Dropout(p=0.1)\n","\n","    def forward(self, input):\n","        \n","        batch_size = input.shape[0]\n","        seq_len = input.shape[1]\n","\n","\n","        mask = makeMask(input, option='padding')\n","\n","        pos = torch.arange(0, seq_len).unsqueeze(0).repeat(batch_size, 1).to(device)\n","\n","        output = self.dropout(self.embedding(input) + self.pos_embedding(pos))\n","\n","        # Dropout\n","        output = self.dropout(output)\n","\n","        # N encoder layer\n","        for layer in self.enc_layers:\n","            output = layer(output, mask)\n","\n","\n","        return output"],"metadata":{"id":"o9wQKd0ZMIyP","executionInfo":{"status":"ok","timestamp":1659878871779,"user_tz":-540,"elapsed":351,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["class EncoderLayer(nn.Module):\n","    def __init__(self, hidden_dim, num_head, inner_dim):\n","        super().__init__()\n","\n","        self.hidden_dim = hidden_dim\n","        self.num_head = num_head\n","        self.inner_dim = inner_dim\n","        \n","        self.multiheadattention = Multiheadattention(hidden_dim, num_head)\n","        self.ffn = FFN(hidden_dim, inner_dim)\n","        self.layerNorm1 = nn.LayerNorm(hidden_dim)\n","        self.layerNorm2 = nn.LayerNorm(hidden_dim)\n","\n","\n","        self.dropout1 = nn.Dropout(p=0.1)\n","        self.dropout2 = nn.Dropout(p=0.1)\n","\n","\n","    def forward(self, input, mask = None):\n","\n","        output = self.multiheadattention(srcQ= input, srcK = input, srcV = input, mask = mask)\n","        output = self.dropout1(output)\n","        output = input + output\n","        output = self.layerNorm1(output)\n","\n","        output_ = self.ffn(output)\n","        output_ = self.dropout2(output_)\n","        output = output + output_\n","        output = self.layerNorm2(output)\n","\n","        return output"],"metadata":{"id":"QZdJ4TuUMs6d","executionInfo":{"status":"ok","timestamp":1659878874014,"user_tz":-540,"elapsed":421,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["class Multiheadattention"],"metadata":{"id":"y-nXmAaZOwsP"}},{"cell_type":"code","source":["class Multiheadattention(nn.Module):\n","    def __init__(self, hidden_dim: int, num_head: int):\n","        super().__init__()\n","\n","        # embedding_dim, d_model, 512 in paper\n","        self.hidden_dim = hidden_dim\n","        # 8 in paper\n","        self.num_head = num_head\n","        # head_dim, d_key, d_query, d_value, 64 in paper (= 512 / 8)\n","        self.head_dim = hidden_dim // num_head\n","        self.scale = torch.sqrt(torch.FloatTensor()).to(device)\n","\n","        self.fcQ = nn.Linear(hidden_dim, hidden_dim)\n","        self.fcK = nn.Linear(hidden_dim, hidden_dim)\n","        self.fcV = nn.Linear(hidden_dim, hidden_dim)\n","        self.fcOut = nn.Linear(hidden_dim, hidden_dim)\n","\n","        self.dropout = nn.Dropout(0.1)\n","\n","\n","    def forward(self, srcQ, srcK, srcV, mask=None):\n","\n","        ##### SCALED DOT PRODUCT ATTENTION ######\n","\n","        Q = self.fcQ(srcQ)\n","        K = self.fcK(srcK)\n","        V = self.fcV(srcV)\n","\n","        Q = rearrange(\n","            Q, 'bs seq_len (num_head head_dim) -> bs num_head seq_len head_dim', num_head=self.num_head)\n","        K_T = rearrange(\n","            K, 'bs seq_len (num_head head_dim) -> bs num_head head_dim seq_len', num_head=self.num_head)\n","        V = rearrange(\n","            V, 'bs seq_len (num_head head_dim) -> bs num_head seq_len head_dim', num_head=self.num_head)\n","        \n","        attention_energy = torch.matmul(Q, K_T)\n","\n","        if mask is not None :\n"," \n","            attention_energy = torch.masked_fill(attention_energy, (mask == 0), -1e+4)\n","            \n","        attention_energy = torch.softmax(attention_energy, dim = -1)\n","\n","        result = torch.matmul(self.dropout(attention_energy),V)\n","\n","        ##### END OF SCALED DOT PRODUCT ATTENTION ######\n","\n","        # CONCAT\n","        result = rearrange(result, 'bs num_head seq_len head_dim -> bs seq_len (num_head head_dim)')\n","\n","        result = self.fcOut(result)\n","\n","        return result"],"metadata":{"id":"AeweX1D4NJ9X","executionInfo":{"status":"ok","timestamp":1659878876639,"user_tz":-540,"elapsed":459,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["FFN"],"metadata":{"id":"kEBf_pUfO1LT"}},{"cell_type":"code","source":["class FFN(nn.Module):\n","    def __init__ (self, hidden_dim, inner_dim):\n","        super().__init__()\n"," \n","        self.hidden_dim = hidden_dim\n","\n","        self.inner_dim = inner_dim \n","\n","        self.fc1 = nn.Linear(hidden_dim, inner_dim)\n","        self.fc2 = nn.Linear(inner_dim, hidden_dim)\n","        self.relu = nn.ReLU(inplace=False)\n","        self.dropout = nn.Dropout(0.1)\n","   \n","    def forward(self, input):\n","        output = input\n","        output = self.fc1(output)\n","        output2 = self.relu(output)\n","        output2 = self.dropout(output)\n","        output3 = self.fc2(output2)\n","\n","        return output3"],"metadata":{"id":"_HyB0V7hOCzX","executionInfo":{"status":"ok","timestamp":1659878878512,"user_tz":-540,"elapsed":345,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["Decoder"],"metadata":{"id":"Hy_z0xRPO3al"}},{"cell_type":"code","source":["class Decoder(nn.Module):\n","    def __init__ (self, N, hidden_dim, num_head, inner_dim, max_length=100):\n","        super().__init__()\n","\n","        # N : number of encoder layer repeated \n","        self.N = N\n","        self.hidden_dim = hidden_dim\n","        self.num_head = num_head\n","        self.inner_dim = inner_dim\n","\n","        self.embedding = nn.Embedding(num_embeddings=VOCAB_SIZE, embedding_dim=hidden_dim, padding_idx=0)\n","        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n","\n","        self.dec_layers = nn.ModuleList([DecoderLayer(hidden_dim, num_head, inner_dim) for _ in range(N)])\n","\n","        self.dropout = nn.Dropout(p=0.1)\n","        \n","        self.finalFc = nn.Linear(hidden_dim, VOCAB_SIZE)\n","\n","\n","    def forward(self, input, enc_src, enc_output):\n","\n","        \n","        lookaheadMask = makeMask(input, option= 'lookahead')\n","        paddingMask = makeMask(enc_src, option = 'padding')\n","\n","        # embedding layer\n","        output = self.embedding(input)\n","\n","        # Dropout\n","        output = self.dropout(output)\n","\n","        for layer in self.dec_layers:\n","            output = layer(output, enc_output, paddingMask, lookaheadMask)\n","\n","        logits = self.finalFc(output)\n","\n","        output = torch.softmax(logits, dim = -1)\n","\n","        output = torch.argmax(output, dim = -1)\n","\n","\n","        return logits, output"],"metadata":{"id":"MBrYWnwpOnsl","executionInfo":{"status":"ok","timestamp":1659878880693,"user_tz":-540,"elapsed":362,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["class DecoderLayer(nn.Module):\n","    def __init__(self, hidden_dim, num_head, inner_dim):\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.inner_dim = inner_dim\n","\n","        self.multiheadattention1 = Multiheadattention(hidden_dim, num_head)\n","        self.layerNorm1 = nn.LayerNorm(hidden_dim)\n","        self.multiheadattention2 = Multiheadattention(hidden_dim, num_head)\n","        self.layerNorm2 = nn.LayerNorm(hidden_dim)\n","        self.ffn = FFN(hidden_dim, inner_dim)\n","        self.layerNorm3 = nn.LayerNorm(hidden_dim)\n","\n","        self.dropout1 = nn.Dropout(p=0.1)\n","        self.dropout2 = nn.Dropout(p=0.1)\n","        self.dropout3 = nn.Dropout(p=0.1)\n","\n","    \n","    def forward(self, input, enc_output, paddingMask, lookaheadMask):\n","\n","        # first multiheadattention\n","        output = self.multiheadattention1(input, input, input, lookaheadMask)\n","        output = self.dropout1(output)\n","        output = output + input\n","        output = self.layerNorm1(output)\n","\n","\n","        # second multiheadattention\n","        output_ = self.multiheadattention2(output, enc_output, enc_output, paddingMask)\n","        output_ = self.dropout2(output_)\n","        output = output_ + output\n","        output = self.layerNorm2(output)\n","\n","\n","        # Feedforward Network\n","        output_ = self.ffn(output)\n","        output_ = self.dropout3(output_)\n","        output = output + output_\n","        output = self.layerNorm3(output)\n","\n","\n","\n","        return output"],"metadata":{"id":"nCf_HyzMPUUf","executionInfo":{"status":"ok","timestamp":1659878882646,"user_tz":-540,"elapsed":347,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["\n","def makeMask(tensor, option: str) -> torch.Tensor:\n","  \n","    if option == 'padding':\n","        tmp = torch.full_like(tensor, fill_value=PAD_IDX).to(device)\n","       \n","        mask = (tensor != tmp).float()\n","        \n","        mask = rearrange(mask, 'bs seq_len -> bs 1 1 seq_len ')\n","\n","    elif option == 'lookahead':\n","\n","        padding_mask = makeMask(tensor, 'padding')\n","        padding_mask = repeat(\n","            padding_mask, 'bs 1 1 k_len -> bs 1 new k_len', new=padding_mask.shape[3])\n","        \n","        mask = torch.ones_like(padding_mask)\n","        mask = torch.tril(mask)\n","\n","        mask = mask * padding_mask\n","        \n","    return mask"],"metadata":{"id":"SsUFdxgXQPjs","executionInfo":{"status":"ok","timestamp":1659878884900,"user_tz":-540,"elapsed":362,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["Model 생성"],"metadata":{"id":"1dIgrqUaQw0X"}},{"cell_type":"code","source":["model = Transformer(N, HIDDEN_DIM, NUM_HEAD, INNER_DIM).to(device)"],"metadata":{"id":"mel1uin4QX4O","executionInfo":{"status":"ok","timestamp":1659878889880,"user_tz":-540,"elapsed":2329,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["optimizer = torch.optim.Adam(params = model.parameters(), lr = 1e-4, weight_decay = 0)\n","\n","def criterion(logits: torch.tensor, targets: torch.tensor):\n","    return nn.CrossEntropyLoss(ignore_index=PAD_IDX)(logits.view(-1,VOCAB_SIZE), targets.view(-1))"],"metadata":{"id":"uEQppjFFQjVu","executionInfo":{"status":"ok","timestamp":1659878895147,"user_tz":-540,"elapsed":351,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["Training Function"],"metadata":{"id":"bRz2_8pDR5bo"}},{"cell_type":"code","source":["def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n","\n","    model.train()\n","\n","    dataset_size = 0\n","    running_loss = 0\n","    running_accuracy = 0\n","    accuracy = 0\n","\n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","\n","    for step, (src, trg_input, trg_output) in bar:\n","        src = src.to(device)\n","        trg_input = trg_input.to(device)\n","        trg_output = trg_output.to(device)\n","\n","        batch_size = src.shape[0]\n","\n","        logits, output = model(enc_src=src, dec_src=trg_input)\n","        loss = criterion(logits, trg_output)\n","\n","        loss.backward()\n","    \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)  \n","     \n","        optimizer.step()\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # change learning rate by Scheduler\n","        if scheduler is not None:\n","            scheduler.step()\n","\n","        running_loss += loss.item() * batch_size\n","        running_accuracy = np.mean(\n","            output.view(-1).detach().cpu().numpy() == trg_output.view(-1).detach().cpu().numpy())\n","\n","        accuracy += running_accuracy\n","\n","        dataset_size += batch_size\n","        epoch_loss = running_loss / dataset_size\n","\n","        bar.set_postfix(\n","            Epoch=epoch, Train_Loss=epoch_loss, LR=optimizer.param_groups[0][\"lr\"], accuracy=accuracy / np.float(\n","                step+1)\n","        )\n","\n","    accuracy /= len(dataloader)\n","\n","    gc.collect()\n","\n","    return epoch_loss, accuracy"],"metadata":{"id":"5hYMDEp1Q5u3","executionInfo":{"status":"ok","timestamp":1659878897845,"user_tz":-540,"elapsed":364,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["Validation Frunction"],"metadata":{"id":"i3bhrhnGSINv"}},{"cell_type":"code","source":["@torch.no_grad()\n","def valid_one_epoch(model, dataloader, device, epoch):\n","    model.eval()\n","\n","    dataset_size = 0\n","    running_loss = 0\n","    accuracy = 0\n","\n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","\n","    for step, (src, trg_input, trg_output) in bar:\n","        src = src.to(device)\n","        trg_input = trg_input.to(device)\n","        trg_output = trg_output.to(device)\n","\n","        batch_size = src.shape[0]\n","\n","        logits, output = model(enc_src = src, dec_src = trg_input)\n","        loss = criterion(logits, trg_output)\n","\n","        running_loss += loss.item() * batch_size\n","        dataset_size += batch_size\n","\n","     \n","        val_loss = running_loss / dataset_size\n","        running_accuracy = np.mean(output.view(-1).detach().cpu().numpy() == trg_output.view(-1).detach().cpu().numpy())\n","        \n","        accuracy += running_accuracy\n","\n","        bar.set_postfix(\n","            Epoch=epoch, Valid_Loss=val_loss, LR=optimizer.param_groups[0][\"lr\"], accuracy = accuracy / np.float(step + 1)\n","        )\n","\n","    accuracy /= len(dataloader)\n","\n","    gc.collect()\n","\n","    return val_loss, accuracy"],"metadata":{"id":"FK_FTIL6RY8v","executionInfo":{"status":"ok","timestamp":1659878899961,"user_tz":-540,"elapsed":359,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["Run"],"metadata":{"id":"i8wrQ52aSA1M"}},{"cell_type":"code","source":["def run_training(\n","    model,\n","    optimizer,\n","    scheduler,\n","    device,\n","    num_epochs,\n","    metric_prefix=\"\",\n","    file_prefix=\"\",\n","    early_stopping=True,\n","    early_stopping_step=10,\n","):\n","\n","    if torch.cuda.is_available():\n","        print(\"[INFO] Using GPU:{}\\n\".format(torch.cuda.get_device_name()))\n","\n","    start = time.time()\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_loss = np.inf\n","    history = defaultdict(list)\n","    early_stop_counter = 0\n","\n","    for epoch in range(1, num_epochs + 1):\n","        gc.collect()\n","\n","        train_epoch_loss, train_accuracy = train_one_epoch(\n","            model,\n","            optimizer,\n","            scheduler,\n","            dataloader= train_dataloader,\n","            device=device,\n","            epoch=epoch,\n","        )\n","\n","        val_loss, val_accuracy = valid_one_epoch(\n","            model, valid_dataloader, device=device, epoch=epoch\n","        )\n","\n","        history[f\"{metric_prefix}Train Loss\"].append(train_epoch_loss)\n","        history[f\"{metric_prefix}Train Accuracy\"].append(train_accuracy)\n","        history[f\"{metric_prefix}Valid Loss\"].append(val_loss)\n","        history[f\"{metric_prefix}Valid Accuracy\"].append(val_accuracy)\n","\n","\n","        print(f\"Valid Loss : {val_loss}\")\n","\n","        if val_loss <= best_loss:\n","            early_stop_counter = 0\n","\n","            print(\n","                f\"Validation Loss improved( {best_loss} ---> {val_loss}  )\"\n","            )\n","\n","            # Update Best Loss\n","            best_loss = val_loss\n","            \n","            best_model_wts = copy.deepcopy(model.state_dict())\n","\n","            PATH = \"{}epoch{:.0f}_Loss{:.4f}.bin\".format(file_prefix, epoch, best_loss)\n","            torch.save(model.state_dict(), PATH)\n","            torch.save(model.state_dict(), f\"{file_prefix}best_{epoch}epoch.bin\")\n","\n","            print(f\"Model Saved\")\n","\n","        elif early_stopping:\n","            early_stop_counter += 1\n","            if early_stop_counter > early_stopping_step:\n","                break\n","        \n","    end = time.time()\n","    time_elapsed = end - start\n","    print(\n","        \"Training complete in {:.0f}h {:.0f}m {:.0f}s\".format(\n","            time_elapsed // 3600,\n","            (time_elapsed % 3600) // 60,\n","            (time_elapsed % 3600) % 60,\n","        )\n","    )\n","    print(\"Best Loss: {:.4f}\".format(best_loss))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","\n","    return model, history\n"],"metadata":{"id":"OF2eV4cHRlJ1","executionInfo":{"status":"ok","timestamp":1659878902135,"user_tz":-540,"elapsed":349,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["Training 실행"],"metadata":{"id":"UwyaPjIGSXwx"}},{"cell_type":"code","source":["run_training(\n","    model = model,\n","    optimizer = optimizer,\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=100, eta_min=1e-5),\n","    device = device,\n","    num_epochs = 2000,\n","    metric_prefix=\"\",\n","    file_prefix=\"\",\n","    early_stopping=True,\n","    early_stopping_step=10,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":500},"id":"FFbdhrGqRzhV","executionInfo":{"status":"error","timestamp":1659878911431,"user_tz":-540,"elapsed":1959,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"c374061e-ca7e-440e-8499-3a8bf2a43ce7"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Using GPU:Tesla T4\n","\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/389 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  7%|▋         | 26/389 [00:01<00:25, 14.01it/s, Epoch=1, LR=7.55e-5, Train_Loss=8.27, accuracy=0.0414]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-1d3ec80f0558>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfile_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mearly_stopping_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m )\n","\u001b[0;32m<ipython-input-22-087663d34a55>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(model, optimizer, scheduler, device, num_epochs, metric_prefix, file_prefix, early_stopping, early_stopping_step)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         )\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-56aa3ff10f88>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, scheduler, dataloader, device, epoch)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# zero the parameter gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    169\u001b[0m                  \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                  \u001b[0mforeach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'foreach'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                  capturable=group['capturable'])\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    224\u001b[0m          \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m          \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m          capturable=capturable)\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), 'final.bin')"],"metadata":{"id":"gk4eVIOzSaVP","executionInfo":{"status":"ok","timestamp":1659876276701,"user_tz":-540,"elapsed":396,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":["Load text data"],"metadata":{"id":"IZ2MZfDwSnJ0"}},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"gj3gDfn4Sjv2","executionInfo":{"status":"ok","timestamp":1659878916096,"user_tz":-540,"elapsed":343,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["DATASET_PATH = '/content/drive/MyDrive/lecture/datasets/korean-parallel-corpora/bible/'"],"metadata":{"id":"buTaupXhStW2","executionInfo":{"status":"ok","timestamp":1659878919170,"user_tz":-540,"elapsed":330,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["en_train = open(os.path.join(DATASET_PATH, 'bible-all.en.txt'))\n","en_train_content = en_train.read()\n","\n","en_train_list = en_train_content.split('\\n')"],"metadata":{"id":"Uxd50D8oSv-e","executionInfo":{"status":"ok","timestamp":1659878920353,"user_tz":-540,"elapsed":1,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["ko_train = open(os.path.join(DATASET_PATH, 'bible-all.kr.txt'))\n","ko_train_content = ko_train.read()\n","\n","ko_train_list = ko_train_content.split('\\n')"],"metadata":{"id":"97sOH0CMTCIs","executionInfo":{"status":"ok","timestamp":1659878922894,"user_tz":-540,"elapsed":335,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["en_train_list[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zesnp-wqTEEt","executionInfo":{"status":"ok","timestamp":1659878925365,"user_tz":-540,"elapsed":348,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"d09a9458-0298-4ddb-f7c2-755e7f8a841f"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Genesis1.1  In the beginning God created the heavens and the earth.',\n"," 'Genesis1.2  Now the earth was formless and empty, darkness was over the surface of the deep, and the Spirit of God was hovering over the waters.',\n"," 'Genesis1.3  And God said, \"Let there be light,\" and there was light.',\n"," 'Genesis1.4  God saw that the light was good, and He separated the light from the darkness.',\n"," 'Genesis1.5  God called the light \"day,\" and the darkness he called \"night.\" And there was evening, and there was morning--the first day.',\n"," 'Genesis1.6  And God said, \"Let there be an expanse between the waters to separate water from water.\"',\n"," 'Genesis1.7  So God made the expanse and separated the water under the expanse from the water above it. And it was so.',\n"," 'Genesis1.8  God called the expanse \"sky.\" And there was evening, and there was morning--the second day.',\n"," 'Genesis1.9  And God said, \"Let the water under the sky be gathered to one place, and let dry ground appear.\" And it was so.',\n"," 'Genesis1.10  God called the dry ground \"land,\" and the gathered waters he called \"seas.\" And God saw that it was good.']"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["data = pd.DataFrame()\n","data['en_raw'] = en_train_list\n","data['ko_raw'] = ko_train_list"],"metadata":{"id":"hU3xK73ETHTl","executionInfo":{"status":"ok","timestamp":1659878927532,"user_tz":-540,"elapsed":417,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250},"id":"Fn5hYxY_TK6G","executionInfo":{"status":"ok","timestamp":1659878929530,"user_tz":-540,"elapsed":365,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"8a6b3485-221b-4ed5-df49-30244fe55bcd"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              en_raw  \\\n","0  Genesis1.1  In the beginning God created the h...   \n","1  Genesis1.2  Now the earth was formless and emp...   \n","2  Genesis1.3  And God said, \"Let there be light,...   \n","3  Genesis1.4  God saw that the light was good, a...   \n","4  Genesis1.5  God called the light \"day,\" and th...   \n","\n","                                              ko_raw  \n","0                    Genesis1.1  태초에 하나님이 천지를 창조하셨다.  \n","1  Genesis1.2  땅이 혼돈하고 공허하며, 어둠이 깊음 위에 있고, 하나님의 영...  \n","2      Genesis1.3  하나님이 말씀하시기를 \"빛이 생겨라\" 하시니, 빛이 생겼다.  \n","3   Genesis1.4  그 빛이 하나님 보시기에 좋았다. 하나님이 빛과 어둠을 나누셔서,  \n","4  Genesis1.5  빛을 낮이라고 하시고, 어둠을 밤이라고 하셨다. 저녁이 되고 ...  "],"text/html":["\n","  <div id=\"df-95f944a4-cc6d-4d83-a4b4-4bf023fbfcde\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>en_raw</th>\n","      <th>ko_raw</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Genesis1.1  In the beginning God created the h...</td>\n","      <td>Genesis1.1  태초에 하나님이 천지를 창조하셨다.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Genesis1.2  Now the earth was formless and emp...</td>\n","      <td>Genesis1.2  땅이 혼돈하고 공허하며, 어둠이 깊음 위에 있고, 하나님의 영...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Genesis1.3  And God said, \"Let there be light,...</td>\n","      <td>Genesis1.3  하나님이 말씀하시기를 \"빛이 생겨라\" 하시니, 빛이 생겼다.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Genesis1.4  God saw that the light was good, a...</td>\n","      <td>Genesis1.4  그 빛이 하나님 보시기에 좋았다. 하나님이 빛과 어둠을 나누셔서,</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Genesis1.5  God called the light \"day,\" and th...</td>\n","      <td>Genesis1.5  빛을 낮이라고 하시고, 어둠을 밤이라고 하셨다. 저녁이 되고 ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95f944a4-cc6d-4d83-a4b4-4bf023fbfcde')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-95f944a4-cc6d-4d83-a4b4-4bf023fbfcde button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-95f944a4-cc6d-4d83-a4b4-4bf023fbfcde');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["len(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y2TQ6Sh3TM4u","executionInfo":{"status":"ok","timestamp":1659878932261,"user_tz":-540,"elapsed":530,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"8cfb43a3-43e1-40fe-c323-572a795aba77"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["31104"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["data = data.reset_index(drop = True)\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250},"id":"xQKds0SRTQwX","executionInfo":{"status":"ok","timestamp":1659878932829,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"d3761c9c-e4fb-4aae-bff4-2fd26d7543e0"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              en_raw  \\\n","0  Genesis1.1  In the beginning God created the h...   \n","1  Genesis1.2  Now the earth was formless and emp...   \n","2  Genesis1.3  And God said, \"Let there be light,...   \n","3  Genesis1.4  God saw that the light was good, a...   \n","4  Genesis1.5  God called the light \"day,\" and th...   \n","\n","                                              ko_raw  \n","0                    Genesis1.1  태초에 하나님이 천지를 창조하셨다.  \n","1  Genesis1.2  땅이 혼돈하고 공허하며, 어둠이 깊음 위에 있고, 하나님의 영...  \n","2      Genesis1.3  하나님이 말씀하시기를 \"빛이 생겨라\" 하시니, 빛이 생겼다.  \n","3   Genesis1.4  그 빛이 하나님 보시기에 좋았다. 하나님이 빛과 어둠을 나누셔서,  \n","4  Genesis1.5  빛을 낮이라고 하시고, 어둠을 밤이라고 하셨다. 저녁이 되고 ...  "],"text/html":["\n","  <div id=\"df-3414571e-39ea-4736-86f4-d847e910f361\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>en_raw</th>\n","      <th>ko_raw</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Genesis1.1  In the beginning God created the h...</td>\n","      <td>Genesis1.1  태초에 하나님이 천지를 창조하셨다.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Genesis1.2  Now the earth was formless and emp...</td>\n","      <td>Genesis1.2  땅이 혼돈하고 공허하며, 어둠이 깊음 위에 있고, 하나님의 영...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Genesis1.3  And God said, \"Let there be light,...</td>\n","      <td>Genesis1.3  하나님이 말씀하시기를 \"빛이 생겨라\" 하시니, 빛이 생겼다.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Genesis1.4  God saw that the light was good, a...</td>\n","      <td>Genesis1.4  그 빛이 하나님 보시기에 좋았다. 하나님이 빛과 어둠을 나누셔서,</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Genesis1.5  God called the light \"day,\" and th...</td>\n","      <td>Genesis1.5  빛을 낮이라고 하시고, 어둠을 밤이라고 하셨다. 저녁이 되고 ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3414571e-39ea-4736-86f4-d847e910f361')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3414571e-39ea-4736-86f4-d847e910f361 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3414571e-39ea-4736-86f4-d847e910f361');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["data['en'] = data['en_raw'].apply(lambda x: x.split(' ')[1:])\n","data['en'] = data['en'].apply(lambda x: (' ').join(x))\n","data['ko'] = data['ko_raw'].apply(lambda x: x.split(' ')[1:])\n","data['ko'] = data['ko'].apply(lambda x: (' ').join(x))"],"metadata":{"id":"khbKCxBDTXt-","executionInfo":{"status":"ok","timestamp":1659878936872,"user_tz":-540,"elapsed":835,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["data = data[['en','ko']]\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320},"id":"oBeOpGwzTbL-","executionInfo":{"status":"ok","timestamp":1659878938164,"user_tz":-540,"elapsed":3,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"ec9a2bae-35fb-4675-8ab6-0bb5f7ea8ca6"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  en  \\\n","0   In the beginning God created the heavens and ...   \n","1   Now the earth was formless and empty, darknes...   \n","2   And God said, \"Let there be light,\" and there...   \n","3   God saw that the light was good, and He separ...   \n","4   God called the light \"day,\" and the darkness ...   \n","\n","                                                  ko  \n","0                                태초에 하나님이 천지를 창조하셨다.  \n","1   땅이 혼돈하고 공허하며, 어둠이 깊음 위에 있고, 하나님의 영은 물 위에 움직이고...  \n","2                  하나님이 말씀하시기를 \"빛이 생겨라\" 하시니, 빛이 생겼다.  \n","3               그 빛이 하나님 보시기에 좋았다. 하나님이 빛과 어둠을 나누셔서,  \n","4   빛을 낮이라고 하시고, 어둠을 밤이라고 하셨다. 저녁이 되고 아침이 되니, 하루가...  "],"text/html":["\n","  <div id=\"df-3d964e66-4ce2-4287-9ff1-20c89b490465\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>en</th>\n","      <th>ko</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>In the beginning God created the heavens and ...</td>\n","      <td>태초에 하나님이 천지를 창조하셨다.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Now the earth was formless and empty, darknes...</td>\n","      <td>땅이 혼돈하고 공허하며, 어둠이 깊음 위에 있고, 하나님의 영은 물 위에 움직이고...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>And God said, \"Let there be light,\" and there...</td>\n","      <td>하나님이 말씀하시기를 \"빛이 생겨라\" 하시니, 빛이 생겼다.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>God saw that the light was good, and He separ...</td>\n","      <td>그 빛이 하나님 보시기에 좋았다. 하나님이 빛과 어둠을 나누셔서,</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>God called the light \"day,\" and the darkness ...</td>\n","      <td>빛을 낮이라고 하시고, 어둠을 밤이라고 하셨다. 저녁이 되고 아침이 되니, 하루가...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d964e66-4ce2-4287-9ff1-20c89b490465')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3d964e66-4ce2-4287-9ff1-20c89b490465 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3d964e66-4ce2-4287-9ff1-20c89b490465');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","source":["Load weight"],"metadata":{"id":"ds6mXcXdTinm"}},{"cell_type":"code","source":["WEIGHT_FILE = 'final.bin'\n","WEIGHT_PATH = '/content/drive/MyDrive/Storage/transformer_lecture/'\n","\n","model = Transformer(N, HIDDEN_DIM, NUM_HEAD, INNER_DIM).to(device)\n","model.load_state_dict(torch.load(os.path.join(WEIGHT_PATH, WEIGHT_FILE), map_location=device))\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bPwSkpYhTdee","executionInfo":{"status":"ok","timestamp":1659878942192,"user_tz":-540,"elapsed":354,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"5463ec86-b91b-49fd-d030-1ec649b5c1b2"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Transformer(\n","  (encoder): Encoder(\n","    (embedding): Embedding(10000, 256, padding_idx=0)\n","    (pos_embedding): Embedding(100, 256)\n","    (enc_layers): ModuleList(\n","      (0): EncoderLayer(\n","        (multiheadattention): Multiheadattention(\n","          (fcQ): Linear(in_features=256, out_features=256, bias=True)\n","          (fcK): Linear(in_features=256, out_features=256, bias=True)\n","          (fcV): Linear(in_features=256, out_features=256, bias=True)\n","          (fcOut): Linear(in_features=256, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ffn): FFN(\n","          (fc1): Linear(in_features=256, out_features=512, bias=True)\n","          (fc2): Linear(in_features=512, out_features=256, bias=True)\n","          (relu): ReLU()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (layerNorm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (layerNorm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.1, inplace=False)\n","        (dropout2): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): EncoderLayer(\n","        (multiheadattention): Multiheadattention(\n","          (fcQ): Linear(in_features=256, out_features=256, bias=True)\n","          (fcK): Linear(in_features=256, out_features=256, bias=True)\n","          (fcV): Linear(in_features=256, out_features=256, bias=True)\n","          (fcOut): Linear(in_features=256, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ffn): FFN(\n","          (fc1): Linear(in_features=256, out_features=512, bias=True)\n","          (fc2): Linear(in_features=512, out_features=256, bias=True)\n","          (relu): ReLU()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (layerNorm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (layerNorm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.1, inplace=False)\n","        (dropout2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): Decoder(\n","    (embedding): Embedding(10000, 256, padding_idx=0)\n","    (pos_embedding): Embedding(100, 256)\n","    (dec_layers): ModuleList(\n","      (0): DecoderLayer(\n","        (multiheadattention1): Multiheadattention(\n","          (fcQ): Linear(in_features=256, out_features=256, bias=True)\n","          (fcK): Linear(in_features=256, out_features=256, bias=True)\n","          (fcV): Linear(in_features=256, out_features=256, bias=True)\n","          (fcOut): Linear(in_features=256, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (layerNorm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (multiheadattention2): Multiheadattention(\n","          (fcQ): Linear(in_features=256, out_features=256, bias=True)\n","          (fcK): Linear(in_features=256, out_features=256, bias=True)\n","          (fcV): Linear(in_features=256, out_features=256, bias=True)\n","          (fcOut): Linear(in_features=256, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (layerNorm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (ffn): FFN(\n","          (fc1): Linear(in_features=256, out_features=512, bias=True)\n","          (fc2): Linear(in_features=512, out_features=256, bias=True)\n","          (relu): ReLU()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (layerNorm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.1, inplace=False)\n","        (dropout2): Dropout(p=0.1, inplace=False)\n","        (dropout3): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): DecoderLayer(\n","        (multiheadattention1): Multiheadattention(\n","          (fcQ): Linear(in_features=256, out_features=256, bias=True)\n","          (fcK): Linear(in_features=256, out_features=256, bias=True)\n","          (fcV): Linear(in_features=256, out_features=256, bias=True)\n","          (fcOut): Linear(in_features=256, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (layerNorm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (multiheadattention2): Multiheadattention(\n","          (fcQ): Linear(in_features=256, out_features=256, bias=True)\n","          (fcK): Linear(in_features=256, out_features=256, bias=True)\n","          (fcV): Linear(in_features=256, out_features=256, bias=True)\n","          (fcOut): Linear(in_features=256, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (layerNorm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (ffn): FFN(\n","          (fc1): Linear(in_features=256, out_features=512, bias=True)\n","          (fc2): Linear(in_features=512, out_features=256, bias=True)\n","          (relu): ReLU()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (layerNorm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.1, inplace=False)\n","        (dropout2): Dropout(p=0.1, inplace=False)\n","        (dropout3): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (finalFc): Linear(in_features=256, out_features=10000, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["import sentencepiece as spm\n","\n","SRC_MODEL_FILE = os.path.join(ddir,'src.model')\n","TRG_MODEL_FILE = os.path.join(ddir,'trg.model')\n","\n","sp_src = spm.SentencePieceProcessor()\n","sp_src.Load(SRC_MODEL_FILE)\n","sp_trg = spm.SentencePieceProcessor()\n","sp_trg.Load(TRG_MODEL_FILE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E_hs7oqPTvvN","executionInfo":{"status":"ok","timestamp":1659878945103,"user_tz":-540,"elapsed":343,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"56f97fc5-8121-4bad-8db5-576eafff0c19"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["def predict(src_sentence):\n","  \n","    dec_sentence = ''\n","\n","    enc_src = sp_src.EncodeAsIds(src_sentence)\n","    dec_src = []\n","    dec_src = np.insert(dec_src, 0, sp_trg.bos_id())\n","\n","    enc_src = torch.Tensor(enc_src).view(1, -1).int().to(device)\n","    dec_src = torch.Tensor(dec_src).view(1, -1).int().to(device)\n"," \n","    last_token = None\n","    last_token_idx = 0\n","\n","    while(True):\n","\n","        enc_output = model.encoder(enc_src)\n","\n","        dec_logits, dec_output = model.decoder(\n","            input=dec_src, enc_src=enc_src, enc_output=enc_output\n","        )\n","\n","        last_token = dec_output[:, last_token_idx].item()\n","        last_token = torch.Tensor([last_token]).view(-1, 1).int().to(device)\n","\n","        dec_src = torch.cat((dec_src, last_token), dim=-1)\n","\n","        last_token_idx = last_token_idx + 1\n","\n","        if last_token.item() is EOS_IDX:\n","            break\n","\n","    return sp_trg.Decode(dec_src.tolist())"],"metadata":{"id":"EYkzRgGtUQSW","executionInfo":{"status":"ok","timestamp":1659879692363,"user_tz":-540,"elapsed":358,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["indices = np.random.choice(len(data['en']), 10, replace=False)\n","sentences = data['en'][indices].to_list()\n","answers = data['ko'][indices].to_list()\n","\n","for idx in range(len(sentences)):\n","    sentence = sentences[idx]\n","    print(f'en = {sentence}')\n","    print(f'answer = {answers[idx]}')\n","    print(f'ko = {predict(sentence)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nMPTvCBWikNk","executionInfo":{"status":"ok","timestamp":1659879890275,"user_tz":-540,"elapsed":2561,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"1d7db73b-0dcf-470c-e09b-416942fb9184"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["en =  They did not thirst when he led them through the deserts; he made water flow for them from the rock; he split the rock and water gushed out.\n","answer =  주께서 그들을 사막으로 인도하셨으나, 그들이 전혀 목마르지 않았다. 주께서는 바위에서 물을 내셔서 그들로 마시게 하셨고, 바위를 쪼개셔서 물이 솟아나게 하셨다.\n","ko = ['내가 보니, 야벳의 아들 세베소포타미아 사람 가운데서 으뜸이 되어, 나는 늘어나고 해서, 하나님께 영광을 돌면서, 하나님께 영광을 돌처럼 보이는 것은 무엇이든지 다 털어놓고, 하나님께 영광을 돌처럼 여 ⁇ 을 낳았다.']\n","en =  \"I am an alien and a stranger among you. Sell me some property for a burial site here so I can bury my dead.\"\n","answer =  \"나는 여러분 가운데서 나그네로, 떠돌이로 살고 있습니다. 죽은 나의 아내를 묻으려고 하는데, 무덤으로 쓸 땅을 여러분들에게서 좀 살 수 있게 해주시기를 바랍니다.\"\n","ko = ['\"내가 어찌 그리도 저런한 말로만 해도, 내가 어찌 그리워하는구나\" 하고 말할 수 있을까?\"']\n","en =  Then the iron, the clay, the bronze, the silver and the gold were broken to pieces at the same time and became like chaff on a threshing floor in the summer. The wind swept them away without leaving a trace. But the rock that struck the statue became a huge mountain and filled the whole earth.\n","answer =  그 때에 쇠와 진흙과 놋쇠와 은과 금이 다 부서졌으며, 여름 타작 마당의 겨와 같이 바람에 날려 가서 흔적도 찾아볼 수 없게 되었습니다. 그러나 그 신상을 친 돌은 큰 산이 되어, 온 땅에 가득 찼습니다.\n","ko = ['이 모든 것을 보고, 큰소리로 외치며, 그 사람을 사랑스러운 물건이 다 털어놓아서, 사마리아 사람의 뼈를 꺾이고, 그 다음에, 그 다음에, 그 다음에, 유다의 비탈길에 발라라. 그래서 아하스를 짜는 틀에서는 악굽이 그 다음에, 그 다음에, 그 다음에, 그 곳에다가, 그 자리에서 물러난 다음에, 그 자리에서 물러난 다음에,']\n","en =  \"Make a bronze basin, with its bronze stand, for washing. Place it between the Tent of Meeting and the altar, and put water in it.\n","answer =  \"너는 물두멍과 그 받침을 놋쇠로 만들어서, 씻는 데 쓰게 하여라. 너는 그것을 회막과 제단 사이에 놓고, 거기에 물을 담아라.\n","ko = ['그 때에 시그래의 시삭이 일어나야 한다. 그는 이 백성을 속담을 퍼붓고, 주의 율례를 지키지 않았다.']\n","en =  The descendants of the servants of Solomon: the descendants of Sotai, Sophereth, Perida,\n","answer =  솔로몬을 섬기던 종들의 자손은, 소대 자손과 소베렛 자손과 브리다 자손과\n","ko = ['\"너희의 복을 받을 때에, 인생을 즐겁게 하는 사람은 화가 있다.']\n","en =  For where your treasure is, there your heart will be also.\n","answer =  너희의 재물이 있는 곳에, 너희의 마음도 있다.\"\n","ko = ['네전한 계명은 모두와 같이, 네모두로 말미암아 내맡기 때문이다.']\n","en =  From the descendants of Bebai: Jehohanan, Hananiah, Zabbai and Athlai.\n","answer =  베배의 자손 가운데서는 여호하난과 하나냐와 삽배와 아들래요,\n","ko = ['그 아들은 아셀이다. 그 아들은 다음과 같다. 그 아들은 에브라임이다.']\n","en =  and asked, \"What are you willing to give me if I hand him over to you?\" So they counted out for him thirty silver coins.\n","answer =  \"내가 예수를 넘겨 주면, 내게 무엇을 주실 작정입니까?\" 하였다. 그들은 유다에게 은돈 서른 닢을 셈하여 주었다.\n","ko = ['\"그래서  ⁇ 대편 사람의 수가 너무 많아서, 내가 들추어 다오. 내가 들추어 다오.']\n","en =  \"Look up to the barren heights and see. Is there any place where you have not been ravished? By the roadside you sat waiting for lovers, sat like a nomad in the desert. You have defiled the land with your prostitution and wickedness.\n","answer =  \"두 눈을 뜨고, 저 벌거숭이 언덕들을 바라보아라. 네가 음행을 하여서 더럽히지 않은 곳이 어디에 있느냐? 사막에 숨어서 사람을 기다리다가 물건을 터는 유목민처럼, 너는 길거리마다 앉아서 남자들을 기다렸다. 너는 이렇게 네 음행과 악행으로 이 땅을 더럽혀 놓았다.\n","ko = [\"'이웃음의 사 ⁇ 을 지나면, 사르던 것의 욕망의 욕망의 머리도 그 밖의 보석과 같고, 그 밖의 보석을 깎는다. 그는 그돌아서는 것을 보고  ⁇ 퀴를 둘러싸 줄 알몸을 깎는다.\"]\n","en =  From the time that Amaziah turned away from following the LORD, they conspired against him in Jerusalem and he fled to Lachish, but they sent men after him to Lachish and killed him there.\n","answer =  아마샤가 주를 따르다가 등지고 돌아선 뒤에, 예루살렘에서 반란이 일어나자, 아마샤는 라기스로 도망하였다. 그러나 반란을 일으킨 사람들은 라기스에까지 사람을 보내어, 거기에서 그를 죽였고,\n","ko = ['그들은, 곧 나팔을 불고, 그 불리는 도도의 물결이 하나밖에 못 본 일이 일어나, 천천장에 넘칠 때에 나는 매우  ⁇ 니다.']\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"PUWvlS4HjRAV"},"execution_count":null,"outputs":[]}]}