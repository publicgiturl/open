{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"part4-ch5-OCR.ipynb","provenance":[],"machine_shape":"hm","mount_file_id":"1tav1opoid1iwCg88oejKh8Ymfipm85wv","authorship_tag":"ABX9TyNY0f4sj/O5SEWcXkIeJ/Gn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["cd /content/drive/MyDrive/lecture"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2-X__V1ssUdO","executionInfo":{"status":"ok","timestamp":1661073530159,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"53d59ff7-270e-4b63-8356-247d36ccbc47"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/lecture\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/HRNet/HRNet-Semantic-Segmentation.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WbipP4W0spXm","executionInfo":{"status":"ok","timestamp":1661073561454,"user_tz":-540,"elapsed":2560,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"4bcf1903-da40-47ef-c04c-2bcede828230"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'HRNet-Semantic-Segmentation'...\n","remote: Enumerating objects: 1321, done.\u001b[K\n","remote: Total 1321 (delta 0), reused 0 (delta 0), pack-reused 1321\u001b[K\n","Receiving objects: 100% (1321/1321), 1.79 MiB | 4.80 MiB/s, done.\n","Resolving deltas: 100% (828/828), done.\n"]}]},{"cell_type":"code","source":["cd HRNet-Semantic-Segmentation/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rRV3mzMpswge","executionInfo":{"status":"ok","timestamp":1661073571169,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"549af143-d00b-42a8-dc4e-5304c9a32eb4"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/lecture/HRNet-Semantic-Segmentation\n"]}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xBLZSZ16szce","executionInfo":{"status":"ok","timestamp":1661073587451,"user_tz":-540,"elapsed":3,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"1da6f8cc-bd88-4c8e-e496-2e9c3eb1447d"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdata\u001b[0m/         hubconf.py  local_log.txt     run_dist.sh\n","\u001b[01;34mexperiments\u001b[0m/  \u001b[01;34mlib\u001b[0m/        README.md         run_local.sh\n","\u001b[01;34mfigures\u001b[0m/      LICENSE     requirements.txt  \u001b[01;34mtools\u001b[0m/\n"]}]},{"cell_type":"markdown","source":["Dataset download : https://www.cityscapes-dataset.com/"],"metadata":{"id":"4nu9b0SEs-Zy"}},{"cell_type":"code","source":["cd data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fUq5H0kws3RG","executionInfo":{"status":"ok","timestamp":1661073595712,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"7ac6425c-31ac-46fc-a626-0d6f8838678f"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/lecture/HRNet-Semantic-Segmentation/data\n"]}]},{"cell_type":"code","source":["!ln -s  /content/drive/MyDrive/AI-NN/HRNet-Semantic-Segmentation/data/cityscapes/ cityscapes "],"metadata":{"id":"LW2VhmL1s5fe","executionInfo":{"status":"ok","timestamp":1661073665556,"user_tz":-540,"elapsed":1011,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["ls -al"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"30JyHdwmtKUO","executionInfo":{"status":"ok","timestamp":1661073684003,"user_tz":-540,"elapsed":3,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"4f0ffafb-21d9-465e-cb1c-8dc218437588"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["total 5\n","lrw------- 1 root root   73 Aug 21 09:21 \u001b[0m\u001b[01;36mcityscapes\u001b[0m -> \u001b[01;34m/content/drive/MyDrive/AI-NN/HRNet-Semantic-Segmentation/data/cityscapes/\u001b[0m\u001b[K/\n","drwx------ 5 root root 4096 Aug 21 09:19 \u001b[01;34mlist\u001b[0m/\n"]}]},{"cell_type":"code","source":["cd .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9mmPsBSjtMf-","executionInfo":{"status":"ok","timestamp":1661073717298,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"a8c5039c-8937-476e-f740-9a6c69ad3235"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/lecture/HRNet-Semantic-Segmentation\n"]}]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z3OlhTmitS60","executionInfo":{"status":"ok","timestamp":1661073763946,"user_tz":-540,"elapsed":7259,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"ac670000-c077-4a4d-c31f-fca66f994ee0"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting EasyDict==1.7\n","  Downloading easydict-1.7.tar.gz (6.2 kB)\n","Requirement already satisfied: shapely in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.8.4)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.29.32)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.7.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.3.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (6.0)\n","Collecting json_tricks\n","  Downloading json_tricks-3.15.5-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (0.18.3)\n","Collecting yacs>=0.1.5\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Collecting tensorboardX>=1.6\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 6.4 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (4.64.0)\n","Collecting ninja\n","  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n","\u001b[K     |████████████████████████████████| 108 kB 33.5 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=1.6->-r requirements.txt (line 10)) (3.17.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=1.6->-r requirements.txt (line 10)) (1.21.6)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX>=1.6->-r requirements.txt (line 10)) (1.15.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 5)) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 5)) (2022.2.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 8)) (2021.11.2)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 8)) (3.2.2)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 8)) (2.9.0)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 8)) (2.6.3)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 8)) (1.3.0)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 8)) (7.1.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 8)) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 8)) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 8)) (1.4.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 8)) (4.1.1)\n","Building wheels for collected packages: EasyDict\n","  Building wheel for EasyDict (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for EasyDict: filename=easydict-1.7-py3-none-any.whl size=6122 sha256=d0ef343867fd9937a18c615af2e7e097912cf11c277c4c8c799d5ff24aad0aa2\n","  Stored in directory: /root/.cache/pip/wheels/1d/be/cf/14f66f4c4cea5ebf212d9ce559c8a0d8f4882ecc7f59a6710c\n","Successfully built EasyDict\n","Installing collected packages: yacs, tensorboardX, ninja, json-tricks, EasyDict\n","  Attempting uninstall: EasyDict\n","    Found existing installation: easydict 1.9\n","    Uninstalling easydict-1.9:\n","      Successfully uninstalled easydict-1.9\n","Successfully installed EasyDict-1.7 json-tricks-3.15.5 ninja-1.10.2.3 tensorboardX-2.5.1 yacs-0.1.8\n"]}]},{"cell_type":"markdown","source":["pretraned model download"],"metadata":{"id":"xIXrb7tPtkPo"}},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aO8lEnZCtZnu","executionInfo":{"status":"ok","timestamp":1661073825705,"user_tz":-540,"elapsed":412,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"d37f782c-0a79-468f-bc78-5552b939e39b"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdata\u001b[0m/         hubconf.py  local_log.txt       requirements.txt  \u001b[01;34mtools\u001b[0m/\n","\u001b[01;34mexperiments\u001b[0m/  \u001b[01;34mlib\u001b[0m/        \u001b[01;34mpretrained_models\u001b[0m/  run_dist.sh\n","\u001b[01;34mfigures\u001b[0m/      LICENSE     README.md           run_local.sh\n"]}]},{"cell_type":"code","source":["!mkdir pretrained_models"],"metadata":{"id":"4QOaxA5LtqLX","executionInfo":{"status":"ok","timestamp":1661073818390,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["cd pretrained_models"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"isSXfnvwtvzO","executionInfo":{"status":"ok","timestamp":1661073867186,"user_tz":-540,"elapsed":761,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"8cc62541-c497-4c79-d373-86b17f87798d"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/lecture/HRNet-Semantic-Segmentation/pretrained_models\n"]}]},{"cell_type":"code","source":["#backbone\n","!cp /content/drive/MyDrive/AI-NN/HRNet-Semantic-Segmentation/pretrained_models/hrnetv2_w48_imagenet_pretrained.pth ./ "],"metadata":{"id":"ShNc_tEGt6KW","executionInfo":{"status":"ok","timestamp":1661074448818,"user_tz":-540,"elapsed":1779,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mg8_GQMFuCYV","executionInfo":{"status":"ok","timestamp":1661074599867,"user_tz":-540,"elapsed":396,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"a85fcd9d-a98e-4bff-9e26-12c0edf2b90a"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdata\u001b[0m/                                \u001b[01;34mlib\u001b[0m/                README.md\n","\u001b[01;34mexperiments\u001b[0m/                         LICENSE             requirements.txt\n","\u001b[01;34mfigures\u001b[0m/                             local_log.txt       run_dist.sh\n","hrnet_ocr_cs_8162_torch11.pth        \u001b[01;34mlog\u001b[0m/                run_local.sh\n","hrnetv2_w48_imagenet_pretrained.pth  \u001b[01;34moutput\u001b[0m/             \u001b[01;34mtools\u001b[0m/\n","hubconf.py                           \u001b[01;34mpretrained_models\u001b[0m/\n"]}]},{"cell_type":"code","source":["#ocr\n","!wget https://github.com/hsfzxjy/models.storage/releases/download/HRNet-OCR/hrnet_ocr_cs_8162_torch11.pth "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AF04Gz56uduG","executionInfo":{"status":"ok","timestamp":1661074596130,"user_tz":-540,"elapsed":49788,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"ac0d3ccf-0b77-4a2b-91ca-c89a4538fd56"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-08-21 09:35:42--  https://github.com/hsfzxjy/models.storage/releases/download/HRNet-OCR/hrnet_ocr_cs_8162_torch11.pth\n","Resolving github.com (github.com)... 20.27.177.113\n","Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/299848440/833f1980-0336-11eb-9b20-6fc0209b1c79?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220821%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220821T093542Z&X-Amz-Expires=300&X-Amz-Signature=e866f4279f38645847c1430b079183e912d8c42c09864092f52a7af72a3651ca&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=299848440&response-content-disposition=attachment%3B%20filename%3Dhrnet_ocr_cs_8162_torch11.pth&response-content-type=application%2Foctet-stream [following]\n","--2022-08-21 09:35:42--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/299848440/833f1980-0336-11eb-9b20-6fc0209b1c79?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220821%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220821T093542Z&X-Amz-Expires=300&X-Amz-Signature=e866f4279f38645847c1430b079183e912d8c42c09864092f52a7af72a3651ca&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=299848440&response-content-disposition=attachment%3B%20filename%3Dhrnet_ocr_cs_8162_torch11.pth&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 282263005 (269M) [application/octet-stream]\n","Saving to: ‘hrnet_ocr_cs_8162_torch11.pth’\n","\n","hrnet_ocr_cs_8162_t 100%[===================>] 269.19M  6.44MB/s    in 47s     \n","\n","2022-08-21 09:36:31 (5.67 MB/s) - ‘hrnet_ocr_cs_8162_torch11.pth’ saved [282263005/282263005]\n","\n"]}]},{"cell_type":"markdown","source":["Test 실행"],"metadata":{"id":"Lq6IC_l7uqcd"}},{"cell_type":"code","source":["!python tools/test.py --cfg experiments/cityscapes/seg_hrnet_ocr_w48_train_512x1024_sgd_lr1e-2_wd5e-4_bs_12_epoch484.yaml \\\n","                     TEST.MODEL_FILE hrnet_ocr_cs_8162_torch11.pth \\\n","                     TEST.SCALE_LIST 0.5,0.75,1.0,1.25,1.5,1.75 \\\n","                     TEST.FLIP_TEST True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"79M1pM8sumGO","executionInfo":{"status":"ok","timestamp":1661074824814,"user_tz":-540,"elapsed":76671,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"cdaaf190-0c37-4de6-8768-2dcdd8dc8d77"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["=> creating output/cityscapes/seg_hrnet_ocr_w48_train_512x1024_sgd_lr1e-2_wd5e-4_bs_12_epoch484\n","=> creating log/cityscapes/seg_hrnet_ocr/seg_hrnet_ocr_w48_train_512x1024_sgd_lr1e-2_wd5e-4_bs_12_epoch484_2022-08-21-09-39\n","Namespace(cfg='experiments/cityscapes/seg_hrnet_ocr_w48_train_512x1024_sgd_lr1e-2_wd5e-4_bs_12_epoch484.yaml', opts=['TEST.MODEL_FILE', 'hrnet_ocr_cs_8162_torch11.pth', 'TEST.SCALE_LIST', '0.5,0.75,1.0,1.25,1.5,1.75', 'TEST.FLIP_TEST', 'True'])\n","{'AUTO_RESUME': False,\n"," 'CUDNN': CfgNode({'BENCHMARK': True, 'DETERMINISTIC': False, 'ENABLED': True}),\n"," 'DATASET': {'DATASET': 'cityscapes',\n","             'EXTRA_TRAIN_SET': '',\n","             'NUM_CLASSES': 19,\n","             'ROOT': 'data/',\n","             'TEST_SET': 'list/cityscapes/val.lst',\n","             'TRAIN_SET': 'list/cityscapes/train.lst'},\n"," 'DEBUG': {'DEBUG': False,\n","           'SAVE_BATCH_IMAGES_GT': False,\n","           'SAVE_BATCH_IMAGES_PRED': False,\n","           'SAVE_HEATMAPS_GT': False,\n","           'SAVE_HEATMAPS_PRED': False},\n"," 'GPUS': (0,),\n"," 'LOG_DIR': 'log',\n"," 'LOSS': {'BALANCE_WEIGHTS': [0.4, 1],\n","          'CLASS_BALANCE': False,\n","          'OHEMKEEP': 131072,\n","          'OHEMTHRES': 0.9,\n","          'USE_OHEM': False},\n"," 'MODEL': {'ALIGN_CORNERS': True,\n","           'EXTRA': {'FINAL_CONV_KERNEL': 1,\n","                     'STAGE1': {'BLOCK': 'BOTTLENECK',\n","                                'FUSE_METHOD': 'SUM',\n","                                'NUM_BLOCKS': [4],\n","                                'NUM_CHANNELS': [64],\n","                                'NUM_MODULES': 1,\n","                                'NUM_RANCHES': 1},\n","                     'STAGE2': {'BLOCK': 'BASIC',\n","                                'FUSE_METHOD': 'SUM',\n","                                'NUM_BLOCKS': [4, 4],\n","                                'NUM_BRANCHES': 2,\n","                                'NUM_CHANNELS': [48, 96],\n","                                'NUM_MODULES': 1},\n","                     'STAGE3': {'BLOCK': 'BASIC',\n","                                'FUSE_METHOD': 'SUM',\n","                                'NUM_BLOCKS': [4, 4, 4],\n","                                'NUM_BRANCHES': 3,\n","                                'NUM_CHANNELS': [48, 96, 192],\n","                                'NUM_MODULES': 4},\n","                     'STAGE4': {'BLOCK': 'BASIC',\n","                                'FUSE_METHOD': 'SUM',\n","                                'NUM_BLOCKS': [4, 4, 4, 4],\n","                                'NUM_BRANCHES': 4,\n","                                'NUM_CHANNELS': [48, 96, 192, 384],\n","                                'NUM_MODULES': 3}},\n","           'NAME': 'seg_hrnet_ocr',\n","           'NUM_OUTPUTS': 2,\n","           'OCR': {'DROPOUT': 0.05,\n","                   'KEY_CHANNELS': 256,\n","                   'MID_CHANNELS': 512,\n","                   'SCALE': 1},\n","           'PRETRAINED': 'pretrained_models/hrnetv2_w48_imagenet_pretrained.pth'},\n"," 'OUTPUT_DIR': 'output',\n"," 'PIN_MEMORY': True,\n"," 'PRINT_FREQ': 10,\n"," 'RANK': 0,\n"," 'TEST': {'BASE_SIZE': 2048,\n","          'BATCH_SIZE_PER_GPU': 4,\n","          'FLIP_TEST': True,\n","          'IMAGE_SIZE': [2048, 1024],\n","          'MODEL_FILE': 'hrnet_ocr_cs_8162_torch11.pth',\n","          'MULTI_SCALE': False,\n","          'NUM_SAMPLES': 0,\n","          'OUTPUT_INDEX': -1,\n","          'SCALE_LIST': [0.5, 0.75, 1.0, 1.25, 1.5, 1.75]},\n"," 'TRAIN': {'BASE_SIZE': 2048,\n","           'BATCH_SIZE_PER_GPU': 3,\n","           'BEGIN_EPOCH': 0,\n","           'DOWNSAMPLERATE': 1,\n","           'END_EPOCH': 484,\n","           'EXTRA_EPOCH': 0,\n","           'EXTRA_LR': 0.001,\n","           'FLIP': True,\n","           'FREEZE_EPOCHS': -1,\n","           'FREEZE_LAYERS': '',\n","           'IGNORE_LABEL': 255,\n","           'IMAGE_SIZE': [1024, 512],\n","           'LR': 0.01,\n","           'LR_FACTOR': 0.1,\n","           'LR_STEP': [90, 110],\n","           'MOMENTUM': 0.9,\n","           'MULTI_SCALE': True,\n","           'NESTEROV': False,\n","           'NONBACKBONE_KEYWORDS': [],\n","           'NONBACKBONE_MULT': 10,\n","           'NUM_SAMPLES': 0,\n","           'OPTIMIZER': 'sgd',\n","           'RANDOM_BRIGHTNESS': False,\n","           'RANDOM_BRIGHTNESS_SHIFT_VALUE': 10,\n","           'RESUME': True,\n","           'SCALE_FACTOR': 16,\n","           'SHUFFLE': True,\n","           'WD': 0.0005},\n"," 'WORKERS': 2}\n","=> init weights from normal distribution\n","=> loading pretrained model pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n","{'ocr_distri_head.conv_bn_dropout.1.0.running_var', 'conv3x3_ocr.1.weight', 'ocr_distri_head.object_context_block.f_pixel.1.0.running_var', 'cls_head.bias', 'ocr_distri_head.object_context_block.f_object.3.0.weight', 'aux_head.1.num_batches_tracked', 'ocr_distri_head.object_context_block.f_down.1.0.bias', 'conv3x3_ocr.1.running_mean', 'ocr_distri_head.object_context_block.f_object.3.0.running_mean', 'ocr_distri_head.object_context_block.f_object.1.0.weight', 'ocr_distri_head.object_context_block.f_object.3.0.bias', 'aux_head.3.bias', 'ocr_distri_head.object_context_block.f_up.0.weight', 'ocr_distri_head.object_context_block.f_object.1.0.running_mean', 'ocr_distri_head.object_context_block.f_pixel.1.0.running_mean', 'ocr_distri_head.object_context_block.f_object.3.0.running_var', 'ocr_distri_head.object_context_block.f_pixel.3.0.bias', 'aux_head.1.running_mean', 'cls_head.weight', 'ocr_distri_head.object_context_block.f_object.3.0.num_batches_tracked', 'conv3x3_ocr.1.bias', 'ocr_distri_head.object_context_block.f_pixel.1.0.bias', 'aux_head.1.running_var', 'conv3x3_ocr.0.bias', 'ocr_distri_head.object_context_block.f_down.1.0.weight', 'aux_head.0.bias', 'ocr_distri_head.object_context_block.f_pixel.1.0.weight', 'ocr_distri_head.object_context_block.f_pixel.3.0.num_batches_tracked', 'ocr_distri_head.object_context_block.f_pixel.3.0.running_mean', 'ocr_distri_head.object_context_block.f_object.1.0.running_var', 'ocr_distri_head.object_context_block.f_up.1.0.running_mean', 'ocr_distri_head.object_context_block.f_up.1.0.weight', 'ocr_distri_head.object_context_block.f_pixel.0.weight', 'ocr_distri_head.conv_bn_dropout.1.0.num_batches_tracked', 'ocr_distri_head.object_context_block.f_pixel.2.weight', 'aux_head.1.weight', 'ocr_distri_head.object_context_block.f_pixel.3.0.running_var', 'ocr_distri_head.object_context_block.f_down.1.0.running_var', 'ocr_distri_head.conv_bn_dropout.1.0.bias', 'ocr_distri_head.object_context_block.f_object.0.weight', 'ocr_distri_head.object_context_block.f_object.1.0.num_batches_tracked', 'conv3x3_ocr.1.running_var', 'ocr_distri_head.object_context_block.f_down.1.0.running_mean', 'ocr_distri_head.object_context_block.f_object.1.0.bias', 'aux_head.3.weight', 'ocr_distri_head.object_context_block.f_object.2.weight', 'ocr_distri_head.object_context_block.f_down.1.0.num_batches_tracked', 'conv3x3_ocr.0.weight', 'ocr_distri_head.object_context_block.f_up.1.0.num_batches_tracked', 'ocr_distri_head.object_context_block.f_pixel.1.0.num_batches_tracked', 'aux_head.0.weight', 'ocr_distri_head.conv_bn_dropout.1.0.running_mean', 'aux_head.1.bias', 'ocr_distri_head.conv_bn_dropout.0.weight', 'ocr_distri_head.object_context_block.f_down.0.weight', 'ocr_distri_head.conv_bn_dropout.1.0.weight', 'ocr_distri_head.object_context_block.f_pixel.3.0.weight', 'ocr_distri_head.object_context_block.f_up.1.0.running_var', 'ocr_distri_head.object_context_block.f_up.1.0.bias', 'conv3x3_ocr.1.num_batches_tracked'}\n","{'incre_modules.0.0.downsample.1.num_batches_tracked', 'incre_modules.2.0.bn3.bias', 'incre_modules.1.0.downsample.1.num_batches_tracked', 'incre_modules.1.0.downsample.1.weight', 'incre_modules.2.0.bn2.weight', 'incre_modules.1.0.downsample.1.bias', 'incre_modules.3.0.bn2.bias', 'incre_modules.2.0.conv1.weight', 'incre_modules.0.0.downsample.1.bias', 'incre_modules.2.0.downsample.0.weight', 'incre_modules.2.0.conv3.weight', 'incre_modules.3.0.bn1.weight', 'downsamp_modules.0.0.bias', 'incre_modules.3.0.downsample.1.weight', 'incre_modules.0.0.conv2.weight', 'incre_modules.0.0.conv1.weight', 'incre_modules.1.0.bn1.weight', 'incre_modules.1.0.downsample.1.running_var', 'downsamp_modules.0.0.weight', 'incre_modules.2.0.bn3.running_mean', 'incre_modules.0.0.bn1.running_mean', 'downsamp_modules.0.1.running_mean', 'final_layer.0.bias', 'incre_modules.0.0.downsample.1.running_mean', 'incre_modules.0.0.downsample.1.running_var', 'downsamp_modules.2.0.weight', 'downsamp_modules.0.1.running_var', 'incre_modules.0.0.bn1.num_batches_tracked', 'incre_modules.1.0.bn3.weight', 'incre_modules.0.0.bn3.bias', 'incre_modules.3.0.bn1.running_mean', 'incre_modules.2.0.bn1.weight', 'incre_modules.3.0.bn3.running_mean', 'incre_modules.3.0.downsample.1.running_var', 'incre_modules.0.0.bn1.bias', 'final_layer.1.running_mean', 'incre_modules.0.0.bn3.weight', 'incre_modules.3.0.conv1.weight', 'downsamp_modules.2.1.num_batches_tracked', 'incre_modules.3.0.bn2.weight', 'incre_modules.2.0.bn3.running_var', 'incre_modules.2.0.downsample.1.num_batches_tracked', 'downsamp_modules.1.1.running_var', 'final_layer.1.weight', 'incre_modules.0.0.bn2.running_mean', 'downsamp_modules.1.0.bias', 'incre_modules.1.0.conv1.weight', 'incre_modules.0.0.bn2.num_batches_tracked', 'incre_modules.1.0.bn2.weight', 'final_layer.1.running_var', 'downsamp_modules.0.1.num_batches_tracked', 'incre_modules.0.0.bn1.running_var', 'incre_modules.1.0.bn1.running_mean', 'incre_modules.3.0.downsample.1.num_batches_tracked', 'incre_modules.2.0.downsample.1.bias', 'incre_modules.0.0.conv3.weight', 'incre_modules.3.0.bn1.running_var', 'final_layer.0.weight', 'incre_modules.3.0.bn2.num_batches_tracked', 'incre_modules.1.0.bn2.num_batches_tracked', 'incre_modules.3.0.bn3.bias', 'incre_modules.1.0.bn3.running_var', 'final_layer.1.num_batches_tracked', 'downsamp_modules.2.1.running_var', 'incre_modules.2.0.bn1.bias', 'incre_modules.1.0.conv2.weight', 'incre_modules.1.0.bn2.running_var', 'incre_modules.0.0.bn2.running_var', 'downsamp_modules.1.1.bias', 'downsamp_modules.1.1.running_mean', 'incre_modules.1.0.conv3.weight', 'incre_modules.3.0.downsample.0.weight', 'incre_modules.3.0.bn2.running_var', 'incre_modules.2.0.downsample.1.running_mean', 'incre_modules.3.0.bn3.weight', 'incre_modules.1.0.bn3.bias', 'incre_modules.3.0.bn3.running_var', 'incre_modules.3.0.downsample.1.bias', 'incre_modules.2.0.bn1.running_mean', 'incre_modules.0.0.bn2.bias', 'incre_modules.1.0.downsample.1.running_mean', 'incre_modules.2.0.bn3.weight', 'incre_modules.3.0.bn3.num_batches_tracked', 'classifier.bias', 'downsamp_modules.1.0.weight', 'downsamp_modules.0.1.bias', 'incre_modules.2.0.bn2.num_batches_tracked', 'incre_modules.3.0.downsample.1.running_mean', 'incre_modules.3.0.bn1.num_batches_tracked', 'downsamp_modules.2.1.bias', 'incre_modules.3.0.conv2.weight', 'downsamp_modules.2.0.bias', 'classifier.weight', 'incre_modules.3.0.bn1.bias', 'incre_modules.2.0.bn1.running_var', 'incre_modules.1.0.bn1.bias', 'incre_modules.2.0.downsample.1.weight', 'downsamp_modules.1.1.weight', 'downsamp_modules.1.1.num_batches_tracked', 'downsamp_modules.2.1.weight', 'incre_modules.2.0.bn2.running_mean', 'downsamp_modules.2.1.running_mean', 'incre_modules.2.0.conv2.weight', 'incre_modules.0.0.bn1.weight', 'incre_modules.1.0.bn2.bias', 'incre_modules.0.0.downsample.1.weight', 'incre_modules.2.0.bn2.running_var', 'incre_modules.2.0.downsample.1.running_var', 'incre_modules.0.0.bn3.running_var', 'incre_modules.0.0.bn3.running_mean', 'incre_modules.2.0.bn2.bias', 'downsamp_modules.0.1.weight', 'final_layer.1.bias', 'incre_modules.1.0.bn1.num_batches_tracked', 'incre_modules.0.0.bn3.num_batches_tracked', 'incre_modules.3.0.conv3.weight', 'incre_modules.1.0.downsample.0.weight', 'incre_modules.3.0.bn2.running_mean', 'incre_modules.0.0.bn2.weight', 'incre_modules.1.0.bn1.running_var', 'incre_modules.1.0.bn3.num_batches_tracked', 'incre_modules.2.0.bn1.num_batches_tracked', 'incre_modules.2.0.bn3.num_batches_tracked', 'incre_modules.0.0.downsample.0.weight', 'incre_modules.1.0.bn3.running_mean', 'incre_modules.1.0.bn2.running_mean'}\n","\n","Total Parameters: 70,372,678\n","----------------------------------------------------------------------------------------------------------------------------------\n","Total Multiply Adds (For Convolution and Linear Layers only): 301.59661865234375 GFLOPs\n","----------------------------------------------------------------------------------------------------------------------------------\n","Number of Layers\n","Conv2d : 316 layers   BatchNorm2d : 314 layers   ReLU : 277 layers   Bottleneck : 4 layers   BasicBlock : 104 layers   HighResolutionModule : 8 layers   SpatialGather_Module : 1 layers   ObjectAttentionBlock2D : 1 layers   Dropout2d : 1 layers   SpatialOCR_Module : 1 layers   \n","=> loading model from hrnet_ocr_cs_8162_torch11.pth\n","=> loading conv1.weight from pretrained model\n","=> loading bn1.weight from pretrained model\n","=> loading bn1.bias from pretrained model\n","=> loading bn1.running_mean from pretrained model\n","=> loading bn1.running_var from pretrained model\n","=> loading bn1.num_batches_tracked from pretrained model\n","=> loading conv2.weight from pretrained model\n","=> loading bn2.weight from pretrained model\n","=> loading bn2.bias from pretrained model\n","=> loading bn2.running_mean from pretrained model\n","=> loading bn2.running_var from pretrained model\n","=> loading bn2.num_batches_tracked from pretrained model\n","=> loading layer1.0.conv1.weight from pretrained model\n","=> loading layer1.0.bn1.weight from pretrained model\n","=> loading layer1.0.bn1.bias from pretrained model\n","=> loading layer1.0.bn1.running_mean from pretrained model\n","=> loading layer1.0.bn1.running_var from pretrained model\n","=> loading layer1.0.bn1.num_batches_tracked from pretrained model\n","=> loading layer1.0.conv2.weight from pretrained model\n","=> loading layer1.0.bn2.weight from pretrained model\n","=> loading layer1.0.bn2.bias from pretrained model\n","=> loading layer1.0.bn2.running_mean from pretrained model\n","=> loading layer1.0.bn2.running_var from pretrained model\n","=> loading layer1.0.bn2.num_batches_tracked from pretrained model\n","=> loading layer1.0.conv3.weight from pretrained model\n","=> loading layer1.0.bn3.weight from pretrained model\n","=> loading layer1.0.bn3.bias from pretrained model\n","=> loading layer1.0.bn3.running_mean from pretrained model\n","=> loading layer1.0.bn3.running_var from pretrained model\n","=> loading layer1.0.bn3.num_batches_tracked from pretrained model\n","=> loading layer1.0.downsample.0.weight from pretrained model\n","=> loading layer1.0.downsample.1.weight from pretrained model\n","=> loading layer1.0.downsample.1.bias from pretrained model\n","=> loading layer1.0.downsample.1.running_mean from pretrained model\n","=> loading layer1.0.downsample.1.running_var from pretrained model\n","=> loading layer1.0.downsample.1.num_batches_tracked from pretrained model\n","=> loading layer1.1.conv1.weight from pretrained model\n","=> loading layer1.1.bn1.weight from pretrained model\n","=> loading layer1.1.bn1.bias from pretrained model\n","=> loading layer1.1.bn1.running_mean from pretrained model\n","=> loading layer1.1.bn1.running_var from pretrained model\n","=> loading layer1.1.bn1.num_batches_tracked from pretrained model\n","=> loading layer1.1.conv2.weight from pretrained model\n","=> loading layer1.1.bn2.weight from pretrained model\n","=> loading layer1.1.bn2.bias from pretrained model\n","=> loading layer1.1.bn2.running_mean from pretrained model\n","=> loading layer1.1.bn2.running_var from pretrained model\n","=> loading layer1.1.bn2.num_batches_tracked from pretrained model\n","=> loading layer1.1.conv3.weight from pretrained model\n","=> loading layer1.1.bn3.weight from pretrained model\n","=> loading layer1.1.bn3.bias from pretrained model\n","=> loading layer1.1.bn3.running_mean from pretrained model\n","=> loading layer1.1.bn3.running_var from pretrained model\n","=> loading layer1.1.bn3.num_batches_tracked from pretrained model\n","=> loading layer1.2.conv1.weight from pretrained model\n","=> loading layer1.2.bn1.weight from pretrained model\n","=> loading layer1.2.bn1.bias from pretrained model\n","=> loading layer1.2.bn1.running_mean from pretrained model\n","=> loading layer1.2.bn1.running_var from pretrained model\n","=> loading layer1.2.bn1.num_batches_tracked from pretrained model\n","=> loading layer1.2.conv2.weight from pretrained model\n","=> loading layer1.2.bn2.weight from pretrained model\n","=> loading layer1.2.bn2.bias from pretrained model\n","=> loading layer1.2.bn2.running_mean from pretrained model\n","=> loading layer1.2.bn2.running_var from pretrained model\n","=> loading layer1.2.bn2.num_batches_tracked from pretrained model\n","=> loading layer1.2.conv3.weight from pretrained model\n","=> loading layer1.2.bn3.weight from pretrained model\n","=> loading layer1.2.bn3.bias from pretrained model\n","=> loading layer1.2.bn3.running_mean from pretrained model\n","=> loading layer1.2.bn3.running_var from pretrained model\n","=> loading layer1.2.bn3.num_batches_tracked from pretrained model\n","=> loading layer1.3.conv1.weight from pretrained model\n","=> loading layer1.3.bn1.weight from pretrained model\n","=> loading layer1.3.bn1.bias from pretrained model\n","=> loading layer1.3.bn1.running_mean from pretrained model\n","=> loading layer1.3.bn1.running_var from pretrained model\n","=> loading layer1.3.bn1.num_batches_tracked from pretrained model\n","=> loading layer1.3.conv2.weight from pretrained model\n","=> loading layer1.3.bn2.weight from pretrained model\n","=> loading layer1.3.bn2.bias from pretrained model\n","=> loading layer1.3.bn2.running_mean from pretrained model\n","=> loading layer1.3.bn2.running_var from pretrained model\n","=> loading layer1.3.bn2.num_batches_tracked from pretrained model\n","=> loading layer1.3.conv3.weight from pretrained model\n","=> loading layer1.3.bn3.weight from pretrained model\n","=> loading layer1.3.bn3.bias from pretrained model\n","=> loading layer1.3.bn3.running_mean from pretrained model\n","=> loading layer1.3.bn3.running_var from pretrained model\n","=> loading layer1.3.bn3.num_batches_tracked from pretrained model\n","=> loading transition1.0.0.weight from pretrained model\n","=> loading transition1.0.1.weight from pretrained model\n","=> loading transition1.0.1.bias from pretrained model\n","=> loading transition1.0.1.running_mean from pretrained model\n","=> loading transition1.0.1.running_var from pretrained model\n","=> loading transition1.0.1.num_batches_tracked from pretrained model\n","=> loading transition1.1.0.0.weight from pretrained model\n","=> loading transition1.1.0.1.weight from pretrained model\n","=> loading transition1.1.0.1.bias from pretrained model\n","=> loading transition1.1.0.1.running_mean from pretrained model\n","=> loading transition1.1.0.1.running_var from pretrained model\n","=> loading transition1.1.0.1.num_batches_tracked from pretrained model\n","=> loading stage2.0.branches.0.0.conv1.weight from pretrained model\n","=> loading stage2.0.branches.0.0.bn1.weight from pretrained model\n","=> loading stage2.0.branches.0.0.bn1.bias from pretrained model\n","=> loading stage2.0.branches.0.0.bn1.running_mean from pretrained model\n","=> loading stage2.0.branches.0.0.bn1.running_var from pretrained model\n","=> loading stage2.0.branches.0.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage2.0.branches.0.0.conv2.weight from pretrained model\n","=> loading stage2.0.branches.0.0.bn2.weight from pretrained model\n","=> loading stage2.0.branches.0.0.bn2.bias from pretrained model\n","=> loading stage2.0.branches.0.0.bn2.running_mean from pretrained model\n","=> loading stage2.0.branches.0.0.bn2.running_var from pretrained model\n","=> loading stage2.0.branches.0.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage2.0.branches.0.1.conv1.weight from pretrained model\n","=> loading stage2.0.branches.0.1.bn1.weight from pretrained model\n","=> loading stage2.0.branches.0.1.bn1.bias from pretrained model\n","=> loading stage2.0.branches.0.1.bn1.running_mean from pretrained model\n","=> loading stage2.0.branches.0.1.bn1.running_var from pretrained model\n","=> loading stage2.0.branches.0.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage2.0.branches.0.1.conv2.weight from pretrained model\n","=> loading stage2.0.branches.0.1.bn2.weight from pretrained model\n","=> loading stage2.0.branches.0.1.bn2.bias from pretrained model\n","=> loading stage2.0.branches.0.1.bn2.running_mean from pretrained model\n","=> loading stage2.0.branches.0.1.bn2.running_var from pretrained model\n","=> loading stage2.0.branches.0.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage2.0.branches.0.2.conv1.weight from pretrained model\n","=> loading stage2.0.branches.0.2.bn1.weight from pretrained model\n","=> loading stage2.0.branches.0.2.bn1.bias from pretrained model\n","=> loading stage2.0.branches.0.2.bn1.running_mean from pretrained model\n","=> loading stage2.0.branches.0.2.bn1.running_var from pretrained model\n","=> loading stage2.0.branches.0.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage2.0.branches.0.2.conv2.weight from pretrained model\n","=> loading stage2.0.branches.0.2.bn2.weight from pretrained model\n","=> loading stage2.0.branches.0.2.bn2.bias from pretrained model\n","=> loading stage2.0.branches.0.2.bn2.running_mean from pretrained model\n","=> loading stage2.0.branches.0.2.bn2.running_var from pretrained model\n","=> loading stage2.0.branches.0.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage2.0.branches.0.3.conv1.weight from pretrained model\n","=> loading stage2.0.branches.0.3.bn1.weight from pretrained model\n","=> loading stage2.0.branches.0.3.bn1.bias from pretrained model\n","=> loading stage2.0.branches.0.3.bn1.running_mean from pretrained model\n","=> loading stage2.0.branches.0.3.bn1.running_var from pretrained model\n","=> loading stage2.0.branches.0.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage2.0.branches.0.3.conv2.weight from pretrained model\n","=> loading stage2.0.branches.0.3.bn2.weight from pretrained model\n","=> loading stage2.0.branches.0.3.bn2.bias from pretrained model\n","=> loading stage2.0.branches.0.3.bn2.running_mean from pretrained model\n","=> loading stage2.0.branches.0.3.bn2.running_var from pretrained model\n","=> loading stage2.0.branches.0.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage2.0.branches.1.0.conv1.weight from pretrained model\n","=> loading stage2.0.branches.1.0.bn1.weight from pretrained model\n","=> loading stage2.0.branches.1.0.bn1.bias from pretrained model\n","=> loading stage2.0.branches.1.0.bn1.running_mean from pretrained model\n","=> loading stage2.0.branches.1.0.bn1.running_var from pretrained model\n","=> loading stage2.0.branches.1.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage2.0.branches.1.0.conv2.weight from pretrained model\n","=> loading stage2.0.branches.1.0.bn2.weight from pretrained model\n","=> loading stage2.0.branches.1.0.bn2.bias from pretrained model\n","=> loading stage2.0.branches.1.0.bn2.running_mean from pretrained model\n","=> loading stage2.0.branches.1.0.bn2.running_var from pretrained model\n","=> loading stage2.0.branches.1.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage2.0.branches.1.1.conv1.weight from pretrained model\n","=> loading stage2.0.branches.1.1.bn1.weight from pretrained model\n","=> loading stage2.0.branches.1.1.bn1.bias from pretrained model\n","=> loading stage2.0.branches.1.1.bn1.running_mean from pretrained model\n","=> loading stage2.0.branches.1.1.bn1.running_var from pretrained model\n","=> loading stage2.0.branches.1.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage2.0.branches.1.1.conv2.weight from pretrained model\n","=> loading stage2.0.branches.1.1.bn2.weight from pretrained model\n","=> loading stage2.0.branches.1.1.bn2.bias from pretrained model\n","=> loading stage2.0.branches.1.1.bn2.running_mean from pretrained model\n","=> loading stage2.0.branches.1.1.bn2.running_var from pretrained model\n","=> loading stage2.0.branches.1.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage2.0.branches.1.2.conv1.weight from pretrained model\n","=> loading stage2.0.branches.1.2.bn1.weight from pretrained model\n","=> loading stage2.0.branches.1.2.bn1.bias from pretrained model\n","=> loading stage2.0.branches.1.2.bn1.running_mean from pretrained model\n","=> loading stage2.0.branches.1.2.bn1.running_var from pretrained model\n","=> loading stage2.0.branches.1.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage2.0.branches.1.2.conv2.weight from pretrained model\n","=> loading stage2.0.branches.1.2.bn2.weight from pretrained model\n","=> loading stage2.0.branches.1.2.bn2.bias from pretrained model\n","=> loading stage2.0.branches.1.2.bn2.running_mean from pretrained model\n","=> loading stage2.0.branches.1.2.bn2.running_var from pretrained model\n","=> loading stage2.0.branches.1.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage2.0.branches.1.3.conv1.weight from pretrained model\n","=> loading stage2.0.branches.1.3.bn1.weight from pretrained model\n","=> loading stage2.0.branches.1.3.bn1.bias from pretrained model\n","=> loading stage2.0.branches.1.3.bn1.running_mean from pretrained model\n","=> loading stage2.0.branches.1.3.bn1.running_var from pretrained model\n","=> loading stage2.0.branches.1.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage2.0.branches.1.3.conv2.weight from pretrained model\n","=> loading stage2.0.branches.1.3.bn2.weight from pretrained model\n","=> loading stage2.0.branches.1.3.bn2.bias from pretrained model\n","=> loading stage2.0.branches.1.3.bn2.running_mean from pretrained model\n","=> loading stage2.0.branches.1.3.bn2.running_var from pretrained model\n","=> loading stage2.0.branches.1.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage2.0.fuse_layers.0.1.0.weight from pretrained model\n","=> loading stage2.0.fuse_layers.0.1.1.weight from pretrained model\n","=> loading stage2.0.fuse_layers.0.1.1.bias from pretrained model\n","=> loading stage2.0.fuse_layers.0.1.1.running_mean from pretrained model\n","=> loading stage2.0.fuse_layers.0.1.1.running_var from pretrained model\n","=> loading stage2.0.fuse_layers.0.1.1.num_batches_tracked from pretrained model\n","=> loading stage2.0.fuse_layers.1.0.0.0.weight from pretrained model\n","=> loading stage2.0.fuse_layers.1.0.0.1.weight from pretrained model\n","=> loading stage2.0.fuse_layers.1.0.0.1.bias from pretrained model\n","=> loading stage2.0.fuse_layers.1.0.0.1.running_mean from pretrained model\n","=> loading stage2.0.fuse_layers.1.0.0.1.running_var from pretrained model\n","=> loading stage2.0.fuse_layers.1.0.0.1.num_batches_tracked from pretrained model\n","=> loading transition2.2.0.0.weight from pretrained model\n","=> loading transition2.2.0.1.weight from pretrained model\n","=> loading transition2.2.0.1.bias from pretrained model\n","=> loading transition2.2.0.1.running_mean from pretrained model\n","=> loading transition2.2.0.1.running_var from pretrained model\n","=> loading transition2.2.0.1.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.0.0.conv1.weight from pretrained model\n","=> loading stage3.0.branches.0.0.bn1.weight from pretrained model\n","=> loading stage3.0.branches.0.0.bn1.bias from pretrained model\n","=> loading stage3.0.branches.0.0.bn1.running_mean from pretrained model\n","=> loading stage3.0.branches.0.0.bn1.running_var from pretrained model\n","=> loading stage3.0.branches.0.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.0.0.conv2.weight from pretrained model\n","=> loading stage3.0.branches.0.0.bn2.weight from pretrained model\n","=> loading stage3.0.branches.0.0.bn2.bias from pretrained model\n","=> loading stage3.0.branches.0.0.bn2.running_mean from pretrained model\n","=> loading stage3.0.branches.0.0.bn2.running_var from pretrained model\n","=> loading stage3.0.branches.0.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.0.1.conv1.weight from pretrained model\n","=> loading stage3.0.branches.0.1.bn1.weight from pretrained model\n","=> loading stage3.0.branches.0.1.bn1.bias from pretrained model\n","=> loading stage3.0.branches.0.1.bn1.running_mean from pretrained model\n","=> loading stage3.0.branches.0.1.bn1.running_var from pretrained model\n","=> loading stage3.0.branches.0.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.0.1.conv2.weight from pretrained model\n","=> loading stage3.0.branches.0.1.bn2.weight from pretrained model\n","=> loading stage3.0.branches.0.1.bn2.bias from pretrained model\n","=> loading stage3.0.branches.0.1.bn2.running_mean from pretrained model\n","=> loading stage3.0.branches.0.1.bn2.running_var from pretrained model\n","=> loading stage3.0.branches.0.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.0.2.conv1.weight from pretrained model\n","=> loading stage3.0.branches.0.2.bn1.weight from pretrained model\n","=> loading stage3.0.branches.0.2.bn1.bias from pretrained model\n","=> loading stage3.0.branches.0.2.bn1.running_mean from pretrained model\n","=> loading stage3.0.branches.0.2.bn1.running_var from pretrained model\n","=> loading stage3.0.branches.0.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.0.2.conv2.weight from pretrained model\n","=> loading stage3.0.branches.0.2.bn2.weight from pretrained model\n","=> loading stage3.0.branches.0.2.bn2.bias from pretrained model\n","=> loading stage3.0.branches.0.2.bn2.running_mean from pretrained model\n","=> loading stage3.0.branches.0.2.bn2.running_var from pretrained model\n","=> loading stage3.0.branches.0.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.0.3.conv1.weight from pretrained model\n","=> loading stage3.0.branches.0.3.bn1.weight from pretrained model\n","=> loading stage3.0.branches.0.3.bn1.bias from pretrained model\n","=> loading stage3.0.branches.0.3.bn1.running_mean from pretrained model\n","=> loading stage3.0.branches.0.3.bn1.running_var from pretrained model\n","=> loading stage3.0.branches.0.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.0.3.conv2.weight from pretrained model\n","=> loading stage3.0.branches.0.3.bn2.weight from pretrained model\n","=> loading stage3.0.branches.0.3.bn2.bias from pretrained model\n","=> loading stage3.0.branches.0.3.bn2.running_mean from pretrained model\n","=> loading stage3.0.branches.0.3.bn2.running_var from pretrained model\n","=> loading stage3.0.branches.0.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.1.0.conv1.weight from pretrained model\n","=> loading stage3.0.branches.1.0.bn1.weight from pretrained model\n","=> loading stage3.0.branches.1.0.bn1.bias from pretrained model\n","=> loading stage3.0.branches.1.0.bn1.running_mean from pretrained model\n","=> loading stage3.0.branches.1.0.bn1.running_var from pretrained model\n","=> loading stage3.0.branches.1.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.1.0.conv2.weight from pretrained model\n","=> loading stage3.0.branches.1.0.bn2.weight from pretrained model\n","=> loading stage3.0.branches.1.0.bn2.bias from pretrained model\n","=> loading stage3.0.branches.1.0.bn2.running_mean from pretrained model\n","=> loading stage3.0.branches.1.0.bn2.running_var from pretrained model\n","=> loading stage3.0.branches.1.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.1.1.conv1.weight from pretrained model\n","=> loading stage3.0.branches.1.1.bn1.weight from pretrained model\n","=> loading stage3.0.branches.1.1.bn1.bias from pretrained model\n","=> loading stage3.0.branches.1.1.bn1.running_mean from pretrained model\n","=> loading stage3.0.branches.1.1.bn1.running_var from pretrained model\n","=> loading stage3.0.branches.1.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.1.1.conv2.weight from pretrained model\n","=> loading stage3.0.branches.1.1.bn2.weight from pretrained model\n","=> loading stage3.0.branches.1.1.bn2.bias from pretrained model\n","=> loading stage3.0.branches.1.1.bn2.running_mean from pretrained model\n","=> loading stage3.0.branches.1.1.bn2.running_var from pretrained model\n","=> loading stage3.0.branches.1.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.1.2.conv1.weight from pretrained model\n","=> loading stage3.0.branches.1.2.bn1.weight from pretrained model\n","=> loading stage3.0.branches.1.2.bn1.bias from pretrained model\n","=> loading stage3.0.branches.1.2.bn1.running_mean from pretrained model\n","=> loading stage3.0.branches.1.2.bn1.running_var from pretrained model\n","=> loading stage3.0.branches.1.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.1.2.conv2.weight from pretrained model\n","=> loading stage3.0.branches.1.2.bn2.weight from pretrained model\n","=> loading stage3.0.branches.1.2.bn2.bias from pretrained model\n","=> loading stage3.0.branches.1.2.bn2.running_mean from pretrained model\n","=> loading stage3.0.branches.1.2.bn2.running_var from pretrained model\n","=> loading stage3.0.branches.1.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.1.3.conv1.weight from pretrained model\n","=> loading stage3.0.branches.1.3.bn1.weight from pretrained model\n","=> loading stage3.0.branches.1.3.bn1.bias from pretrained model\n","=> loading stage3.0.branches.1.3.bn1.running_mean from pretrained model\n","=> loading stage3.0.branches.1.3.bn1.running_var from pretrained model\n","=> loading stage3.0.branches.1.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.1.3.conv2.weight from pretrained model\n","=> loading stage3.0.branches.1.3.bn2.weight from pretrained model\n","=> loading stage3.0.branches.1.3.bn2.bias from pretrained model\n","=> loading stage3.0.branches.1.3.bn2.running_mean from pretrained model\n","=> loading stage3.0.branches.1.3.bn2.running_var from pretrained model\n","=> loading stage3.0.branches.1.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.2.0.conv1.weight from pretrained model\n","=> loading stage3.0.branches.2.0.bn1.weight from pretrained model\n","=> loading stage3.0.branches.2.0.bn1.bias from pretrained model\n","=> loading stage3.0.branches.2.0.bn1.running_mean from pretrained model\n","=> loading stage3.0.branches.2.0.bn1.running_var from pretrained model\n","=> loading stage3.0.branches.2.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.2.0.conv2.weight from pretrained model\n","=> loading stage3.0.branches.2.0.bn2.weight from pretrained model\n","=> loading stage3.0.branches.2.0.bn2.bias from pretrained model\n","=> loading stage3.0.branches.2.0.bn2.running_mean from pretrained model\n","=> loading stage3.0.branches.2.0.bn2.running_var from pretrained model\n","=> loading stage3.0.branches.2.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.2.1.conv1.weight from pretrained model\n","=> loading stage3.0.branches.2.1.bn1.weight from pretrained model\n","=> loading stage3.0.branches.2.1.bn1.bias from pretrained model\n","=> loading stage3.0.branches.2.1.bn1.running_mean from pretrained model\n","=> loading stage3.0.branches.2.1.bn1.running_var from pretrained model\n","=> loading stage3.0.branches.2.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.2.1.conv2.weight from pretrained model\n","=> loading stage3.0.branches.2.1.bn2.weight from pretrained model\n","=> loading stage3.0.branches.2.1.bn2.bias from pretrained model\n","=> loading stage3.0.branches.2.1.bn2.running_mean from pretrained model\n","=> loading stage3.0.branches.2.1.bn2.running_var from pretrained model\n","=> loading stage3.0.branches.2.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.2.2.conv1.weight from pretrained model\n","=> loading stage3.0.branches.2.2.bn1.weight from pretrained model\n","=> loading stage3.0.branches.2.2.bn1.bias from pretrained model\n","=> loading stage3.0.branches.2.2.bn1.running_mean from pretrained model\n","=> loading stage3.0.branches.2.2.bn1.running_var from pretrained model\n","=> loading stage3.0.branches.2.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.2.2.conv2.weight from pretrained model\n","=> loading stage3.0.branches.2.2.bn2.weight from pretrained model\n","=> loading stage3.0.branches.2.2.bn2.bias from pretrained model\n","=> loading stage3.0.branches.2.2.bn2.running_mean from pretrained model\n","=> loading stage3.0.branches.2.2.bn2.running_var from pretrained model\n","=> loading stage3.0.branches.2.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.2.3.conv1.weight from pretrained model\n","=> loading stage3.0.branches.2.3.bn1.weight from pretrained model\n","=> loading stage3.0.branches.2.3.bn1.bias from pretrained model\n","=> loading stage3.0.branches.2.3.bn1.running_mean from pretrained model\n","=> loading stage3.0.branches.2.3.bn1.running_var from pretrained model\n","=> loading stage3.0.branches.2.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.0.branches.2.3.conv2.weight from pretrained model\n","=> loading stage3.0.branches.2.3.bn2.weight from pretrained model\n","=> loading stage3.0.branches.2.3.bn2.bias from pretrained model\n","=> loading stage3.0.branches.2.3.bn2.running_mean from pretrained model\n","=> loading stage3.0.branches.2.3.bn2.running_var from pretrained model\n","=> loading stage3.0.branches.2.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.0.fuse_layers.0.1.0.weight from pretrained model\n","=> loading stage3.0.fuse_layers.0.1.1.weight from pretrained model\n","=> loading stage3.0.fuse_layers.0.1.1.bias from pretrained model\n","=> loading stage3.0.fuse_layers.0.1.1.running_mean from pretrained model\n","=> loading stage3.0.fuse_layers.0.1.1.running_var from pretrained model\n","=> loading stage3.0.fuse_layers.0.1.1.num_batches_tracked from pretrained model\n","=> loading stage3.0.fuse_layers.0.2.0.weight from pretrained model\n","=> loading stage3.0.fuse_layers.0.2.1.weight from pretrained model\n","=> loading stage3.0.fuse_layers.0.2.1.bias from pretrained model\n","=> loading stage3.0.fuse_layers.0.2.1.running_mean from pretrained model\n","=> loading stage3.0.fuse_layers.0.2.1.running_var from pretrained model\n","=> loading stage3.0.fuse_layers.0.2.1.num_batches_tracked from pretrained model\n","=> loading stage3.0.fuse_layers.1.0.0.0.weight from pretrained model\n","=> loading stage3.0.fuse_layers.1.0.0.1.weight from pretrained model\n","=> loading stage3.0.fuse_layers.1.0.0.1.bias from pretrained model\n","=> loading stage3.0.fuse_layers.1.0.0.1.running_mean from pretrained model\n","=> loading stage3.0.fuse_layers.1.0.0.1.running_var from pretrained model\n","=> loading stage3.0.fuse_layers.1.0.0.1.num_batches_tracked from pretrained model\n","=> loading stage3.0.fuse_layers.1.2.0.weight from pretrained model\n","=> loading stage3.0.fuse_layers.1.2.1.weight from pretrained model\n","=> loading stage3.0.fuse_layers.1.2.1.bias from pretrained model\n","=> loading stage3.0.fuse_layers.1.2.1.running_mean from pretrained model\n","=> loading stage3.0.fuse_layers.1.2.1.running_var from pretrained model\n","=> loading stage3.0.fuse_layers.1.2.1.num_batches_tracked from pretrained model\n","=> loading stage3.0.fuse_layers.2.0.0.0.weight from pretrained model\n","=> loading stage3.0.fuse_layers.2.0.0.1.weight from pretrained model\n","=> loading stage3.0.fuse_layers.2.0.0.1.bias from pretrained model\n","=> loading stage3.0.fuse_layers.2.0.0.1.running_mean from pretrained model\n","=> loading stage3.0.fuse_layers.2.0.0.1.running_var from pretrained model\n","=> loading stage3.0.fuse_layers.2.0.0.1.num_batches_tracked from pretrained model\n","=> loading stage3.0.fuse_layers.2.0.1.0.weight from pretrained model\n","=> loading stage3.0.fuse_layers.2.0.1.1.weight from pretrained model\n","=> loading stage3.0.fuse_layers.2.0.1.1.bias from pretrained model\n","=> loading stage3.0.fuse_layers.2.0.1.1.running_mean from pretrained model\n","=> loading stage3.0.fuse_layers.2.0.1.1.running_var from pretrained model\n","=> loading stage3.0.fuse_layers.2.0.1.1.num_batches_tracked from pretrained model\n","=> loading stage3.0.fuse_layers.2.1.0.0.weight from pretrained model\n","=> loading stage3.0.fuse_layers.2.1.0.1.weight from pretrained model\n","=> loading stage3.0.fuse_layers.2.1.0.1.bias from pretrained model\n","=> loading stage3.0.fuse_layers.2.1.0.1.running_mean from pretrained model\n","=> loading stage3.0.fuse_layers.2.1.0.1.running_var from pretrained model\n","=> loading stage3.0.fuse_layers.2.1.0.1.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.0.0.conv1.weight from pretrained model\n","=> loading stage3.1.branches.0.0.bn1.weight from pretrained model\n","=> loading stage3.1.branches.0.0.bn1.bias from pretrained model\n","=> loading stage3.1.branches.0.0.bn1.running_mean from pretrained model\n","=> loading stage3.1.branches.0.0.bn1.running_var from pretrained model\n","=> loading stage3.1.branches.0.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.0.0.conv2.weight from pretrained model\n","=> loading stage3.1.branches.0.0.bn2.weight from pretrained model\n","=> loading stage3.1.branches.0.0.bn2.bias from pretrained model\n","=> loading stage3.1.branches.0.0.bn2.running_mean from pretrained model\n","=> loading stage3.1.branches.0.0.bn2.running_var from pretrained model\n","=> loading stage3.1.branches.0.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.0.1.conv1.weight from pretrained model\n","=> loading stage3.1.branches.0.1.bn1.weight from pretrained model\n","=> loading stage3.1.branches.0.1.bn1.bias from pretrained model\n","=> loading stage3.1.branches.0.1.bn1.running_mean from pretrained model\n","=> loading stage3.1.branches.0.1.bn1.running_var from pretrained model\n","=> loading stage3.1.branches.0.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.0.1.conv2.weight from pretrained model\n","=> loading stage3.1.branches.0.1.bn2.weight from pretrained model\n","=> loading stage3.1.branches.0.1.bn2.bias from pretrained model\n","=> loading stage3.1.branches.0.1.bn2.running_mean from pretrained model\n","=> loading stage3.1.branches.0.1.bn2.running_var from pretrained model\n","=> loading stage3.1.branches.0.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.0.2.conv1.weight from pretrained model\n","=> loading stage3.1.branches.0.2.bn1.weight from pretrained model\n","=> loading stage3.1.branches.0.2.bn1.bias from pretrained model\n","=> loading stage3.1.branches.0.2.bn1.running_mean from pretrained model\n","=> loading stage3.1.branches.0.2.bn1.running_var from pretrained model\n","=> loading stage3.1.branches.0.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.0.2.conv2.weight from pretrained model\n","=> loading stage3.1.branches.0.2.bn2.weight from pretrained model\n","=> loading stage3.1.branches.0.2.bn2.bias from pretrained model\n","=> loading stage3.1.branches.0.2.bn2.running_mean from pretrained model\n","=> loading stage3.1.branches.0.2.bn2.running_var from pretrained model\n","=> loading stage3.1.branches.0.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.0.3.conv1.weight from pretrained model\n","=> loading stage3.1.branches.0.3.bn1.weight from pretrained model\n","=> loading stage3.1.branches.0.3.bn1.bias from pretrained model\n","=> loading stage3.1.branches.0.3.bn1.running_mean from pretrained model\n","=> loading stage3.1.branches.0.3.bn1.running_var from pretrained model\n","=> loading stage3.1.branches.0.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.0.3.conv2.weight from pretrained model\n","=> loading stage3.1.branches.0.3.bn2.weight from pretrained model\n","=> loading stage3.1.branches.0.3.bn2.bias from pretrained model\n","=> loading stage3.1.branches.0.3.bn2.running_mean from pretrained model\n","=> loading stage3.1.branches.0.3.bn2.running_var from pretrained model\n","=> loading stage3.1.branches.0.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.1.0.conv1.weight from pretrained model\n","=> loading stage3.1.branches.1.0.bn1.weight from pretrained model\n","=> loading stage3.1.branches.1.0.bn1.bias from pretrained model\n","=> loading stage3.1.branches.1.0.bn1.running_mean from pretrained model\n","=> loading stage3.1.branches.1.0.bn1.running_var from pretrained model\n","=> loading stage3.1.branches.1.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.1.0.conv2.weight from pretrained model\n","=> loading stage3.1.branches.1.0.bn2.weight from pretrained model\n","=> loading stage3.1.branches.1.0.bn2.bias from pretrained model\n","=> loading stage3.1.branches.1.0.bn2.running_mean from pretrained model\n","=> loading stage3.1.branches.1.0.bn2.running_var from pretrained model\n","=> loading stage3.1.branches.1.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.1.1.conv1.weight from pretrained model\n","=> loading stage3.1.branches.1.1.bn1.weight from pretrained model\n","=> loading stage3.1.branches.1.1.bn1.bias from pretrained model\n","=> loading stage3.1.branches.1.1.bn1.running_mean from pretrained model\n","=> loading stage3.1.branches.1.1.bn1.running_var from pretrained model\n","=> loading stage3.1.branches.1.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.1.1.conv2.weight from pretrained model\n","=> loading stage3.1.branches.1.1.bn2.weight from pretrained model\n","=> loading stage3.1.branches.1.1.bn2.bias from pretrained model\n","=> loading stage3.1.branches.1.1.bn2.running_mean from pretrained model\n","=> loading stage3.1.branches.1.1.bn2.running_var from pretrained model\n","=> loading stage3.1.branches.1.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.1.2.conv1.weight from pretrained model\n","=> loading stage3.1.branches.1.2.bn1.weight from pretrained model\n","=> loading stage3.1.branches.1.2.bn1.bias from pretrained model\n","=> loading stage3.1.branches.1.2.bn1.running_mean from pretrained model\n","=> loading stage3.1.branches.1.2.bn1.running_var from pretrained model\n","=> loading stage3.1.branches.1.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.1.2.conv2.weight from pretrained model\n","=> loading stage3.1.branches.1.2.bn2.weight from pretrained model\n","=> loading stage3.1.branches.1.2.bn2.bias from pretrained model\n","=> loading stage3.1.branches.1.2.bn2.running_mean from pretrained model\n","=> loading stage3.1.branches.1.2.bn2.running_var from pretrained model\n","=> loading stage3.1.branches.1.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.1.3.conv1.weight from pretrained model\n","=> loading stage3.1.branches.1.3.bn1.weight from pretrained model\n","=> loading stage3.1.branches.1.3.bn1.bias from pretrained model\n","=> loading stage3.1.branches.1.3.bn1.running_mean from pretrained model\n","=> loading stage3.1.branches.1.3.bn1.running_var from pretrained model\n","=> loading stage3.1.branches.1.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.1.3.conv2.weight from pretrained model\n","=> loading stage3.1.branches.1.3.bn2.weight from pretrained model\n","=> loading stage3.1.branches.1.3.bn2.bias from pretrained model\n","=> loading stage3.1.branches.1.3.bn2.running_mean from pretrained model\n","=> loading stage3.1.branches.1.3.bn2.running_var from pretrained model\n","=> loading stage3.1.branches.1.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.2.0.conv1.weight from pretrained model\n","=> loading stage3.1.branches.2.0.bn1.weight from pretrained model\n","=> loading stage3.1.branches.2.0.bn1.bias from pretrained model\n","=> loading stage3.1.branches.2.0.bn1.running_mean from pretrained model\n","=> loading stage3.1.branches.2.0.bn1.running_var from pretrained model\n","=> loading stage3.1.branches.2.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.2.0.conv2.weight from pretrained model\n","=> loading stage3.1.branches.2.0.bn2.weight from pretrained model\n","=> loading stage3.1.branches.2.0.bn2.bias from pretrained model\n","=> loading stage3.1.branches.2.0.bn2.running_mean from pretrained model\n","=> loading stage3.1.branches.2.0.bn2.running_var from pretrained model\n","=> loading stage3.1.branches.2.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.2.1.conv1.weight from pretrained model\n","=> loading stage3.1.branches.2.1.bn1.weight from pretrained model\n","=> loading stage3.1.branches.2.1.bn1.bias from pretrained model\n","=> loading stage3.1.branches.2.1.bn1.running_mean from pretrained model\n","=> loading stage3.1.branches.2.1.bn1.running_var from pretrained model\n","=> loading stage3.1.branches.2.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.2.1.conv2.weight from pretrained model\n","=> loading stage3.1.branches.2.1.bn2.weight from pretrained model\n","=> loading stage3.1.branches.2.1.bn2.bias from pretrained model\n","=> loading stage3.1.branches.2.1.bn2.running_mean from pretrained model\n","=> loading stage3.1.branches.2.1.bn2.running_var from pretrained model\n","=> loading stage3.1.branches.2.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.2.2.conv1.weight from pretrained model\n","=> loading stage3.1.branches.2.2.bn1.weight from pretrained model\n","=> loading stage3.1.branches.2.2.bn1.bias from pretrained model\n","=> loading stage3.1.branches.2.2.bn1.running_mean from pretrained model\n","=> loading stage3.1.branches.2.2.bn1.running_var from pretrained model\n","=> loading stage3.1.branches.2.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.2.2.conv2.weight from pretrained model\n","=> loading stage3.1.branches.2.2.bn2.weight from pretrained model\n","=> loading stage3.1.branches.2.2.bn2.bias from pretrained model\n","=> loading stage3.1.branches.2.2.bn2.running_mean from pretrained model\n","=> loading stage3.1.branches.2.2.bn2.running_var from pretrained model\n","=> loading stage3.1.branches.2.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.2.3.conv1.weight from pretrained model\n","=> loading stage3.1.branches.2.3.bn1.weight from pretrained model\n","=> loading stage3.1.branches.2.3.bn1.bias from pretrained model\n","=> loading stage3.1.branches.2.3.bn1.running_mean from pretrained model\n","=> loading stage3.1.branches.2.3.bn1.running_var from pretrained model\n","=> loading stage3.1.branches.2.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.1.branches.2.3.conv2.weight from pretrained model\n","=> loading stage3.1.branches.2.3.bn2.weight from pretrained model\n","=> loading stage3.1.branches.2.3.bn2.bias from pretrained model\n","=> loading stage3.1.branches.2.3.bn2.running_mean from pretrained model\n","=> loading stage3.1.branches.2.3.bn2.running_var from pretrained model\n","=> loading stage3.1.branches.2.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.1.fuse_layers.0.1.0.weight from pretrained model\n","=> loading stage3.1.fuse_layers.0.1.1.weight from pretrained model\n","=> loading stage3.1.fuse_layers.0.1.1.bias from pretrained model\n","=> loading stage3.1.fuse_layers.0.1.1.running_mean from pretrained model\n","=> loading stage3.1.fuse_layers.0.1.1.running_var from pretrained model\n","=> loading stage3.1.fuse_layers.0.1.1.num_batches_tracked from pretrained model\n","=> loading stage3.1.fuse_layers.0.2.0.weight from pretrained model\n","=> loading stage3.1.fuse_layers.0.2.1.weight from pretrained model\n","=> loading stage3.1.fuse_layers.0.2.1.bias from pretrained model\n","=> loading stage3.1.fuse_layers.0.2.1.running_mean from pretrained model\n","=> loading stage3.1.fuse_layers.0.2.1.running_var from pretrained model\n","=> loading stage3.1.fuse_layers.0.2.1.num_batches_tracked from pretrained model\n","=> loading stage3.1.fuse_layers.1.0.0.0.weight from pretrained model\n","=> loading stage3.1.fuse_layers.1.0.0.1.weight from pretrained model\n","=> loading stage3.1.fuse_layers.1.0.0.1.bias from pretrained model\n","=> loading stage3.1.fuse_layers.1.0.0.1.running_mean from pretrained model\n","=> loading stage3.1.fuse_layers.1.0.0.1.running_var from pretrained model\n","=> loading stage3.1.fuse_layers.1.0.0.1.num_batches_tracked from pretrained model\n","=> loading stage3.1.fuse_layers.1.2.0.weight from pretrained model\n","=> loading stage3.1.fuse_layers.1.2.1.weight from pretrained model\n","=> loading stage3.1.fuse_layers.1.2.1.bias from pretrained model\n","=> loading stage3.1.fuse_layers.1.2.1.running_mean from pretrained model\n","=> loading stage3.1.fuse_layers.1.2.1.running_var from pretrained model\n","=> loading stage3.1.fuse_layers.1.2.1.num_batches_tracked from pretrained model\n","=> loading stage3.1.fuse_layers.2.0.0.0.weight from pretrained model\n","=> loading stage3.1.fuse_layers.2.0.0.1.weight from pretrained model\n","=> loading stage3.1.fuse_layers.2.0.0.1.bias from pretrained model\n","=> loading stage3.1.fuse_layers.2.0.0.1.running_mean from pretrained model\n","=> loading stage3.1.fuse_layers.2.0.0.1.running_var from pretrained model\n","=> loading stage3.1.fuse_layers.2.0.0.1.num_batches_tracked from pretrained model\n","=> loading stage3.1.fuse_layers.2.0.1.0.weight from pretrained model\n","=> loading stage3.1.fuse_layers.2.0.1.1.weight from pretrained model\n","=> loading stage3.1.fuse_layers.2.0.1.1.bias from pretrained model\n","=> loading stage3.1.fuse_layers.2.0.1.1.running_mean from pretrained model\n","=> loading stage3.1.fuse_layers.2.0.1.1.running_var from pretrained model\n","=> loading stage3.1.fuse_layers.2.0.1.1.num_batches_tracked from pretrained model\n","=> loading stage3.1.fuse_layers.2.1.0.0.weight from pretrained model\n","=> loading stage3.1.fuse_layers.2.1.0.1.weight from pretrained model\n","=> loading stage3.1.fuse_layers.2.1.0.1.bias from pretrained model\n","=> loading stage3.1.fuse_layers.2.1.0.1.running_mean from pretrained model\n","=> loading stage3.1.fuse_layers.2.1.0.1.running_var from pretrained model\n","=> loading stage3.1.fuse_layers.2.1.0.1.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.0.0.conv1.weight from pretrained model\n","=> loading stage3.2.branches.0.0.bn1.weight from pretrained model\n","=> loading stage3.2.branches.0.0.bn1.bias from pretrained model\n","=> loading stage3.2.branches.0.0.bn1.running_mean from pretrained model\n","=> loading stage3.2.branches.0.0.bn1.running_var from pretrained model\n","=> loading stage3.2.branches.0.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.0.0.conv2.weight from pretrained model\n","=> loading stage3.2.branches.0.0.bn2.weight from pretrained model\n","=> loading stage3.2.branches.0.0.bn2.bias from pretrained model\n","=> loading stage3.2.branches.0.0.bn2.running_mean from pretrained model\n","=> loading stage3.2.branches.0.0.bn2.running_var from pretrained model\n","=> loading stage3.2.branches.0.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.0.1.conv1.weight from pretrained model\n","=> loading stage3.2.branches.0.1.bn1.weight from pretrained model\n","=> loading stage3.2.branches.0.1.bn1.bias from pretrained model\n","=> loading stage3.2.branches.0.1.bn1.running_mean from pretrained model\n","=> loading stage3.2.branches.0.1.bn1.running_var from pretrained model\n","=> loading stage3.2.branches.0.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.0.1.conv2.weight from pretrained model\n","=> loading stage3.2.branches.0.1.bn2.weight from pretrained model\n","=> loading stage3.2.branches.0.1.bn2.bias from pretrained model\n","=> loading stage3.2.branches.0.1.bn2.running_mean from pretrained model\n","=> loading stage3.2.branches.0.1.bn2.running_var from pretrained model\n","=> loading stage3.2.branches.0.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.0.2.conv1.weight from pretrained model\n","=> loading stage3.2.branches.0.2.bn1.weight from pretrained model\n","=> loading stage3.2.branches.0.2.bn1.bias from pretrained model\n","=> loading stage3.2.branches.0.2.bn1.running_mean from pretrained model\n","=> loading stage3.2.branches.0.2.bn1.running_var from pretrained model\n","=> loading stage3.2.branches.0.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.0.2.conv2.weight from pretrained model\n","=> loading stage3.2.branches.0.2.bn2.weight from pretrained model\n","=> loading stage3.2.branches.0.2.bn2.bias from pretrained model\n","=> loading stage3.2.branches.0.2.bn2.running_mean from pretrained model\n","=> loading stage3.2.branches.0.2.bn2.running_var from pretrained model\n","=> loading stage3.2.branches.0.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.0.3.conv1.weight from pretrained model\n","=> loading stage3.2.branches.0.3.bn1.weight from pretrained model\n","=> loading stage3.2.branches.0.3.bn1.bias from pretrained model\n","=> loading stage3.2.branches.0.3.bn1.running_mean from pretrained model\n","=> loading stage3.2.branches.0.3.bn1.running_var from pretrained model\n","=> loading stage3.2.branches.0.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.0.3.conv2.weight from pretrained model\n","=> loading stage3.2.branches.0.3.bn2.weight from pretrained model\n","=> loading stage3.2.branches.0.3.bn2.bias from pretrained model\n","=> loading stage3.2.branches.0.3.bn2.running_mean from pretrained model\n","=> loading stage3.2.branches.0.3.bn2.running_var from pretrained model\n","=> loading stage3.2.branches.0.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.1.0.conv1.weight from pretrained model\n","=> loading stage3.2.branches.1.0.bn1.weight from pretrained model\n","=> loading stage3.2.branches.1.0.bn1.bias from pretrained model\n","=> loading stage3.2.branches.1.0.bn1.running_mean from pretrained model\n","=> loading stage3.2.branches.1.0.bn1.running_var from pretrained model\n","=> loading stage3.2.branches.1.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.1.0.conv2.weight from pretrained model\n","=> loading stage3.2.branches.1.0.bn2.weight from pretrained model\n","=> loading stage3.2.branches.1.0.bn2.bias from pretrained model\n","=> loading stage3.2.branches.1.0.bn2.running_mean from pretrained model\n","=> loading stage3.2.branches.1.0.bn2.running_var from pretrained model\n","=> loading stage3.2.branches.1.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.1.1.conv1.weight from pretrained model\n","=> loading stage3.2.branches.1.1.bn1.weight from pretrained model\n","=> loading stage3.2.branches.1.1.bn1.bias from pretrained model\n","=> loading stage3.2.branches.1.1.bn1.running_mean from pretrained model\n","=> loading stage3.2.branches.1.1.bn1.running_var from pretrained model\n","=> loading stage3.2.branches.1.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.1.1.conv2.weight from pretrained model\n","=> loading stage3.2.branches.1.1.bn2.weight from pretrained model\n","=> loading stage3.2.branches.1.1.bn2.bias from pretrained model\n","=> loading stage3.2.branches.1.1.bn2.running_mean from pretrained model\n","=> loading stage3.2.branches.1.1.bn2.running_var from pretrained model\n","=> loading stage3.2.branches.1.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.1.2.conv1.weight from pretrained model\n","=> loading stage3.2.branches.1.2.bn1.weight from pretrained model\n","=> loading stage3.2.branches.1.2.bn1.bias from pretrained model\n","=> loading stage3.2.branches.1.2.bn1.running_mean from pretrained model\n","=> loading stage3.2.branches.1.2.bn1.running_var from pretrained model\n","=> loading stage3.2.branches.1.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.1.2.conv2.weight from pretrained model\n","=> loading stage3.2.branches.1.2.bn2.weight from pretrained model\n","=> loading stage3.2.branches.1.2.bn2.bias from pretrained model\n","=> loading stage3.2.branches.1.2.bn2.running_mean from pretrained model\n","=> loading stage3.2.branches.1.2.bn2.running_var from pretrained model\n","=> loading stage3.2.branches.1.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.1.3.conv1.weight from pretrained model\n","=> loading stage3.2.branches.1.3.bn1.weight from pretrained model\n","=> loading stage3.2.branches.1.3.bn1.bias from pretrained model\n","=> loading stage3.2.branches.1.3.bn1.running_mean from pretrained model\n","=> loading stage3.2.branches.1.3.bn1.running_var from pretrained model\n","=> loading stage3.2.branches.1.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.1.3.conv2.weight from pretrained model\n","=> loading stage3.2.branches.1.3.bn2.weight from pretrained model\n","=> loading stage3.2.branches.1.3.bn2.bias from pretrained model\n","=> loading stage3.2.branches.1.3.bn2.running_mean from pretrained model\n","=> loading stage3.2.branches.1.3.bn2.running_var from pretrained model\n","=> loading stage3.2.branches.1.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.2.0.conv1.weight from pretrained model\n","=> loading stage3.2.branches.2.0.bn1.weight from pretrained model\n","=> loading stage3.2.branches.2.0.bn1.bias from pretrained model\n","=> loading stage3.2.branches.2.0.bn1.running_mean from pretrained model\n","=> loading stage3.2.branches.2.0.bn1.running_var from pretrained model\n","=> loading stage3.2.branches.2.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.2.0.conv2.weight from pretrained model\n","=> loading stage3.2.branches.2.0.bn2.weight from pretrained model\n","=> loading stage3.2.branches.2.0.bn2.bias from pretrained model\n","=> loading stage3.2.branches.2.0.bn2.running_mean from pretrained model\n","=> loading stage3.2.branches.2.0.bn2.running_var from pretrained model\n","=> loading stage3.2.branches.2.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.2.1.conv1.weight from pretrained model\n","=> loading stage3.2.branches.2.1.bn1.weight from pretrained model\n","=> loading stage3.2.branches.2.1.bn1.bias from pretrained model\n","=> loading stage3.2.branches.2.1.bn1.running_mean from pretrained model\n","=> loading stage3.2.branches.2.1.bn1.running_var from pretrained model\n","=> loading stage3.2.branches.2.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.2.1.conv2.weight from pretrained model\n","=> loading stage3.2.branches.2.1.bn2.weight from pretrained model\n","=> loading stage3.2.branches.2.1.bn2.bias from pretrained model\n","=> loading stage3.2.branches.2.1.bn2.running_mean from pretrained model\n","=> loading stage3.2.branches.2.1.bn2.running_var from pretrained model\n","=> loading stage3.2.branches.2.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.2.2.conv1.weight from pretrained model\n","=> loading stage3.2.branches.2.2.bn1.weight from pretrained model\n","=> loading stage3.2.branches.2.2.bn1.bias from pretrained model\n","=> loading stage3.2.branches.2.2.bn1.running_mean from pretrained model\n","=> loading stage3.2.branches.2.2.bn1.running_var from pretrained model\n","=> loading stage3.2.branches.2.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.2.2.conv2.weight from pretrained model\n","=> loading stage3.2.branches.2.2.bn2.weight from pretrained model\n","=> loading stage3.2.branches.2.2.bn2.bias from pretrained model\n","=> loading stage3.2.branches.2.2.bn2.running_mean from pretrained model\n","=> loading stage3.2.branches.2.2.bn2.running_var from pretrained model\n","=> loading stage3.2.branches.2.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.2.3.conv1.weight from pretrained model\n","=> loading stage3.2.branches.2.3.bn1.weight from pretrained model\n","=> loading stage3.2.branches.2.3.bn1.bias from pretrained model\n","=> loading stage3.2.branches.2.3.bn1.running_mean from pretrained model\n","=> loading stage3.2.branches.2.3.bn1.running_var from pretrained model\n","=> loading stage3.2.branches.2.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.2.branches.2.3.conv2.weight from pretrained model\n","=> loading stage3.2.branches.2.3.bn2.weight from pretrained model\n","=> loading stage3.2.branches.2.3.bn2.bias from pretrained model\n","=> loading stage3.2.branches.2.3.bn2.running_mean from pretrained model\n","=> loading stage3.2.branches.2.3.bn2.running_var from pretrained model\n","=> loading stage3.2.branches.2.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.2.fuse_layers.0.1.0.weight from pretrained model\n","=> loading stage3.2.fuse_layers.0.1.1.weight from pretrained model\n","=> loading stage3.2.fuse_layers.0.1.1.bias from pretrained model\n","=> loading stage3.2.fuse_layers.0.1.1.running_mean from pretrained model\n","=> loading stage3.2.fuse_layers.0.1.1.running_var from pretrained model\n","=> loading stage3.2.fuse_layers.0.1.1.num_batches_tracked from pretrained model\n","=> loading stage3.2.fuse_layers.0.2.0.weight from pretrained model\n","=> loading stage3.2.fuse_layers.0.2.1.weight from pretrained model\n","=> loading stage3.2.fuse_layers.0.2.1.bias from pretrained model\n","=> loading stage3.2.fuse_layers.0.2.1.running_mean from pretrained model\n","=> loading stage3.2.fuse_layers.0.2.1.running_var from pretrained model\n","=> loading stage3.2.fuse_layers.0.2.1.num_batches_tracked from pretrained model\n","=> loading stage3.2.fuse_layers.1.0.0.0.weight from pretrained model\n","=> loading stage3.2.fuse_layers.1.0.0.1.weight from pretrained model\n","=> loading stage3.2.fuse_layers.1.0.0.1.bias from pretrained model\n","=> loading stage3.2.fuse_layers.1.0.0.1.running_mean from pretrained model\n","=> loading stage3.2.fuse_layers.1.0.0.1.running_var from pretrained model\n","=> loading stage3.2.fuse_layers.1.0.0.1.num_batches_tracked from pretrained model\n","=> loading stage3.2.fuse_layers.1.2.0.weight from pretrained model\n","=> loading stage3.2.fuse_layers.1.2.1.weight from pretrained model\n","=> loading stage3.2.fuse_layers.1.2.1.bias from pretrained model\n","=> loading stage3.2.fuse_layers.1.2.1.running_mean from pretrained model\n","=> loading stage3.2.fuse_layers.1.2.1.running_var from pretrained model\n","=> loading stage3.2.fuse_layers.1.2.1.num_batches_tracked from pretrained model\n","=> loading stage3.2.fuse_layers.2.0.0.0.weight from pretrained model\n","=> loading stage3.2.fuse_layers.2.0.0.1.weight from pretrained model\n","=> loading stage3.2.fuse_layers.2.0.0.1.bias from pretrained model\n","=> loading stage3.2.fuse_layers.2.0.0.1.running_mean from pretrained model\n","=> loading stage3.2.fuse_layers.2.0.0.1.running_var from pretrained model\n","=> loading stage3.2.fuse_layers.2.0.0.1.num_batches_tracked from pretrained model\n","=> loading stage3.2.fuse_layers.2.0.1.0.weight from pretrained model\n","=> loading stage3.2.fuse_layers.2.0.1.1.weight from pretrained model\n","=> loading stage3.2.fuse_layers.2.0.1.1.bias from pretrained model\n","=> loading stage3.2.fuse_layers.2.0.1.1.running_mean from pretrained model\n","=> loading stage3.2.fuse_layers.2.0.1.1.running_var from pretrained model\n","=> loading stage3.2.fuse_layers.2.0.1.1.num_batches_tracked from pretrained model\n","=> loading stage3.2.fuse_layers.2.1.0.0.weight from pretrained model\n","=> loading stage3.2.fuse_layers.2.1.0.1.weight from pretrained model\n","=> loading stage3.2.fuse_layers.2.1.0.1.bias from pretrained model\n","=> loading stage3.2.fuse_layers.2.1.0.1.running_mean from pretrained model\n","=> loading stage3.2.fuse_layers.2.1.0.1.running_var from pretrained model\n","=> loading stage3.2.fuse_layers.2.1.0.1.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.0.0.conv1.weight from pretrained model\n","=> loading stage3.3.branches.0.0.bn1.weight from pretrained model\n","=> loading stage3.3.branches.0.0.bn1.bias from pretrained model\n","=> loading stage3.3.branches.0.0.bn1.running_mean from pretrained model\n","=> loading stage3.3.branches.0.0.bn1.running_var from pretrained model\n","=> loading stage3.3.branches.0.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.0.0.conv2.weight from pretrained model\n","=> loading stage3.3.branches.0.0.bn2.weight from pretrained model\n","=> loading stage3.3.branches.0.0.bn2.bias from pretrained model\n","=> loading stage3.3.branches.0.0.bn2.running_mean from pretrained model\n","=> loading stage3.3.branches.0.0.bn2.running_var from pretrained model\n","=> loading stage3.3.branches.0.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.0.1.conv1.weight from pretrained model\n","=> loading stage3.3.branches.0.1.bn1.weight from pretrained model\n","=> loading stage3.3.branches.0.1.bn1.bias from pretrained model\n","=> loading stage3.3.branches.0.1.bn1.running_mean from pretrained model\n","=> loading stage3.3.branches.0.1.bn1.running_var from pretrained model\n","=> loading stage3.3.branches.0.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.0.1.conv2.weight from pretrained model\n","=> loading stage3.3.branches.0.1.bn2.weight from pretrained model\n","=> loading stage3.3.branches.0.1.bn2.bias from pretrained model\n","=> loading stage3.3.branches.0.1.bn2.running_mean from pretrained model\n","=> loading stage3.3.branches.0.1.bn2.running_var from pretrained model\n","=> loading stage3.3.branches.0.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.0.2.conv1.weight from pretrained model\n","=> loading stage3.3.branches.0.2.bn1.weight from pretrained model\n","=> loading stage3.3.branches.0.2.bn1.bias from pretrained model\n","=> loading stage3.3.branches.0.2.bn1.running_mean from pretrained model\n","=> loading stage3.3.branches.0.2.bn1.running_var from pretrained model\n","=> loading stage3.3.branches.0.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.0.2.conv2.weight from pretrained model\n","=> loading stage3.3.branches.0.2.bn2.weight from pretrained model\n","=> loading stage3.3.branches.0.2.bn2.bias from pretrained model\n","=> loading stage3.3.branches.0.2.bn2.running_mean from pretrained model\n","=> loading stage3.3.branches.0.2.bn2.running_var from pretrained model\n","=> loading stage3.3.branches.0.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.0.3.conv1.weight from pretrained model\n","=> loading stage3.3.branches.0.3.bn1.weight from pretrained model\n","=> loading stage3.3.branches.0.3.bn1.bias from pretrained model\n","=> loading stage3.3.branches.0.3.bn1.running_mean from pretrained model\n","=> loading stage3.3.branches.0.3.bn1.running_var from pretrained model\n","=> loading stage3.3.branches.0.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.0.3.conv2.weight from pretrained model\n","=> loading stage3.3.branches.0.3.bn2.weight from pretrained model\n","=> loading stage3.3.branches.0.3.bn2.bias from pretrained model\n","=> loading stage3.3.branches.0.3.bn2.running_mean from pretrained model\n","=> loading stage3.3.branches.0.3.bn2.running_var from pretrained model\n","=> loading stage3.3.branches.0.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.1.0.conv1.weight from pretrained model\n","=> loading stage3.3.branches.1.0.bn1.weight from pretrained model\n","=> loading stage3.3.branches.1.0.bn1.bias from pretrained model\n","=> loading stage3.3.branches.1.0.bn1.running_mean from pretrained model\n","=> loading stage3.3.branches.1.0.bn1.running_var from pretrained model\n","=> loading stage3.3.branches.1.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.1.0.conv2.weight from pretrained model\n","=> loading stage3.3.branches.1.0.bn2.weight from pretrained model\n","=> loading stage3.3.branches.1.0.bn2.bias from pretrained model\n","=> loading stage3.3.branches.1.0.bn2.running_mean from pretrained model\n","=> loading stage3.3.branches.1.0.bn2.running_var from pretrained model\n","=> loading stage3.3.branches.1.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.1.1.conv1.weight from pretrained model\n","=> loading stage3.3.branches.1.1.bn1.weight from pretrained model\n","=> loading stage3.3.branches.1.1.bn1.bias from pretrained model\n","=> loading stage3.3.branches.1.1.bn1.running_mean from pretrained model\n","=> loading stage3.3.branches.1.1.bn1.running_var from pretrained model\n","=> loading stage3.3.branches.1.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.1.1.conv2.weight from pretrained model\n","=> loading stage3.3.branches.1.1.bn2.weight from pretrained model\n","=> loading stage3.3.branches.1.1.bn2.bias from pretrained model\n","=> loading stage3.3.branches.1.1.bn2.running_mean from pretrained model\n","=> loading stage3.3.branches.1.1.bn2.running_var from pretrained model\n","=> loading stage3.3.branches.1.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.1.2.conv1.weight from pretrained model\n","=> loading stage3.3.branches.1.2.bn1.weight from pretrained model\n","=> loading stage3.3.branches.1.2.bn1.bias from pretrained model\n","=> loading stage3.3.branches.1.2.bn1.running_mean from pretrained model\n","=> loading stage3.3.branches.1.2.bn1.running_var from pretrained model\n","=> loading stage3.3.branches.1.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.1.2.conv2.weight from pretrained model\n","=> loading stage3.3.branches.1.2.bn2.weight from pretrained model\n","=> loading stage3.3.branches.1.2.bn2.bias from pretrained model\n","=> loading stage3.3.branches.1.2.bn2.running_mean from pretrained model\n","=> loading stage3.3.branches.1.2.bn2.running_var from pretrained model\n","=> loading stage3.3.branches.1.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.1.3.conv1.weight from pretrained model\n","=> loading stage3.3.branches.1.3.bn1.weight from pretrained model\n","=> loading stage3.3.branches.1.3.bn1.bias from pretrained model\n","=> loading stage3.3.branches.1.3.bn1.running_mean from pretrained model\n","=> loading stage3.3.branches.1.3.bn1.running_var from pretrained model\n","=> loading stage3.3.branches.1.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.1.3.conv2.weight from pretrained model\n","=> loading stage3.3.branches.1.3.bn2.weight from pretrained model\n","=> loading stage3.3.branches.1.3.bn2.bias from pretrained model\n","=> loading stage3.3.branches.1.3.bn2.running_mean from pretrained model\n","=> loading stage3.3.branches.1.3.bn2.running_var from pretrained model\n","=> loading stage3.3.branches.1.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.2.0.conv1.weight from pretrained model\n","=> loading stage3.3.branches.2.0.bn1.weight from pretrained model\n","=> loading stage3.3.branches.2.0.bn1.bias from pretrained model\n","=> loading stage3.3.branches.2.0.bn1.running_mean from pretrained model\n","=> loading stage3.3.branches.2.0.bn1.running_var from pretrained model\n","=> loading stage3.3.branches.2.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.2.0.conv2.weight from pretrained model\n","=> loading stage3.3.branches.2.0.bn2.weight from pretrained model\n","=> loading stage3.3.branches.2.0.bn2.bias from pretrained model\n","=> loading stage3.3.branches.2.0.bn2.running_mean from pretrained model\n","=> loading stage3.3.branches.2.0.bn2.running_var from pretrained model\n","=> loading stage3.3.branches.2.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.2.1.conv1.weight from pretrained model\n","=> loading stage3.3.branches.2.1.bn1.weight from pretrained model\n","=> loading stage3.3.branches.2.1.bn1.bias from pretrained model\n","=> loading stage3.3.branches.2.1.bn1.running_mean from pretrained model\n","=> loading stage3.3.branches.2.1.bn1.running_var from pretrained model\n","=> loading stage3.3.branches.2.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.2.1.conv2.weight from pretrained model\n","=> loading stage3.3.branches.2.1.bn2.weight from pretrained model\n","=> loading stage3.3.branches.2.1.bn2.bias from pretrained model\n","=> loading stage3.3.branches.2.1.bn2.running_mean from pretrained model\n","=> loading stage3.3.branches.2.1.bn2.running_var from pretrained model\n","=> loading stage3.3.branches.2.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.2.2.conv1.weight from pretrained model\n","=> loading stage3.3.branches.2.2.bn1.weight from pretrained model\n","=> loading stage3.3.branches.2.2.bn1.bias from pretrained model\n","=> loading stage3.3.branches.2.2.bn1.running_mean from pretrained model\n","=> loading stage3.3.branches.2.2.bn1.running_var from pretrained model\n","=> loading stage3.3.branches.2.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.2.2.conv2.weight from pretrained model\n","=> loading stage3.3.branches.2.2.bn2.weight from pretrained model\n","=> loading stage3.3.branches.2.2.bn2.bias from pretrained model\n","=> loading stage3.3.branches.2.2.bn2.running_mean from pretrained model\n","=> loading stage3.3.branches.2.2.bn2.running_var from pretrained model\n","=> loading stage3.3.branches.2.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.2.3.conv1.weight from pretrained model\n","=> loading stage3.3.branches.2.3.bn1.weight from pretrained model\n","=> loading stage3.3.branches.2.3.bn1.bias from pretrained model\n","=> loading stage3.3.branches.2.3.bn1.running_mean from pretrained model\n","=> loading stage3.3.branches.2.3.bn1.running_var from pretrained model\n","=> loading stage3.3.branches.2.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage3.3.branches.2.3.conv2.weight from pretrained model\n","=> loading stage3.3.branches.2.3.bn2.weight from pretrained model\n","=> loading stage3.3.branches.2.3.bn2.bias from pretrained model\n","=> loading stage3.3.branches.2.3.bn2.running_mean from pretrained model\n","=> loading stage3.3.branches.2.3.bn2.running_var from pretrained model\n","=> loading stage3.3.branches.2.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage3.3.fuse_layers.0.1.0.weight from pretrained model\n","=> loading stage3.3.fuse_layers.0.1.1.weight from pretrained model\n","=> loading stage3.3.fuse_layers.0.1.1.bias from pretrained model\n","=> loading stage3.3.fuse_layers.0.1.1.running_mean from pretrained model\n","=> loading stage3.3.fuse_layers.0.1.1.running_var from pretrained model\n","=> loading stage3.3.fuse_layers.0.1.1.num_batches_tracked from pretrained model\n","=> loading stage3.3.fuse_layers.0.2.0.weight from pretrained model\n","=> loading stage3.3.fuse_layers.0.2.1.weight from pretrained model\n","=> loading stage3.3.fuse_layers.0.2.1.bias from pretrained model\n","=> loading stage3.3.fuse_layers.0.2.1.running_mean from pretrained model\n","=> loading stage3.3.fuse_layers.0.2.1.running_var from pretrained model\n","=> loading stage3.3.fuse_layers.0.2.1.num_batches_tracked from pretrained model\n","=> loading stage3.3.fuse_layers.1.0.0.0.weight from pretrained model\n","=> loading stage3.3.fuse_layers.1.0.0.1.weight from pretrained model\n","=> loading stage3.3.fuse_layers.1.0.0.1.bias from pretrained model\n","=> loading stage3.3.fuse_layers.1.0.0.1.running_mean from pretrained model\n","=> loading stage3.3.fuse_layers.1.0.0.1.running_var from pretrained model\n","=> loading stage3.3.fuse_layers.1.0.0.1.num_batches_tracked from pretrained model\n","=> loading stage3.3.fuse_layers.1.2.0.weight from pretrained model\n","=> loading stage3.3.fuse_layers.1.2.1.weight from pretrained model\n","=> loading stage3.3.fuse_layers.1.2.1.bias from pretrained model\n","=> loading stage3.3.fuse_layers.1.2.1.running_mean from pretrained model\n","=> loading stage3.3.fuse_layers.1.2.1.running_var from pretrained model\n","=> loading stage3.3.fuse_layers.1.2.1.num_batches_tracked from pretrained model\n","=> loading stage3.3.fuse_layers.2.0.0.0.weight from pretrained model\n","=> loading stage3.3.fuse_layers.2.0.0.1.weight from pretrained model\n","=> loading stage3.3.fuse_layers.2.0.0.1.bias from pretrained model\n","=> loading stage3.3.fuse_layers.2.0.0.1.running_mean from pretrained model\n","=> loading stage3.3.fuse_layers.2.0.0.1.running_var from pretrained model\n","=> loading stage3.3.fuse_layers.2.0.0.1.num_batches_tracked from pretrained model\n","=> loading stage3.3.fuse_layers.2.0.1.0.weight from pretrained model\n","=> loading stage3.3.fuse_layers.2.0.1.1.weight from pretrained model\n","=> loading stage3.3.fuse_layers.2.0.1.1.bias from pretrained model\n","=> loading stage3.3.fuse_layers.2.0.1.1.running_mean from pretrained model\n","=> loading stage3.3.fuse_layers.2.0.1.1.running_var from pretrained model\n","=> loading stage3.3.fuse_layers.2.0.1.1.num_batches_tracked from pretrained model\n","=> loading stage3.3.fuse_layers.2.1.0.0.weight from pretrained model\n","=> loading stage3.3.fuse_layers.2.1.0.1.weight from pretrained model\n","=> loading stage3.3.fuse_layers.2.1.0.1.bias from pretrained model\n","=> loading stage3.3.fuse_layers.2.1.0.1.running_mean from pretrained model\n","=> loading stage3.3.fuse_layers.2.1.0.1.running_var from pretrained model\n","=> loading stage3.3.fuse_layers.2.1.0.1.num_batches_tracked from pretrained model\n","=> loading transition3.3.0.0.weight from pretrained model\n","=> loading transition3.3.0.1.weight from pretrained model\n","=> loading transition3.3.0.1.bias from pretrained model\n","=> loading transition3.3.0.1.running_mean from pretrained model\n","=> loading transition3.3.0.1.running_var from pretrained model\n","=> loading transition3.3.0.1.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.0.0.conv1.weight from pretrained model\n","=> loading stage4.0.branches.0.0.bn1.weight from pretrained model\n","=> loading stage4.0.branches.0.0.bn1.bias from pretrained model\n","=> loading stage4.0.branches.0.0.bn1.running_mean from pretrained model\n","=> loading stage4.0.branches.0.0.bn1.running_var from pretrained model\n","=> loading stage4.0.branches.0.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.0.0.conv2.weight from pretrained model\n","=> loading stage4.0.branches.0.0.bn2.weight from pretrained model\n","=> loading stage4.0.branches.0.0.bn2.bias from pretrained model\n","=> loading stage4.0.branches.0.0.bn2.running_mean from pretrained model\n","=> loading stage4.0.branches.0.0.bn2.running_var from pretrained model\n","=> loading stage4.0.branches.0.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.0.1.conv1.weight from pretrained model\n","=> loading stage4.0.branches.0.1.bn1.weight from pretrained model\n","=> loading stage4.0.branches.0.1.bn1.bias from pretrained model\n","=> loading stage4.0.branches.0.1.bn1.running_mean from pretrained model\n","=> loading stage4.0.branches.0.1.bn1.running_var from pretrained model\n","=> loading stage4.0.branches.0.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.0.1.conv2.weight from pretrained model\n","=> loading stage4.0.branches.0.1.bn2.weight from pretrained model\n","=> loading stage4.0.branches.0.1.bn2.bias from pretrained model\n","=> loading stage4.0.branches.0.1.bn2.running_mean from pretrained model\n","=> loading stage4.0.branches.0.1.bn2.running_var from pretrained model\n","=> loading stage4.0.branches.0.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.0.2.conv1.weight from pretrained model\n","=> loading stage4.0.branches.0.2.bn1.weight from pretrained model\n","=> loading stage4.0.branches.0.2.bn1.bias from pretrained model\n","=> loading stage4.0.branches.0.2.bn1.running_mean from pretrained model\n","=> loading stage4.0.branches.0.2.bn1.running_var from pretrained model\n","=> loading stage4.0.branches.0.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.0.2.conv2.weight from pretrained model\n","=> loading stage4.0.branches.0.2.bn2.weight from pretrained model\n","=> loading stage4.0.branches.0.2.bn2.bias from pretrained model\n","=> loading stage4.0.branches.0.2.bn2.running_mean from pretrained model\n","=> loading stage4.0.branches.0.2.bn2.running_var from pretrained model\n","=> loading stage4.0.branches.0.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.0.3.conv1.weight from pretrained model\n","=> loading stage4.0.branches.0.3.bn1.weight from pretrained model\n","=> loading stage4.0.branches.0.3.bn1.bias from pretrained model\n","=> loading stage4.0.branches.0.3.bn1.running_mean from pretrained model\n","=> loading stage4.0.branches.0.3.bn1.running_var from pretrained model\n","=> loading stage4.0.branches.0.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.0.3.conv2.weight from pretrained model\n","=> loading stage4.0.branches.0.3.bn2.weight from pretrained model\n","=> loading stage4.0.branches.0.3.bn2.bias from pretrained model\n","=> loading stage4.0.branches.0.3.bn2.running_mean from pretrained model\n","=> loading stage4.0.branches.0.3.bn2.running_var from pretrained model\n","=> loading stage4.0.branches.0.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.1.0.conv1.weight from pretrained model\n","=> loading stage4.0.branches.1.0.bn1.weight from pretrained model\n","=> loading stage4.0.branches.1.0.bn1.bias from pretrained model\n","=> loading stage4.0.branches.1.0.bn1.running_mean from pretrained model\n","=> loading stage4.0.branches.1.0.bn1.running_var from pretrained model\n","=> loading stage4.0.branches.1.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.1.0.conv2.weight from pretrained model\n","=> loading stage4.0.branches.1.0.bn2.weight from pretrained model\n","=> loading stage4.0.branches.1.0.bn2.bias from pretrained model\n","=> loading stage4.0.branches.1.0.bn2.running_mean from pretrained model\n","=> loading stage4.0.branches.1.0.bn2.running_var from pretrained model\n","=> loading stage4.0.branches.1.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.1.1.conv1.weight from pretrained model\n","=> loading stage4.0.branches.1.1.bn1.weight from pretrained model\n","=> loading stage4.0.branches.1.1.bn1.bias from pretrained model\n","=> loading stage4.0.branches.1.1.bn1.running_mean from pretrained model\n","=> loading stage4.0.branches.1.1.bn1.running_var from pretrained model\n","=> loading stage4.0.branches.1.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.1.1.conv2.weight from pretrained model\n","=> loading stage4.0.branches.1.1.bn2.weight from pretrained model\n","=> loading stage4.0.branches.1.1.bn2.bias from pretrained model\n","=> loading stage4.0.branches.1.1.bn2.running_mean from pretrained model\n","=> loading stage4.0.branches.1.1.bn2.running_var from pretrained model\n","=> loading stage4.0.branches.1.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.1.2.conv1.weight from pretrained model\n","=> loading stage4.0.branches.1.2.bn1.weight from pretrained model\n","=> loading stage4.0.branches.1.2.bn1.bias from pretrained model\n","=> loading stage4.0.branches.1.2.bn1.running_mean from pretrained model\n","=> loading stage4.0.branches.1.2.bn1.running_var from pretrained model\n","=> loading stage4.0.branches.1.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.1.2.conv2.weight from pretrained model\n","=> loading stage4.0.branches.1.2.bn2.weight from pretrained model\n","=> loading stage4.0.branches.1.2.bn2.bias from pretrained model\n","=> loading stage4.0.branches.1.2.bn2.running_mean from pretrained model\n","=> loading stage4.0.branches.1.2.bn2.running_var from pretrained model\n","=> loading stage4.0.branches.1.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.1.3.conv1.weight from pretrained model\n","=> loading stage4.0.branches.1.3.bn1.weight from pretrained model\n","=> loading stage4.0.branches.1.3.bn1.bias from pretrained model\n","=> loading stage4.0.branches.1.3.bn1.running_mean from pretrained model\n","=> loading stage4.0.branches.1.3.bn1.running_var from pretrained model\n","=> loading stage4.0.branches.1.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.1.3.conv2.weight from pretrained model\n","=> loading stage4.0.branches.1.3.bn2.weight from pretrained model\n","=> loading stage4.0.branches.1.3.bn2.bias from pretrained model\n","=> loading stage4.0.branches.1.3.bn2.running_mean from pretrained model\n","=> loading stage4.0.branches.1.3.bn2.running_var from pretrained model\n","=> loading stage4.0.branches.1.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.2.0.conv1.weight from pretrained model\n","=> loading stage4.0.branches.2.0.bn1.weight from pretrained model\n","=> loading stage4.0.branches.2.0.bn1.bias from pretrained model\n","=> loading stage4.0.branches.2.0.bn1.running_mean from pretrained model\n","=> loading stage4.0.branches.2.0.bn1.running_var from pretrained model\n","=> loading stage4.0.branches.2.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.2.0.conv2.weight from pretrained model\n","=> loading stage4.0.branches.2.0.bn2.weight from pretrained model\n","=> loading stage4.0.branches.2.0.bn2.bias from pretrained model\n","=> loading stage4.0.branches.2.0.bn2.running_mean from pretrained model\n","=> loading stage4.0.branches.2.0.bn2.running_var from pretrained model\n","=> loading stage4.0.branches.2.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.2.1.conv1.weight from pretrained model\n","=> loading stage4.0.branches.2.1.bn1.weight from pretrained model\n","=> loading stage4.0.branches.2.1.bn1.bias from pretrained model\n","=> loading stage4.0.branches.2.1.bn1.running_mean from pretrained model\n","=> loading stage4.0.branches.2.1.bn1.running_var from pretrained model\n","=> loading stage4.0.branches.2.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.2.1.conv2.weight from pretrained model\n","=> loading stage4.0.branches.2.1.bn2.weight from pretrained model\n","=> loading stage4.0.branches.2.1.bn2.bias from pretrained model\n","=> loading stage4.0.branches.2.1.bn2.running_mean from pretrained model\n","=> loading stage4.0.branches.2.1.bn2.running_var from pretrained model\n","=> loading stage4.0.branches.2.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.2.2.conv1.weight from pretrained model\n","=> loading stage4.0.branches.2.2.bn1.weight from pretrained model\n","=> loading stage4.0.branches.2.2.bn1.bias from pretrained model\n","=> loading stage4.0.branches.2.2.bn1.running_mean from pretrained model\n","=> loading stage4.0.branches.2.2.bn1.running_var from pretrained model\n","=> loading stage4.0.branches.2.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.2.2.conv2.weight from pretrained model\n","=> loading stage4.0.branches.2.2.bn2.weight from pretrained model\n","=> loading stage4.0.branches.2.2.bn2.bias from pretrained model\n","=> loading stage4.0.branches.2.2.bn2.running_mean from pretrained model\n","=> loading stage4.0.branches.2.2.bn2.running_var from pretrained model\n","=> loading stage4.0.branches.2.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.2.3.conv1.weight from pretrained model\n","=> loading stage4.0.branches.2.3.bn1.weight from pretrained model\n","=> loading stage4.0.branches.2.3.bn1.bias from pretrained model\n","=> loading stage4.0.branches.2.3.bn1.running_mean from pretrained model\n","=> loading stage4.0.branches.2.3.bn1.running_var from pretrained model\n","=> loading stage4.0.branches.2.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.2.3.conv2.weight from pretrained model\n","=> loading stage4.0.branches.2.3.bn2.weight from pretrained model\n","=> loading stage4.0.branches.2.3.bn2.bias from pretrained model\n","=> loading stage4.0.branches.2.3.bn2.running_mean from pretrained model\n","=> loading stage4.0.branches.2.3.bn2.running_var from pretrained model\n","=> loading stage4.0.branches.2.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.3.0.conv1.weight from pretrained model\n","=> loading stage4.0.branches.3.0.bn1.weight from pretrained model\n","=> loading stage4.0.branches.3.0.bn1.bias from pretrained model\n","=> loading stage4.0.branches.3.0.bn1.running_mean from pretrained model\n","=> loading stage4.0.branches.3.0.bn1.running_var from pretrained model\n","=> loading stage4.0.branches.3.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.3.0.conv2.weight from pretrained model\n","=> loading stage4.0.branches.3.0.bn2.weight from pretrained model\n","=> loading stage4.0.branches.3.0.bn2.bias from pretrained model\n","=> loading stage4.0.branches.3.0.bn2.running_mean from pretrained model\n","=> loading stage4.0.branches.3.0.bn2.running_var from pretrained model\n","=> loading stage4.0.branches.3.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.3.1.conv1.weight from pretrained model\n","=> loading stage4.0.branches.3.1.bn1.weight from pretrained model\n","=> loading stage4.0.branches.3.1.bn1.bias from pretrained model\n","=> loading stage4.0.branches.3.1.bn1.running_mean from pretrained model\n","=> loading stage4.0.branches.3.1.bn1.running_var from pretrained model\n","=> loading stage4.0.branches.3.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.3.1.conv2.weight from pretrained model\n","=> loading stage4.0.branches.3.1.bn2.weight from pretrained model\n","=> loading stage4.0.branches.3.1.bn2.bias from pretrained model\n","=> loading stage4.0.branches.3.1.bn2.running_mean from pretrained model\n","=> loading stage4.0.branches.3.1.bn2.running_var from pretrained model\n","=> loading stage4.0.branches.3.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.3.2.conv1.weight from pretrained model\n","=> loading stage4.0.branches.3.2.bn1.weight from pretrained model\n","=> loading stage4.0.branches.3.2.bn1.bias from pretrained model\n","=> loading stage4.0.branches.3.2.bn1.running_mean from pretrained model\n","=> loading stage4.0.branches.3.2.bn1.running_var from pretrained model\n","=> loading stage4.0.branches.3.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.3.2.conv2.weight from pretrained model\n","=> loading stage4.0.branches.3.2.bn2.weight from pretrained model\n","=> loading stage4.0.branches.3.2.bn2.bias from pretrained model\n","=> loading stage4.0.branches.3.2.bn2.running_mean from pretrained model\n","=> loading stage4.0.branches.3.2.bn2.running_var from pretrained model\n","=> loading stage4.0.branches.3.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.3.3.conv1.weight from pretrained model\n","=> loading stage4.0.branches.3.3.bn1.weight from pretrained model\n","=> loading stage4.0.branches.3.3.bn1.bias from pretrained model\n","=> loading stage4.0.branches.3.3.bn1.running_mean from pretrained model\n","=> loading stage4.0.branches.3.3.bn1.running_var from pretrained model\n","=> loading stage4.0.branches.3.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.0.branches.3.3.conv2.weight from pretrained model\n","=> loading stage4.0.branches.3.3.bn2.weight from pretrained model\n","=> loading stage4.0.branches.3.3.bn2.bias from pretrained model\n","=> loading stage4.0.branches.3.3.bn2.running_mean from pretrained model\n","=> loading stage4.0.branches.3.3.bn2.running_var from pretrained model\n","=> loading stage4.0.branches.3.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.0.fuse_layers.0.1.0.weight from pretrained model\n","=> loading stage4.0.fuse_layers.0.1.1.weight from pretrained model\n","=> loading stage4.0.fuse_layers.0.1.1.bias from pretrained model\n","=> loading stage4.0.fuse_layers.0.1.1.running_mean from pretrained model\n","=> loading stage4.0.fuse_layers.0.1.1.running_var from pretrained model\n","=> loading stage4.0.fuse_layers.0.1.1.num_batches_tracked from pretrained model\n","=> loading stage4.0.fuse_layers.0.2.0.weight from pretrained model\n","=> loading stage4.0.fuse_layers.0.2.1.weight from pretrained model\n","=> loading stage4.0.fuse_layers.0.2.1.bias from pretrained model\n","=> loading stage4.0.fuse_layers.0.2.1.running_mean from pretrained model\n","=> loading stage4.0.fuse_layers.0.2.1.running_var from pretrained model\n","=> loading stage4.0.fuse_layers.0.2.1.num_batches_tracked from pretrained model\n","=> loading stage4.0.fuse_layers.0.3.0.weight from pretrained model\n","=> loading stage4.0.fuse_layers.0.3.1.weight from pretrained model\n","=> loading stage4.0.fuse_layers.0.3.1.bias from pretrained model\n","=> loading stage4.0.fuse_layers.0.3.1.running_mean from pretrained model\n","=> loading stage4.0.fuse_layers.0.3.1.running_var from pretrained model\n","=> loading stage4.0.fuse_layers.0.3.1.num_batches_tracked from pretrained model\n","=> loading stage4.0.fuse_layers.1.0.0.0.weight from pretrained model\n","=> loading stage4.0.fuse_layers.1.0.0.1.weight from pretrained model\n","=> loading stage4.0.fuse_layers.1.0.0.1.bias from pretrained model\n","=> loading stage4.0.fuse_layers.1.0.0.1.running_mean from pretrained model\n","=> loading stage4.0.fuse_layers.1.0.0.1.running_var from pretrained model\n","=> loading stage4.0.fuse_layers.1.0.0.1.num_batches_tracked from pretrained model\n","=> loading stage4.0.fuse_layers.1.2.0.weight from pretrained model\n","=> loading stage4.0.fuse_layers.1.2.1.weight from pretrained model\n","=> loading stage4.0.fuse_layers.1.2.1.bias from pretrained model\n","=> loading stage4.0.fuse_layers.1.2.1.running_mean from pretrained model\n","=> loading stage4.0.fuse_layers.1.2.1.running_var from pretrained model\n","=> loading stage4.0.fuse_layers.1.2.1.num_batches_tracked from pretrained model\n","=> loading stage4.0.fuse_layers.1.3.0.weight from pretrained model\n","=> loading stage4.0.fuse_layers.1.3.1.weight from pretrained model\n","=> loading stage4.0.fuse_layers.1.3.1.bias from pretrained model\n","=> loading stage4.0.fuse_layers.1.3.1.running_mean from pretrained model\n","=> loading stage4.0.fuse_layers.1.3.1.running_var from pretrained model\n","=> loading stage4.0.fuse_layers.1.3.1.num_batches_tracked from pretrained model\n","=> loading stage4.0.fuse_layers.2.0.0.0.weight from pretrained model\n","=> loading stage4.0.fuse_layers.2.0.0.1.weight from pretrained model\n","=> loading stage4.0.fuse_layers.2.0.0.1.bias from pretrained model\n","=> loading stage4.0.fuse_layers.2.0.0.1.running_mean from pretrained model\n","=> loading stage4.0.fuse_layers.2.0.0.1.running_var from pretrained model\n","=> loading stage4.0.fuse_layers.2.0.0.1.num_batches_tracked from pretrained model\n","=> loading stage4.0.fuse_layers.2.0.1.0.weight from pretrained model\n","=> loading stage4.0.fuse_layers.2.0.1.1.weight from pretrained model\n","=> loading stage4.0.fuse_layers.2.0.1.1.bias from pretrained model\n","=> loading stage4.0.fuse_layers.2.0.1.1.running_mean from pretrained model\n","=> loading stage4.0.fuse_layers.2.0.1.1.running_var from pretrained model\n","=> loading stage4.0.fuse_layers.2.0.1.1.num_batches_tracked from pretrained model\n","=> loading stage4.0.fuse_layers.2.1.0.0.weight from pretrained model\n","=> loading stage4.0.fuse_layers.2.1.0.1.weight from pretrained model\n","=> loading stage4.0.fuse_layers.2.1.0.1.bias from pretrained model\n","=> loading stage4.0.fuse_layers.2.1.0.1.running_mean from pretrained model\n","=> loading stage4.0.fuse_layers.2.1.0.1.running_var from pretrained model\n","=> loading stage4.0.fuse_layers.2.1.0.1.num_batches_tracked from pretrained model\n","=> loading stage4.0.fuse_layers.2.3.0.weight from pretrained model\n","=> loading stage4.0.fuse_layers.2.3.1.weight from pretrained model\n","=> loading stage4.0.fuse_layers.2.3.1.bias from pretrained model\n","=> loading stage4.0.fuse_layers.2.3.1.running_mean from pretrained model\n","=> loading stage4.0.fuse_layers.2.3.1.running_var from pretrained model\n","=> loading stage4.0.fuse_layers.2.3.1.num_batches_tracked from pretrained model\n","=> loading stage4.0.fuse_layers.3.0.0.0.weight from pretrained model\n","=> loading stage4.0.fuse_layers.3.0.0.1.weight from pretrained model\n","=> loading stage4.0.fuse_layers.3.0.0.1.bias from pretrained model\n","=> loading stage4.0.fuse_layers.3.0.0.1.running_mean from pretrained model\n","=> loading stage4.0.fuse_layers.3.0.0.1.running_var from pretrained model\n","=> loading stage4.0.fuse_layers.3.0.0.1.num_batches_tracked from pretrained model\n","=> loading stage4.0.fuse_layers.3.0.1.0.weight from pretrained model\n","=> loading stage4.0.fuse_layers.3.0.1.1.weight from pretrained model\n","=> loading stage4.0.fuse_layers.3.0.1.1.bias from pretrained model\n","=> loading stage4.0.fuse_layers.3.0.1.1.running_mean from pretrained model\n","=> loading stage4.0.fuse_layers.3.0.1.1.running_var from pretrained model\n","=> loading stage4.0.fuse_layers.3.0.1.1.num_batches_tracked from pretrained model\n","=> loading stage4.0.fuse_layers.3.0.2.0.weight from pretrained model\n","=> loading stage4.0.fuse_layers.3.0.2.1.weight from pretrained model\n","=> loading stage4.0.fuse_layers.3.0.2.1.bias from pretrained model\n","=> loading stage4.0.fuse_layers.3.0.2.1.running_mean from pretrained model\n","=> loading stage4.0.fuse_layers.3.0.2.1.running_var from pretrained model\n","=> loading stage4.0.fuse_layers.3.0.2.1.num_batches_tracked from pretrained model\n","=> loading stage4.0.fuse_layers.3.1.0.0.weight from pretrained model\n","=> loading stage4.0.fuse_layers.3.1.0.1.weight from pretrained model\n","=> loading stage4.0.fuse_layers.3.1.0.1.bias from pretrained model\n","=> loading stage4.0.fuse_layers.3.1.0.1.running_mean from pretrained model\n","=> loading stage4.0.fuse_layers.3.1.0.1.running_var from pretrained model\n","=> loading stage4.0.fuse_layers.3.1.0.1.num_batches_tracked from pretrained model\n","=> loading stage4.0.fuse_layers.3.1.1.0.weight from pretrained model\n","=> loading stage4.0.fuse_layers.3.1.1.1.weight from pretrained model\n","=> loading stage4.0.fuse_layers.3.1.1.1.bias from pretrained model\n","=> loading stage4.0.fuse_layers.3.1.1.1.running_mean from pretrained model\n","=> loading stage4.0.fuse_layers.3.1.1.1.running_var from pretrained model\n","=> loading stage4.0.fuse_layers.3.1.1.1.num_batches_tracked from pretrained model\n","=> loading stage4.0.fuse_layers.3.2.0.0.weight from pretrained model\n","=> loading stage4.0.fuse_layers.3.2.0.1.weight from pretrained model\n","=> loading stage4.0.fuse_layers.3.2.0.1.bias from pretrained model\n","=> loading stage4.0.fuse_layers.3.2.0.1.running_mean from pretrained model\n","=> loading stage4.0.fuse_layers.3.2.0.1.running_var from pretrained model\n","=> loading stage4.0.fuse_layers.3.2.0.1.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.0.0.conv1.weight from pretrained model\n","=> loading stage4.1.branches.0.0.bn1.weight from pretrained model\n","=> loading stage4.1.branches.0.0.bn1.bias from pretrained model\n","=> loading stage4.1.branches.0.0.bn1.running_mean from pretrained model\n","=> loading stage4.1.branches.0.0.bn1.running_var from pretrained model\n","=> loading stage4.1.branches.0.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.0.0.conv2.weight from pretrained model\n","=> loading stage4.1.branches.0.0.bn2.weight from pretrained model\n","=> loading stage4.1.branches.0.0.bn2.bias from pretrained model\n","=> loading stage4.1.branches.0.0.bn2.running_mean from pretrained model\n","=> loading stage4.1.branches.0.0.bn2.running_var from pretrained model\n","=> loading stage4.1.branches.0.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.0.1.conv1.weight from pretrained model\n","=> loading stage4.1.branches.0.1.bn1.weight from pretrained model\n","=> loading stage4.1.branches.0.1.bn1.bias from pretrained model\n","=> loading stage4.1.branches.0.1.bn1.running_mean from pretrained model\n","=> loading stage4.1.branches.0.1.bn1.running_var from pretrained model\n","=> loading stage4.1.branches.0.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.0.1.conv2.weight from pretrained model\n","=> loading stage4.1.branches.0.1.bn2.weight from pretrained model\n","=> loading stage4.1.branches.0.1.bn2.bias from pretrained model\n","=> loading stage4.1.branches.0.1.bn2.running_mean from pretrained model\n","=> loading stage4.1.branches.0.1.bn2.running_var from pretrained model\n","=> loading stage4.1.branches.0.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.0.2.conv1.weight from pretrained model\n","=> loading stage4.1.branches.0.2.bn1.weight from pretrained model\n","=> loading stage4.1.branches.0.2.bn1.bias from pretrained model\n","=> loading stage4.1.branches.0.2.bn1.running_mean from pretrained model\n","=> loading stage4.1.branches.0.2.bn1.running_var from pretrained model\n","=> loading stage4.1.branches.0.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.0.2.conv2.weight from pretrained model\n","=> loading stage4.1.branches.0.2.bn2.weight from pretrained model\n","=> loading stage4.1.branches.0.2.bn2.bias from pretrained model\n","=> loading stage4.1.branches.0.2.bn2.running_mean from pretrained model\n","=> loading stage4.1.branches.0.2.bn2.running_var from pretrained model\n","=> loading stage4.1.branches.0.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.0.3.conv1.weight from pretrained model\n","=> loading stage4.1.branches.0.3.bn1.weight from pretrained model\n","=> loading stage4.1.branches.0.3.bn1.bias from pretrained model\n","=> loading stage4.1.branches.0.3.bn1.running_mean from pretrained model\n","=> loading stage4.1.branches.0.3.bn1.running_var from pretrained model\n","=> loading stage4.1.branches.0.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.0.3.conv2.weight from pretrained model\n","=> loading stage4.1.branches.0.3.bn2.weight from pretrained model\n","=> loading stage4.1.branches.0.3.bn2.bias from pretrained model\n","=> loading stage4.1.branches.0.3.bn2.running_mean from pretrained model\n","=> loading stage4.1.branches.0.3.bn2.running_var from pretrained model\n","=> loading stage4.1.branches.0.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.1.0.conv1.weight from pretrained model\n","=> loading stage4.1.branches.1.0.bn1.weight from pretrained model\n","=> loading stage4.1.branches.1.0.bn1.bias from pretrained model\n","=> loading stage4.1.branches.1.0.bn1.running_mean from pretrained model\n","=> loading stage4.1.branches.1.0.bn1.running_var from pretrained model\n","=> loading stage4.1.branches.1.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.1.0.conv2.weight from pretrained model\n","=> loading stage4.1.branches.1.0.bn2.weight from pretrained model\n","=> loading stage4.1.branches.1.0.bn2.bias from pretrained model\n","=> loading stage4.1.branches.1.0.bn2.running_mean from pretrained model\n","=> loading stage4.1.branches.1.0.bn2.running_var from pretrained model\n","=> loading stage4.1.branches.1.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.1.1.conv1.weight from pretrained model\n","=> loading stage4.1.branches.1.1.bn1.weight from pretrained model\n","=> loading stage4.1.branches.1.1.bn1.bias from pretrained model\n","=> loading stage4.1.branches.1.1.bn1.running_mean from pretrained model\n","=> loading stage4.1.branches.1.1.bn1.running_var from pretrained model\n","=> loading stage4.1.branches.1.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.1.1.conv2.weight from pretrained model\n","=> loading stage4.1.branches.1.1.bn2.weight from pretrained model\n","=> loading stage4.1.branches.1.1.bn2.bias from pretrained model\n","=> loading stage4.1.branches.1.1.bn2.running_mean from pretrained model\n","=> loading stage4.1.branches.1.1.bn2.running_var from pretrained model\n","=> loading stage4.1.branches.1.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.1.2.conv1.weight from pretrained model\n","=> loading stage4.1.branches.1.2.bn1.weight from pretrained model\n","=> loading stage4.1.branches.1.2.bn1.bias from pretrained model\n","=> loading stage4.1.branches.1.2.bn1.running_mean from pretrained model\n","=> loading stage4.1.branches.1.2.bn1.running_var from pretrained model\n","=> loading stage4.1.branches.1.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.1.2.conv2.weight from pretrained model\n","=> loading stage4.1.branches.1.2.bn2.weight from pretrained model\n","=> loading stage4.1.branches.1.2.bn2.bias from pretrained model\n","=> loading stage4.1.branches.1.2.bn2.running_mean from pretrained model\n","=> loading stage4.1.branches.1.2.bn2.running_var from pretrained model\n","=> loading stage4.1.branches.1.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.1.3.conv1.weight from pretrained model\n","=> loading stage4.1.branches.1.3.bn1.weight from pretrained model\n","=> loading stage4.1.branches.1.3.bn1.bias from pretrained model\n","=> loading stage4.1.branches.1.3.bn1.running_mean from pretrained model\n","=> loading stage4.1.branches.1.3.bn1.running_var from pretrained model\n","=> loading stage4.1.branches.1.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.1.3.conv2.weight from pretrained model\n","=> loading stage4.1.branches.1.3.bn2.weight from pretrained model\n","=> loading stage4.1.branches.1.3.bn2.bias from pretrained model\n","=> loading stage4.1.branches.1.3.bn2.running_mean from pretrained model\n","=> loading stage4.1.branches.1.3.bn2.running_var from pretrained model\n","=> loading stage4.1.branches.1.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.2.0.conv1.weight from pretrained model\n","=> loading stage4.1.branches.2.0.bn1.weight from pretrained model\n","=> loading stage4.1.branches.2.0.bn1.bias from pretrained model\n","=> loading stage4.1.branches.2.0.bn1.running_mean from pretrained model\n","=> loading stage4.1.branches.2.0.bn1.running_var from pretrained model\n","=> loading stage4.1.branches.2.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.2.0.conv2.weight from pretrained model\n","=> loading stage4.1.branches.2.0.bn2.weight from pretrained model\n","=> loading stage4.1.branches.2.0.bn2.bias from pretrained model\n","=> loading stage4.1.branches.2.0.bn2.running_mean from pretrained model\n","=> loading stage4.1.branches.2.0.bn2.running_var from pretrained model\n","=> loading stage4.1.branches.2.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.2.1.conv1.weight from pretrained model\n","=> loading stage4.1.branches.2.1.bn1.weight from pretrained model\n","=> loading stage4.1.branches.2.1.bn1.bias from pretrained model\n","=> loading stage4.1.branches.2.1.bn1.running_mean from pretrained model\n","=> loading stage4.1.branches.2.1.bn1.running_var from pretrained model\n","=> loading stage4.1.branches.2.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.2.1.conv2.weight from pretrained model\n","=> loading stage4.1.branches.2.1.bn2.weight from pretrained model\n","=> loading stage4.1.branches.2.1.bn2.bias from pretrained model\n","=> loading stage4.1.branches.2.1.bn2.running_mean from pretrained model\n","=> loading stage4.1.branches.2.1.bn2.running_var from pretrained model\n","=> loading stage4.1.branches.2.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.2.2.conv1.weight from pretrained model\n","=> loading stage4.1.branches.2.2.bn1.weight from pretrained model\n","=> loading stage4.1.branches.2.2.bn1.bias from pretrained model\n","=> loading stage4.1.branches.2.2.bn1.running_mean from pretrained model\n","=> loading stage4.1.branches.2.2.bn1.running_var from pretrained model\n","=> loading stage4.1.branches.2.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.2.2.conv2.weight from pretrained model\n","=> loading stage4.1.branches.2.2.bn2.weight from pretrained model\n","=> loading stage4.1.branches.2.2.bn2.bias from pretrained model\n","=> loading stage4.1.branches.2.2.bn2.running_mean from pretrained model\n","=> loading stage4.1.branches.2.2.bn2.running_var from pretrained model\n","=> loading stage4.1.branches.2.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.2.3.conv1.weight from pretrained model\n","=> loading stage4.1.branches.2.3.bn1.weight from pretrained model\n","=> loading stage4.1.branches.2.3.bn1.bias from pretrained model\n","=> loading stage4.1.branches.2.3.bn1.running_mean from pretrained model\n","=> loading stage4.1.branches.2.3.bn1.running_var from pretrained model\n","=> loading stage4.1.branches.2.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.2.3.conv2.weight from pretrained model\n","=> loading stage4.1.branches.2.3.bn2.weight from pretrained model\n","=> loading stage4.1.branches.2.3.bn2.bias from pretrained model\n","=> loading stage4.1.branches.2.3.bn2.running_mean from pretrained model\n","=> loading stage4.1.branches.2.3.bn2.running_var from pretrained model\n","=> loading stage4.1.branches.2.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.3.0.conv1.weight from pretrained model\n","=> loading stage4.1.branches.3.0.bn1.weight from pretrained model\n","=> loading stage4.1.branches.3.0.bn1.bias from pretrained model\n","=> loading stage4.1.branches.3.0.bn1.running_mean from pretrained model\n","=> loading stage4.1.branches.3.0.bn1.running_var from pretrained model\n","=> loading stage4.1.branches.3.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.3.0.conv2.weight from pretrained model\n","=> loading stage4.1.branches.3.0.bn2.weight from pretrained model\n","=> loading stage4.1.branches.3.0.bn2.bias from pretrained model\n","=> loading stage4.1.branches.3.0.bn2.running_mean from pretrained model\n","=> loading stage4.1.branches.3.0.bn2.running_var from pretrained model\n","=> loading stage4.1.branches.3.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.3.1.conv1.weight from pretrained model\n","=> loading stage4.1.branches.3.1.bn1.weight from pretrained model\n","=> loading stage4.1.branches.3.1.bn1.bias from pretrained model\n","=> loading stage4.1.branches.3.1.bn1.running_mean from pretrained model\n","=> loading stage4.1.branches.3.1.bn1.running_var from pretrained model\n","=> loading stage4.1.branches.3.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.3.1.conv2.weight from pretrained model\n","=> loading stage4.1.branches.3.1.bn2.weight from pretrained model\n","=> loading stage4.1.branches.3.1.bn2.bias from pretrained model\n","=> loading stage4.1.branches.3.1.bn2.running_mean from pretrained model\n","=> loading stage4.1.branches.3.1.bn2.running_var from pretrained model\n","=> loading stage4.1.branches.3.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.3.2.conv1.weight from pretrained model\n","=> loading stage4.1.branches.3.2.bn1.weight from pretrained model\n","=> loading stage4.1.branches.3.2.bn1.bias from pretrained model\n","=> loading stage4.1.branches.3.2.bn1.running_mean from pretrained model\n","=> loading stage4.1.branches.3.2.bn1.running_var from pretrained model\n","=> loading stage4.1.branches.3.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.3.2.conv2.weight from pretrained model\n","=> loading stage4.1.branches.3.2.bn2.weight from pretrained model\n","=> loading stage4.1.branches.3.2.bn2.bias from pretrained model\n","=> loading stage4.1.branches.3.2.bn2.running_mean from pretrained model\n","=> loading stage4.1.branches.3.2.bn2.running_var from pretrained model\n","=> loading stage4.1.branches.3.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.3.3.conv1.weight from pretrained model\n","=> loading stage4.1.branches.3.3.bn1.weight from pretrained model\n","=> loading stage4.1.branches.3.3.bn1.bias from pretrained model\n","=> loading stage4.1.branches.3.3.bn1.running_mean from pretrained model\n","=> loading stage4.1.branches.3.3.bn1.running_var from pretrained model\n","=> loading stage4.1.branches.3.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.1.branches.3.3.conv2.weight from pretrained model\n","=> loading stage4.1.branches.3.3.bn2.weight from pretrained model\n","=> loading stage4.1.branches.3.3.bn2.bias from pretrained model\n","=> loading stage4.1.branches.3.3.bn2.running_mean from pretrained model\n","=> loading stage4.1.branches.3.3.bn2.running_var from pretrained model\n","=> loading stage4.1.branches.3.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.1.fuse_layers.0.1.0.weight from pretrained model\n","=> loading stage4.1.fuse_layers.0.1.1.weight from pretrained model\n","=> loading stage4.1.fuse_layers.0.1.1.bias from pretrained model\n","=> loading stage4.1.fuse_layers.0.1.1.running_mean from pretrained model\n","=> loading stage4.1.fuse_layers.0.1.1.running_var from pretrained model\n","=> loading stage4.1.fuse_layers.0.1.1.num_batches_tracked from pretrained model\n","=> loading stage4.1.fuse_layers.0.2.0.weight from pretrained model\n","=> loading stage4.1.fuse_layers.0.2.1.weight from pretrained model\n","=> loading stage4.1.fuse_layers.0.2.1.bias from pretrained model\n","=> loading stage4.1.fuse_layers.0.2.1.running_mean from pretrained model\n","=> loading stage4.1.fuse_layers.0.2.1.running_var from pretrained model\n","=> loading stage4.1.fuse_layers.0.2.1.num_batches_tracked from pretrained model\n","=> loading stage4.1.fuse_layers.0.3.0.weight from pretrained model\n","=> loading stage4.1.fuse_layers.0.3.1.weight from pretrained model\n","=> loading stage4.1.fuse_layers.0.3.1.bias from pretrained model\n","=> loading stage4.1.fuse_layers.0.3.1.running_mean from pretrained model\n","=> loading stage4.1.fuse_layers.0.3.1.running_var from pretrained model\n","=> loading stage4.1.fuse_layers.0.3.1.num_batches_tracked from pretrained model\n","=> loading stage4.1.fuse_layers.1.0.0.0.weight from pretrained model\n","=> loading stage4.1.fuse_layers.1.0.0.1.weight from pretrained model\n","=> loading stage4.1.fuse_layers.1.0.0.1.bias from pretrained model\n","=> loading stage4.1.fuse_layers.1.0.0.1.running_mean from pretrained model\n","=> loading stage4.1.fuse_layers.1.0.0.1.running_var from pretrained model\n","=> loading stage4.1.fuse_layers.1.0.0.1.num_batches_tracked from pretrained model\n","=> loading stage4.1.fuse_layers.1.2.0.weight from pretrained model\n","=> loading stage4.1.fuse_layers.1.2.1.weight from pretrained model\n","=> loading stage4.1.fuse_layers.1.2.1.bias from pretrained model\n","=> loading stage4.1.fuse_layers.1.2.1.running_mean from pretrained model\n","=> loading stage4.1.fuse_layers.1.2.1.running_var from pretrained model\n","=> loading stage4.1.fuse_layers.1.2.1.num_batches_tracked from pretrained model\n","=> loading stage4.1.fuse_layers.1.3.0.weight from pretrained model\n","=> loading stage4.1.fuse_layers.1.3.1.weight from pretrained model\n","=> loading stage4.1.fuse_layers.1.3.1.bias from pretrained model\n","=> loading stage4.1.fuse_layers.1.3.1.running_mean from pretrained model\n","=> loading stage4.1.fuse_layers.1.3.1.running_var from pretrained model\n","=> loading stage4.1.fuse_layers.1.3.1.num_batches_tracked from pretrained model\n","=> loading stage4.1.fuse_layers.2.0.0.0.weight from pretrained model\n","=> loading stage4.1.fuse_layers.2.0.0.1.weight from pretrained model\n","=> loading stage4.1.fuse_layers.2.0.0.1.bias from pretrained model\n","=> loading stage4.1.fuse_layers.2.0.0.1.running_mean from pretrained model\n","=> loading stage4.1.fuse_layers.2.0.0.1.running_var from pretrained model\n","=> loading stage4.1.fuse_layers.2.0.0.1.num_batches_tracked from pretrained model\n","=> loading stage4.1.fuse_layers.2.0.1.0.weight from pretrained model\n","=> loading stage4.1.fuse_layers.2.0.1.1.weight from pretrained model\n","=> loading stage4.1.fuse_layers.2.0.1.1.bias from pretrained model\n","=> loading stage4.1.fuse_layers.2.0.1.1.running_mean from pretrained model\n","=> loading stage4.1.fuse_layers.2.0.1.1.running_var from pretrained model\n","=> loading stage4.1.fuse_layers.2.0.1.1.num_batches_tracked from pretrained model\n","=> loading stage4.1.fuse_layers.2.1.0.0.weight from pretrained model\n","=> loading stage4.1.fuse_layers.2.1.0.1.weight from pretrained model\n","=> loading stage4.1.fuse_layers.2.1.0.1.bias from pretrained model\n","=> loading stage4.1.fuse_layers.2.1.0.1.running_mean from pretrained model\n","=> loading stage4.1.fuse_layers.2.1.0.1.running_var from pretrained model\n","=> loading stage4.1.fuse_layers.2.1.0.1.num_batches_tracked from pretrained model\n","=> loading stage4.1.fuse_layers.2.3.0.weight from pretrained model\n","=> loading stage4.1.fuse_layers.2.3.1.weight from pretrained model\n","=> loading stage4.1.fuse_layers.2.3.1.bias from pretrained model\n","=> loading stage4.1.fuse_layers.2.3.1.running_mean from pretrained model\n","=> loading stage4.1.fuse_layers.2.3.1.running_var from pretrained model\n","=> loading stage4.1.fuse_layers.2.3.1.num_batches_tracked from pretrained model\n","=> loading stage4.1.fuse_layers.3.0.0.0.weight from pretrained model\n","=> loading stage4.1.fuse_layers.3.0.0.1.weight from pretrained model\n","=> loading stage4.1.fuse_layers.3.0.0.1.bias from pretrained model\n","=> loading stage4.1.fuse_layers.3.0.0.1.running_mean from pretrained model\n","=> loading stage4.1.fuse_layers.3.0.0.1.running_var from pretrained model\n","=> loading stage4.1.fuse_layers.3.0.0.1.num_batches_tracked from pretrained model\n","=> loading stage4.1.fuse_layers.3.0.1.0.weight from pretrained model\n","=> loading stage4.1.fuse_layers.3.0.1.1.weight from pretrained model\n","=> loading stage4.1.fuse_layers.3.0.1.1.bias from pretrained model\n","=> loading stage4.1.fuse_layers.3.0.1.1.running_mean from pretrained model\n","=> loading stage4.1.fuse_layers.3.0.1.1.running_var from pretrained model\n","=> loading stage4.1.fuse_layers.3.0.1.1.num_batches_tracked from pretrained model\n","=> loading stage4.1.fuse_layers.3.0.2.0.weight from pretrained model\n","=> loading stage4.1.fuse_layers.3.0.2.1.weight from pretrained model\n","=> loading stage4.1.fuse_layers.3.0.2.1.bias from pretrained model\n","=> loading stage4.1.fuse_layers.3.0.2.1.running_mean from pretrained model\n","=> loading stage4.1.fuse_layers.3.0.2.1.running_var from pretrained model\n","=> loading stage4.1.fuse_layers.3.0.2.1.num_batches_tracked from pretrained model\n","=> loading stage4.1.fuse_layers.3.1.0.0.weight from pretrained model\n","=> loading stage4.1.fuse_layers.3.1.0.1.weight from pretrained model\n","=> loading stage4.1.fuse_layers.3.1.0.1.bias from pretrained model\n","=> loading stage4.1.fuse_layers.3.1.0.1.running_mean from pretrained model\n","=> loading stage4.1.fuse_layers.3.1.0.1.running_var from pretrained model\n","=> loading stage4.1.fuse_layers.3.1.0.1.num_batches_tracked from pretrained model\n","=> loading stage4.1.fuse_layers.3.1.1.0.weight from pretrained model\n","=> loading stage4.1.fuse_layers.3.1.1.1.weight from pretrained model\n","=> loading stage4.1.fuse_layers.3.1.1.1.bias from pretrained model\n","=> loading stage4.1.fuse_layers.3.1.1.1.running_mean from pretrained model\n","=> loading stage4.1.fuse_layers.3.1.1.1.running_var from pretrained model\n","=> loading stage4.1.fuse_layers.3.1.1.1.num_batches_tracked from pretrained model\n","=> loading stage4.1.fuse_layers.3.2.0.0.weight from pretrained model\n","=> loading stage4.1.fuse_layers.3.2.0.1.weight from pretrained model\n","=> loading stage4.1.fuse_layers.3.2.0.1.bias from pretrained model\n","=> loading stage4.1.fuse_layers.3.2.0.1.running_mean from pretrained model\n","=> loading stage4.1.fuse_layers.3.2.0.1.running_var from pretrained model\n","=> loading stage4.1.fuse_layers.3.2.0.1.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.0.0.conv1.weight from pretrained model\n","=> loading stage4.2.branches.0.0.bn1.weight from pretrained model\n","=> loading stage4.2.branches.0.0.bn1.bias from pretrained model\n","=> loading stage4.2.branches.0.0.bn1.running_mean from pretrained model\n","=> loading stage4.2.branches.0.0.bn1.running_var from pretrained model\n","=> loading stage4.2.branches.0.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.0.0.conv2.weight from pretrained model\n","=> loading stage4.2.branches.0.0.bn2.weight from pretrained model\n","=> loading stage4.2.branches.0.0.bn2.bias from pretrained model\n","=> loading stage4.2.branches.0.0.bn2.running_mean from pretrained model\n","=> loading stage4.2.branches.0.0.bn2.running_var from pretrained model\n","=> loading stage4.2.branches.0.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.0.1.conv1.weight from pretrained model\n","=> loading stage4.2.branches.0.1.bn1.weight from pretrained model\n","=> loading stage4.2.branches.0.1.bn1.bias from pretrained model\n","=> loading stage4.2.branches.0.1.bn1.running_mean from pretrained model\n","=> loading stage4.2.branches.0.1.bn1.running_var from pretrained model\n","=> loading stage4.2.branches.0.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.0.1.conv2.weight from pretrained model\n","=> loading stage4.2.branches.0.1.bn2.weight from pretrained model\n","=> loading stage4.2.branches.0.1.bn2.bias from pretrained model\n","=> loading stage4.2.branches.0.1.bn2.running_mean from pretrained model\n","=> loading stage4.2.branches.0.1.bn2.running_var from pretrained model\n","=> loading stage4.2.branches.0.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.0.2.conv1.weight from pretrained model\n","=> loading stage4.2.branches.0.2.bn1.weight from pretrained model\n","=> loading stage4.2.branches.0.2.bn1.bias from pretrained model\n","=> loading stage4.2.branches.0.2.bn1.running_mean from pretrained model\n","=> loading stage4.2.branches.0.2.bn1.running_var from pretrained model\n","=> loading stage4.2.branches.0.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.0.2.conv2.weight from pretrained model\n","=> loading stage4.2.branches.0.2.bn2.weight from pretrained model\n","=> loading stage4.2.branches.0.2.bn2.bias from pretrained model\n","=> loading stage4.2.branches.0.2.bn2.running_mean from pretrained model\n","=> loading stage4.2.branches.0.2.bn2.running_var from pretrained model\n","=> loading stage4.2.branches.0.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.0.3.conv1.weight from pretrained model\n","=> loading stage4.2.branches.0.3.bn1.weight from pretrained model\n","=> loading stage4.2.branches.0.3.bn1.bias from pretrained model\n","=> loading stage4.2.branches.0.3.bn1.running_mean from pretrained model\n","=> loading stage4.2.branches.0.3.bn1.running_var from pretrained model\n","=> loading stage4.2.branches.0.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.0.3.conv2.weight from pretrained model\n","=> loading stage4.2.branches.0.3.bn2.weight from pretrained model\n","=> loading stage4.2.branches.0.3.bn2.bias from pretrained model\n","=> loading stage4.2.branches.0.3.bn2.running_mean from pretrained model\n","=> loading stage4.2.branches.0.3.bn2.running_var from pretrained model\n","=> loading stage4.2.branches.0.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.1.0.conv1.weight from pretrained model\n","=> loading stage4.2.branches.1.0.bn1.weight from pretrained model\n","=> loading stage4.2.branches.1.0.bn1.bias from pretrained model\n","=> loading stage4.2.branches.1.0.bn1.running_mean from pretrained model\n","=> loading stage4.2.branches.1.0.bn1.running_var from pretrained model\n","=> loading stage4.2.branches.1.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.1.0.conv2.weight from pretrained model\n","=> loading stage4.2.branches.1.0.bn2.weight from pretrained model\n","=> loading stage4.2.branches.1.0.bn2.bias from pretrained model\n","=> loading stage4.2.branches.1.0.bn2.running_mean from pretrained model\n","=> loading stage4.2.branches.1.0.bn2.running_var from pretrained model\n","=> loading stage4.2.branches.1.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.1.1.conv1.weight from pretrained model\n","=> loading stage4.2.branches.1.1.bn1.weight from pretrained model\n","=> loading stage4.2.branches.1.1.bn1.bias from pretrained model\n","=> loading stage4.2.branches.1.1.bn1.running_mean from pretrained model\n","=> loading stage4.2.branches.1.1.bn1.running_var from pretrained model\n","=> loading stage4.2.branches.1.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.1.1.conv2.weight from pretrained model\n","=> loading stage4.2.branches.1.1.bn2.weight from pretrained model\n","=> loading stage4.2.branches.1.1.bn2.bias from pretrained model\n","=> loading stage4.2.branches.1.1.bn2.running_mean from pretrained model\n","=> loading stage4.2.branches.1.1.bn2.running_var from pretrained model\n","=> loading stage4.2.branches.1.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.1.2.conv1.weight from pretrained model\n","=> loading stage4.2.branches.1.2.bn1.weight from pretrained model\n","=> loading stage4.2.branches.1.2.bn1.bias from pretrained model\n","=> loading stage4.2.branches.1.2.bn1.running_mean from pretrained model\n","=> loading stage4.2.branches.1.2.bn1.running_var from pretrained model\n","=> loading stage4.2.branches.1.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.1.2.conv2.weight from pretrained model\n","=> loading stage4.2.branches.1.2.bn2.weight from pretrained model\n","=> loading stage4.2.branches.1.2.bn2.bias from pretrained model\n","=> loading stage4.2.branches.1.2.bn2.running_mean from pretrained model\n","=> loading stage4.2.branches.1.2.bn2.running_var from pretrained model\n","=> loading stage4.2.branches.1.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.1.3.conv1.weight from pretrained model\n","=> loading stage4.2.branches.1.3.bn1.weight from pretrained model\n","=> loading stage4.2.branches.1.3.bn1.bias from pretrained model\n","=> loading stage4.2.branches.1.3.bn1.running_mean from pretrained model\n","=> loading stage4.2.branches.1.3.bn1.running_var from pretrained model\n","=> loading stage4.2.branches.1.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.1.3.conv2.weight from pretrained model\n","=> loading stage4.2.branches.1.3.bn2.weight from pretrained model\n","=> loading stage4.2.branches.1.3.bn2.bias from pretrained model\n","=> loading stage4.2.branches.1.3.bn2.running_mean from pretrained model\n","=> loading stage4.2.branches.1.3.bn2.running_var from pretrained model\n","=> loading stage4.2.branches.1.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.2.0.conv1.weight from pretrained model\n","=> loading stage4.2.branches.2.0.bn1.weight from pretrained model\n","=> loading stage4.2.branches.2.0.bn1.bias from pretrained model\n","=> loading stage4.2.branches.2.0.bn1.running_mean from pretrained model\n","=> loading stage4.2.branches.2.0.bn1.running_var from pretrained model\n","=> loading stage4.2.branches.2.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.2.0.conv2.weight from pretrained model\n","=> loading stage4.2.branches.2.0.bn2.weight from pretrained model\n","=> loading stage4.2.branches.2.0.bn2.bias from pretrained model\n","=> loading stage4.2.branches.2.0.bn2.running_mean from pretrained model\n","=> loading stage4.2.branches.2.0.bn2.running_var from pretrained model\n","=> loading stage4.2.branches.2.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.2.1.conv1.weight from pretrained model\n","=> loading stage4.2.branches.2.1.bn1.weight from pretrained model\n","=> loading stage4.2.branches.2.1.bn1.bias from pretrained model\n","=> loading stage4.2.branches.2.1.bn1.running_mean from pretrained model\n","=> loading stage4.2.branches.2.1.bn1.running_var from pretrained model\n","=> loading stage4.2.branches.2.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.2.1.conv2.weight from pretrained model\n","=> loading stage4.2.branches.2.1.bn2.weight from pretrained model\n","=> loading stage4.2.branches.2.1.bn2.bias from pretrained model\n","=> loading stage4.2.branches.2.1.bn2.running_mean from pretrained model\n","=> loading stage4.2.branches.2.1.bn2.running_var from pretrained model\n","=> loading stage4.2.branches.2.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.2.2.conv1.weight from pretrained model\n","=> loading stage4.2.branches.2.2.bn1.weight from pretrained model\n","=> loading stage4.2.branches.2.2.bn1.bias from pretrained model\n","=> loading stage4.2.branches.2.2.bn1.running_mean from pretrained model\n","=> loading stage4.2.branches.2.2.bn1.running_var from pretrained model\n","=> loading stage4.2.branches.2.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.2.2.conv2.weight from pretrained model\n","=> loading stage4.2.branches.2.2.bn2.weight from pretrained model\n","=> loading stage4.2.branches.2.2.bn2.bias from pretrained model\n","=> loading stage4.2.branches.2.2.bn2.running_mean from pretrained model\n","=> loading stage4.2.branches.2.2.bn2.running_var from pretrained model\n","=> loading stage4.2.branches.2.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.2.3.conv1.weight from pretrained model\n","=> loading stage4.2.branches.2.3.bn1.weight from pretrained model\n","=> loading stage4.2.branches.2.3.bn1.bias from pretrained model\n","=> loading stage4.2.branches.2.3.bn1.running_mean from pretrained model\n","=> loading stage4.2.branches.2.3.bn1.running_var from pretrained model\n","=> loading stage4.2.branches.2.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.2.3.conv2.weight from pretrained model\n","=> loading stage4.2.branches.2.3.bn2.weight from pretrained model\n","=> loading stage4.2.branches.2.3.bn2.bias from pretrained model\n","=> loading stage4.2.branches.2.3.bn2.running_mean from pretrained model\n","=> loading stage4.2.branches.2.3.bn2.running_var from pretrained model\n","=> loading stage4.2.branches.2.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.3.0.conv1.weight from pretrained model\n","=> loading stage4.2.branches.3.0.bn1.weight from pretrained model\n","=> loading stage4.2.branches.3.0.bn1.bias from pretrained model\n","=> loading stage4.2.branches.3.0.bn1.running_mean from pretrained model\n","=> loading stage4.2.branches.3.0.bn1.running_var from pretrained model\n","=> loading stage4.2.branches.3.0.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.3.0.conv2.weight from pretrained model\n","=> loading stage4.2.branches.3.0.bn2.weight from pretrained model\n","=> loading stage4.2.branches.3.0.bn2.bias from pretrained model\n","=> loading stage4.2.branches.3.0.bn2.running_mean from pretrained model\n","=> loading stage4.2.branches.3.0.bn2.running_var from pretrained model\n","=> loading stage4.2.branches.3.0.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.3.1.conv1.weight from pretrained model\n","=> loading stage4.2.branches.3.1.bn1.weight from pretrained model\n","=> loading stage4.2.branches.3.1.bn1.bias from pretrained model\n","=> loading stage4.2.branches.3.1.bn1.running_mean from pretrained model\n","=> loading stage4.2.branches.3.1.bn1.running_var from pretrained model\n","=> loading stage4.2.branches.3.1.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.3.1.conv2.weight from pretrained model\n","=> loading stage4.2.branches.3.1.bn2.weight from pretrained model\n","=> loading stage4.2.branches.3.1.bn2.bias from pretrained model\n","=> loading stage4.2.branches.3.1.bn2.running_mean from pretrained model\n","=> loading stage4.2.branches.3.1.bn2.running_var from pretrained model\n","=> loading stage4.2.branches.3.1.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.3.2.conv1.weight from pretrained model\n","=> loading stage4.2.branches.3.2.bn1.weight from pretrained model\n","=> loading stage4.2.branches.3.2.bn1.bias from pretrained model\n","=> loading stage4.2.branches.3.2.bn1.running_mean from pretrained model\n","=> loading stage4.2.branches.3.2.bn1.running_var from pretrained model\n","=> loading stage4.2.branches.3.2.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.3.2.conv2.weight from pretrained model\n","=> loading stage4.2.branches.3.2.bn2.weight from pretrained model\n","=> loading stage4.2.branches.3.2.bn2.bias from pretrained model\n","=> loading stage4.2.branches.3.2.bn2.running_mean from pretrained model\n","=> loading stage4.2.branches.3.2.bn2.running_var from pretrained model\n","=> loading stage4.2.branches.3.2.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.3.3.conv1.weight from pretrained model\n","=> loading stage4.2.branches.3.3.bn1.weight from pretrained model\n","=> loading stage4.2.branches.3.3.bn1.bias from pretrained model\n","=> loading stage4.2.branches.3.3.bn1.running_mean from pretrained model\n","=> loading stage4.2.branches.3.3.bn1.running_var from pretrained model\n","=> loading stage4.2.branches.3.3.bn1.num_batches_tracked from pretrained model\n","=> loading stage4.2.branches.3.3.conv2.weight from pretrained model\n","=> loading stage4.2.branches.3.3.bn2.weight from pretrained model\n","=> loading stage4.2.branches.3.3.bn2.bias from pretrained model\n","=> loading stage4.2.branches.3.3.bn2.running_mean from pretrained model\n","=> loading stage4.2.branches.3.3.bn2.running_var from pretrained model\n","=> loading stage4.2.branches.3.3.bn2.num_batches_tracked from pretrained model\n","=> loading stage4.2.fuse_layers.0.1.0.weight from pretrained model\n","=> loading stage4.2.fuse_layers.0.1.1.weight from pretrained model\n","=> loading stage4.2.fuse_layers.0.1.1.bias from pretrained model\n","=> loading stage4.2.fuse_layers.0.1.1.running_mean from pretrained model\n","=> loading stage4.2.fuse_layers.0.1.1.running_var from pretrained model\n","=> loading stage4.2.fuse_layers.0.1.1.num_batches_tracked from pretrained model\n","=> loading stage4.2.fuse_layers.0.2.0.weight from pretrained model\n","=> loading stage4.2.fuse_layers.0.2.1.weight from pretrained model\n","=> loading stage4.2.fuse_layers.0.2.1.bias from pretrained model\n","=> loading stage4.2.fuse_layers.0.2.1.running_mean from pretrained model\n","=> loading stage4.2.fuse_layers.0.2.1.running_var from pretrained model\n","=> loading stage4.2.fuse_layers.0.2.1.num_batches_tracked from pretrained model\n","=> loading stage4.2.fuse_layers.0.3.0.weight from pretrained model\n","=> loading stage4.2.fuse_layers.0.3.1.weight from pretrained model\n","=> loading stage4.2.fuse_layers.0.3.1.bias from pretrained model\n","=> loading stage4.2.fuse_layers.0.3.1.running_mean from pretrained model\n","=> loading stage4.2.fuse_layers.0.3.1.running_var from pretrained model\n","=> loading stage4.2.fuse_layers.0.3.1.num_batches_tracked from pretrained model\n","=> loading stage4.2.fuse_layers.1.0.0.0.weight from pretrained model\n","=> loading stage4.2.fuse_layers.1.0.0.1.weight from pretrained model\n","=> loading stage4.2.fuse_layers.1.0.0.1.bias from pretrained model\n","=> loading stage4.2.fuse_layers.1.0.0.1.running_mean from pretrained model\n","=> loading stage4.2.fuse_layers.1.0.0.1.running_var from pretrained model\n","=> loading stage4.2.fuse_layers.1.0.0.1.num_batches_tracked from pretrained model\n","=> loading stage4.2.fuse_layers.1.2.0.weight from pretrained model\n","=> loading stage4.2.fuse_layers.1.2.1.weight from pretrained model\n","=> loading stage4.2.fuse_layers.1.2.1.bias from pretrained model\n","=> loading stage4.2.fuse_layers.1.2.1.running_mean from pretrained model\n","=> loading stage4.2.fuse_layers.1.2.1.running_var from pretrained model\n","=> loading stage4.2.fuse_layers.1.2.1.num_batches_tracked from pretrained model\n","=> loading stage4.2.fuse_layers.1.3.0.weight from pretrained model\n","=> loading stage4.2.fuse_layers.1.3.1.weight from pretrained model\n","=> loading stage4.2.fuse_layers.1.3.1.bias from pretrained model\n","=> loading stage4.2.fuse_layers.1.3.1.running_mean from pretrained model\n","=> loading stage4.2.fuse_layers.1.3.1.running_var from pretrained model\n","=> loading stage4.2.fuse_layers.1.3.1.num_batches_tracked from pretrained model\n","=> loading stage4.2.fuse_layers.2.0.0.0.weight from pretrained model\n","=> loading stage4.2.fuse_layers.2.0.0.1.weight from pretrained model\n","=> loading stage4.2.fuse_layers.2.0.0.1.bias from pretrained model\n","=> loading stage4.2.fuse_layers.2.0.0.1.running_mean from pretrained model\n","=> loading stage4.2.fuse_layers.2.0.0.1.running_var from pretrained model\n","=> loading stage4.2.fuse_layers.2.0.0.1.num_batches_tracked from pretrained model\n","=> loading stage4.2.fuse_layers.2.0.1.0.weight from pretrained model\n","=> loading stage4.2.fuse_layers.2.0.1.1.weight from pretrained model\n","=> loading stage4.2.fuse_layers.2.0.1.1.bias from pretrained model\n","=> loading stage4.2.fuse_layers.2.0.1.1.running_mean from pretrained model\n","=> loading stage4.2.fuse_layers.2.0.1.1.running_var from pretrained model\n","=> loading stage4.2.fuse_layers.2.0.1.1.num_batches_tracked from pretrained model\n","=> loading stage4.2.fuse_layers.2.1.0.0.weight from pretrained model\n","=> loading stage4.2.fuse_layers.2.1.0.1.weight from pretrained model\n","=> loading stage4.2.fuse_layers.2.1.0.1.bias from pretrained model\n","=> loading stage4.2.fuse_layers.2.1.0.1.running_mean from pretrained model\n","=> loading stage4.2.fuse_layers.2.1.0.1.running_var from pretrained model\n","=> loading stage4.2.fuse_layers.2.1.0.1.num_batches_tracked from pretrained model\n","=> loading stage4.2.fuse_layers.2.3.0.weight from pretrained model\n","=> loading stage4.2.fuse_layers.2.3.1.weight from pretrained model\n","=> loading stage4.2.fuse_layers.2.3.1.bias from pretrained model\n","=> loading stage4.2.fuse_layers.2.3.1.running_mean from pretrained model\n","=> loading stage4.2.fuse_layers.2.3.1.running_var from pretrained model\n","=> loading stage4.2.fuse_layers.2.3.1.num_batches_tracked from pretrained model\n","=> loading stage4.2.fuse_layers.3.0.0.0.weight from pretrained model\n","=> loading stage4.2.fuse_layers.3.0.0.1.weight from pretrained model\n","=> loading stage4.2.fuse_layers.3.0.0.1.bias from pretrained model\n","=> loading stage4.2.fuse_layers.3.0.0.1.running_mean from pretrained model\n","=> loading stage4.2.fuse_layers.3.0.0.1.running_var from pretrained model\n","=> loading stage4.2.fuse_layers.3.0.0.1.num_batches_tracked from pretrained model\n","=> loading stage4.2.fuse_layers.3.0.1.0.weight from pretrained model\n","=> loading stage4.2.fuse_layers.3.0.1.1.weight from pretrained model\n","=> loading stage4.2.fuse_layers.3.0.1.1.bias from pretrained model\n","=> loading stage4.2.fuse_layers.3.0.1.1.running_mean from pretrained model\n","=> loading stage4.2.fuse_layers.3.0.1.1.running_var from pretrained model\n","=> loading stage4.2.fuse_layers.3.0.1.1.num_batches_tracked from pretrained model\n","=> loading stage4.2.fuse_layers.3.0.2.0.weight from pretrained model\n","=> loading stage4.2.fuse_layers.3.0.2.1.weight from pretrained model\n","=> loading stage4.2.fuse_layers.3.0.2.1.bias from pretrained model\n","=> loading stage4.2.fuse_layers.3.0.2.1.running_mean from pretrained model\n","=> loading stage4.2.fuse_layers.3.0.2.1.running_var from pretrained model\n","=> loading stage4.2.fuse_layers.3.0.2.1.num_batches_tracked from pretrained model\n","=> loading stage4.2.fuse_layers.3.1.0.0.weight from pretrained model\n","=> loading stage4.2.fuse_layers.3.1.0.1.weight from pretrained model\n","=> loading stage4.2.fuse_layers.3.1.0.1.bias from pretrained model\n","=> loading stage4.2.fuse_layers.3.1.0.1.running_mean from pretrained model\n","=> loading stage4.2.fuse_layers.3.1.0.1.running_var from pretrained model\n","=> loading stage4.2.fuse_layers.3.1.0.1.num_batches_tracked from pretrained model\n","=> loading stage4.2.fuse_layers.3.1.1.0.weight from pretrained model\n","=> loading stage4.2.fuse_layers.3.1.1.1.weight from pretrained model\n","=> loading stage4.2.fuse_layers.3.1.1.1.bias from pretrained model\n","=> loading stage4.2.fuse_layers.3.1.1.1.running_mean from pretrained model\n","=> loading stage4.2.fuse_layers.3.1.1.1.running_var from pretrained model\n","=> loading stage4.2.fuse_layers.3.1.1.1.num_batches_tracked from pretrained model\n","=> loading stage4.2.fuse_layers.3.2.0.0.weight from pretrained model\n","=> loading stage4.2.fuse_layers.3.2.0.1.weight from pretrained model\n","=> loading stage4.2.fuse_layers.3.2.0.1.bias from pretrained model\n","=> loading stage4.2.fuse_layers.3.2.0.1.running_mean from pretrained model\n","=> loading stage4.2.fuse_layers.3.2.0.1.running_var from pretrained model\n","=> loading stage4.2.fuse_layers.3.2.0.1.num_batches_tracked from pretrained model\n","=> loading conv3x3_ocr.0.weight from pretrained model\n","=> loading conv3x3_ocr.0.bias from pretrained model\n","=> loading conv3x3_ocr.1.weight from pretrained model\n","=> loading conv3x3_ocr.1.bias from pretrained model\n","=> loading conv3x3_ocr.1.running_mean from pretrained model\n","=> loading conv3x3_ocr.1.running_var from pretrained model\n","=> loading conv3x3_ocr.1.num_batches_tracked from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_pixel.0.weight from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_pixel.1.0.weight from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_pixel.1.0.bias from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_pixel.1.0.running_mean from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_pixel.1.0.running_var from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_pixel.1.0.num_batches_tracked from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_pixel.2.weight from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_pixel.3.0.weight from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_pixel.3.0.bias from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_pixel.3.0.running_mean from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_pixel.3.0.running_var from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_pixel.3.0.num_batches_tracked from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_object.0.weight from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_object.1.0.weight from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_object.1.0.bias from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_object.1.0.running_mean from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_object.1.0.running_var from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_object.1.0.num_batches_tracked from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_object.2.weight from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_object.3.0.weight from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_object.3.0.bias from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_object.3.0.running_mean from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_object.3.0.running_var from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_object.3.0.num_batches_tracked from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_down.0.weight from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_down.1.0.weight from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_down.1.0.bias from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_down.1.0.running_mean from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_down.1.0.running_var from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_down.1.0.num_batches_tracked from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_up.0.weight from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_up.1.0.weight from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_up.1.0.bias from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_up.1.0.running_mean from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_up.1.0.running_var from pretrained model\n","=> loading ocr_distri_head.object_context_block.f_up.1.0.num_batches_tracked from pretrained model\n","=> loading ocr_distri_head.conv_bn_dropout.0.weight from pretrained model\n","=> loading ocr_distri_head.conv_bn_dropout.1.0.weight from pretrained model\n","=> loading ocr_distri_head.conv_bn_dropout.1.0.bias from pretrained model\n","=> loading ocr_distri_head.conv_bn_dropout.1.0.running_mean from pretrained model\n","=> loading ocr_distri_head.conv_bn_dropout.1.0.running_var from pretrained model\n","=> loading ocr_distri_head.conv_bn_dropout.1.0.num_batches_tracked from pretrained model\n","=> loading cls_head.weight from pretrained model\n","=> loading cls_head.bias from pretrained model\n","=> loading aux_head.0.weight from pretrained model\n","=> loading aux_head.0.bias from pretrained model\n","=> loading aux_head.1.weight from pretrained model\n","=> loading aux_head.1.bias from pretrained model\n","=> loading aux_head.1.running_mean from pretrained model\n","=> loading aux_head.1.running_var from pretrained model\n","=> loading aux_head.1.num_batches_tracked from pretrained model\n","=> loading aux_head.3.weight from pretrained model\n","=> loading aux_head.3.bias from pretrained model\n","  0% 0/500 [00:00<?, ?it/s]processing: 0 images\n","mIoU: 0.4360\n","  1% 3/500 [01:05<2:32:18, 18.39s/it]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ffa36925170>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1474, in _shutdown_workers\n","    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 140, in join\n","    res = self._popen.wait(timeout)\n","  File \"/usr/lib/python3.7/multiprocessing/popen_fork.py\", line 45, in wait\n","    if not wait([self.sentinel], timeout):\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 921, in wait\n","    ready = selector.select(timeout)\n","  File \"/usr/lib/python3.7/selectors.py\", line 415, in select\n","    fd_event_list = self._selector.poll(timeout)\n","KeyboardInterrupt: \n","  1% 3/500 [01:07<3:07:03, 22.58s/it]\n","Traceback (most recent call last):\n","  File \"tools/test.py\", line 143, in <module>\n","    main()\n","  File \"tools/test.py\", line 123, in main\n","    model)\n","  File \"/content/drive/MyDrive/lecture/HRNet-Semantic-Segmentation/tools/../lib/core/function.py\", line 167, in testval\n","    flip=config.TEST.FLIP_TEST)\n","  File \"/content/drive/MyDrive/lecture/HRNet-Semantic-Segmentation/tools/../lib/datasets/cityscapes.py\", line 168, in multi_scale_inference\n","    pred = self.inference(config, model, crop_img, flip)\n","  File \"/content/drive/MyDrive/lecture/HRNet-Semantic-Segmentation/tools/../lib/datasets/base_dataset.py\", line 204, in inference\n","    flip_output = model(torch.from_numpy(flip_img.copy()))\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py\", line 166, in forward\n","    return self.module(*inputs[0], **kwargs[0])\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/drive/MyDrive/lecture/HRNet-Semantic-Segmentation/tools/../lib/models/seg_hrnet_ocr.py\", line 620, in forward\n","    x = self.stage4(x_list)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 139, in forward\n","    input = module(input)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/drive/MyDrive/lecture/HRNet-Semantic-Segmentation/tools/../lib/models/seg_hrnet_ocr.py\", line 389, in forward\n","    x[i] = self.branches[i](x[i])\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 139, in forward\n","    input = module(input)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/drive/MyDrive/lecture/HRNet-Semantic-Segmentation/tools/../lib/models/seg_hrnet_ocr.py\", line 218, in forward\n","    out = self.relu(out)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py\", line 98, in forward\n","    return F.relu(input, inplace=self.inplace)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 1455, in relu\n","    result = torch.relu_(input)\n","KeyboardInterrupt\n"]}]},{"cell_type":"markdown","source":["Train 실행"],"metadata":{"id":"aRy_15Chxo9_"}},{"cell_type":"code","source":["!python -m torch.distributed.launch --nproc_per_node=1 tools/train.py --cfg experiments/cityscapes/seg_hrnet_ocr_w48_train_512x1024_sgd_lr1e-2_wd5e-4_bs_12_epoch484.yaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WSXejK4-vFvt","executionInfo":{"status":"ok","timestamp":1661074934605,"user_tz":-540,"elapsed":70070,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"479848e4-f67a-40f0-c874-ff88db6959b6"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n","and will be removed in future. Use torchrun.\n","Note that --use_env is set by default in torchrun.\n","If your script expects `--local_rank` argument to be set, please\n","change it to read from `os.environ['LOCAL_RANK']` instead. See \n","https://pytorch.org/docs/stable/distributed.html#launch-utility for \n","further instructions\n","\n","  FutureWarning,\n","Seeding with 304\n","=> creating output/cityscapes/seg_hrnet_ocr_w48_train_512x1024_sgd_lr1e-2_wd5e-4_bs_12_epoch484\n","=> creating log/cityscapes/seg_hrnet_ocr/seg_hrnet_ocr_w48_train_512x1024_sgd_lr1e-2_wd5e-4_bs_12_epoch484_2022-08-21-09-41\n","Namespace(cfg='experiments/cityscapes/seg_hrnet_ocr_w48_train_512x1024_sgd_lr1e-2_wd5e-4_bs_12_epoch484.yaml', local_rank=0, opts=[], seed=304)\n","AUTO_RESUME: False\n","CUDNN:\n","  BENCHMARK: True\n","  DETERMINISTIC: False\n","  ENABLED: True\n","DATASET:\n","  DATASET: cityscapes\n","  EXTRA_TRAIN_SET: \n","  NUM_CLASSES: 19\n","  ROOT: data/\n","  TEST_SET: list/cityscapes/val.lst\n","  TRAIN_SET: list/cityscapes/train.lst\n","DEBUG:\n","  DEBUG: False\n","  SAVE_BATCH_IMAGES_GT: False\n","  SAVE_BATCH_IMAGES_PRED: False\n","  SAVE_HEATMAPS_GT: False\n","  SAVE_HEATMAPS_PRED: False\n","GPUS: (0,)\n","LOG_DIR: log\n","LOSS:\n","  BALANCE_WEIGHTS: [0.4, 1]\n","  CLASS_BALANCE: False\n","  OHEMKEEP: 131072\n","  OHEMTHRES: 0.9\n","  USE_OHEM: False\n","MODEL:\n","  ALIGN_CORNERS: True\n","  EXTRA:\n","    FINAL_CONV_KERNEL: 1\n","    STAGE1:\n","      BLOCK: BOTTLENECK\n","      FUSE_METHOD: SUM\n","      NUM_BLOCKS: [4]\n","      NUM_CHANNELS: [64]\n","      NUM_MODULES: 1\n","      NUM_RANCHES: 1\n","    STAGE2:\n","      BLOCK: BASIC\n","      FUSE_METHOD: SUM\n","      NUM_BLOCKS: [4, 4]\n","      NUM_BRANCHES: 2\n","      NUM_CHANNELS: [48, 96]\n","      NUM_MODULES: 1\n","    STAGE3:\n","      BLOCK: BASIC\n","      FUSE_METHOD: SUM\n","      NUM_BLOCKS: [4, 4, 4]\n","      NUM_BRANCHES: 3\n","      NUM_CHANNELS: [48, 96, 192]\n","      NUM_MODULES: 4\n","    STAGE4:\n","      BLOCK: BASIC\n","      FUSE_METHOD: SUM\n","      NUM_BLOCKS: [4, 4, 4, 4]\n","      NUM_BRANCHES: 4\n","      NUM_CHANNELS: [48, 96, 192, 384]\n","      NUM_MODULES: 3\n","  NAME: seg_hrnet_ocr\n","  NUM_OUTPUTS: 2\n","  OCR:\n","    DROPOUT: 0.05\n","    KEY_CHANNELS: 256\n","    MID_CHANNELS: 512\n","    SCALE: 1\n","  PRETRAINED: pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n","OUTPUT_DIR: output\n","PIN_MEMORY: True\n","PRINT_FREQ: 10\n","RANK: 0\n","TEST:\n","  BASE_SIZE: 2048\n","  BATCH_SIZE_PER_GPU: 4\n","  FLIP_TEST: False\n","  IMAGE_SIZE: [2048, 1024]\n","  MODEL_FILE: \n","  MULTI_SCALE: False\n","  NUM_SAMPLES: 0\n","  OUTPUT_INDEX: -1\n","  SCALE_LIST: [1]\n","TRAIN:\n","  BASE_SIZE: 2048\n","  BATCH_SIZE_PER_GPU: 3\n","  BEGIN_EPOCH: 0\n","  DOWNSAMPLERATE: 1\n","  END_EPOCH: 484\n","  EXTRA_EPOCH: 0\n","  EXTRA_LR: 0.001\n","  FLIP: True\n","  FREEZE_EPOCHS: -1\n","  FREEZE_LAYERS: \n","  IGNORE_LABEL: 255\n","  IMAGE_SIZE: [1024, 512]\n","  LR: 0.01\n","  LR_FACTOR: 0.1\n","  LR_STEP: [90, 110]\n","  MOMENTUM: 0.9\n","  MULTI_SCALE: True\n","  NESTEROV: False\n","  NONBACKBONE_KEYWORDS: []\n","  NONBACKBONE_MULT: 10\n","  NUM_SAMPLES: 0\n","  OPTIMIZER: sgd\n","  RANDOM_BRIGHTNESS: False\n","  RANDOM_BRIGHTNESS_SHIFT_VALUE: 10\n","  RESUME: True\n","  SCALE_FACTOR: 16\n","  SHUFFLE: True\n","  WD: 0.0005\n","WORKERS: 2\n","Added key: store_based_barrier_key:1 to store for rank: 0\n","Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n","=> init weights from normal distribution\n","=> loading pretrained model pretrained_models/hrnetv2_w48_imagenet_pretrained.pth\n","{'ocr_distri_head.object_context_block.f_down.1.0.weight', 'ocr_distri_head.object_context_block.f_object.1.0.bias', 'ocr_distri_head.object_context_block.f_down.1.0.running_mean', 'ocr_distri_head.object_context_block.f_object.1.0.num_batches_tracked', 'ocr_distri_head.object_context_block.f_pixel.3.0.bias', 'ocr_distri_head.object_context_block.f_up.1.0.running_var', 'aux_head.1.weight', 'ocr_distri_head.object_context_block.f_pixel.3.0.running_mean', 'ocr_distri_head.object_context_block.f_up.0.weight', 'ocr_distri_head.object_context_block.f_down.0.weight', 'aux_head.1.running_var', 'cls_head.bias', 'ocr_distri_head.object_context_block.f_pixel.3.0.num_batches_tracked', 'ocr_distri_head.object_context_block.f_object.3.0.weight', 'ocr_distri_head.object_context_block.f_up.1.0.weight', 'ocr_distri_head.conv_bn_dropout.1.0.weight', 'ocr_distri_head.object_context_block.f_pixel.1.0.bias', 'ocr_distri_head.conv_bn_dropout.1.0.bias', 'ocr_distri_head.object_context_block.f_down.1.0.bias', 'ocr_distri_head.object_context_block.f_object.3.0.bias', 'conv3x3_ocr.1.num_batches_tracked', 'aux_head.0.bias', 'ocr_distri_head.object_context_block.f_pixel.1.0.weight', 'ocr_distri_head.object_context_block.f_object.3.0.running_mean', 'aux_head.3.weight', 'ocr_distri_head.object_context_block.f_object.1.0.running_mean', 'conv3x3_ocr.0.weight', 'ocr_distri_head.object_context_block.f_object.0.weight', 'conv3x3_ocr.1.bias', 'ocr_distri_head.object_context_block.f_down.1.0.num_batches_tracked', 'aux_head.3.bias', 'ocr_distri_head.object_context_block.f_pixel.1.0.num_batches_tracked', 'conv3x3_ocr.0.bias', 'ocr_distri_head.object_context_block.f_pixel.3.0.running_var', 'cls_head.weight', 'ocr_distri_head.object_context_block.f_object.3.0.running_var', 'ocr_distri_head.object_context_block.f_up.1.0.running_mean', 'conv3x3_ocr.1.running_mean', 'ocr_distri_head.conv_bn_dropout.1.0.running_var', 'ocr_distri_head.conv_bn_dropout.1.0.running_mean', 'ocr_distri_head.conv_bn_dropout.0.weight', 'aux_head.0.weight', 'aux_head.1.running_mean', 'ocr_distri_head.conv_bn_dropout.1.0.num_batches_tracked', 'conv3x3_ocr.1.running_var', 'ocr_distri_head.object_context_block.f_object.1.0.running_var', 'ocr_distri_head.object_context_block.f_object.3.0.num_batches_tracked', 'ocr_distri_head.object_context_block.f_pixel.3.0.weight', 'ocr_distri_head.object_context_block.f_down.1.0.running_var', 'ocr_distri_head.object_context_block.f_pixel.1.0.running_var', 'ocr_distri_head.object_context_block.f_pixel.0.weight', 'aux_head.1.num_batches_tracked', 'ocr_distri_head.object_context_block.f_pixel.2.weight', 'ocr_distri_head.object_context_block.f_up.1.0.num_batches_tracked', 'conv3x3_ocr.1.weight', 'ocr_distri_head.object_context_block.f_up.1.0.bias', 'ocr_distri_head.object_context_block.f_object.1.0.weight', 'aux_head.1.bias', 'ocr_distri_head.object_context_block.f_pixel.1.0.running_mean', 'ocr_distri_head.object_context_block.f_object.2.weight'}\n","{'incre_modules.3.0.conv1.weight', 'downsamp_modules.2.0.weight', 'incre_modules.3.0.downsample.1.num_batches_tracked', 'incre_modules.3.0.bn1.num_batches_tracked', 'downsamp_modules.1.0.weight', 'downsamp_modules.0.1.bias', 'incre_modules.3.0.bn2.weight', 'downsamp_modules.0.0.bias', 'incre_modules.2.0.bn3.running_mean', 'incre_modules.2.0.downsample.1.bias', 'incre_modules.1.0.bn2.num_batches_tracked', 'downsamp_modules.0.1.weight', 'incre_modules.0.0.bn2.num_batches_tracked', 'incre_modules.3.0.downsample.1.weight', 'downsamp_modules.1.1.running_mean', 'downsamp_modules.2.1.running_mean', 'classifier.bias', 'incre_modules.1.0.conv1.weight', 'incre_modules.3.0.bn2.num_batches_tracked', 'incre_modules.2.0.bn2.weight', 'incre_modules.2.0.bn1.running_mean', 'incre_modules.2.0.downsample.1.running_var', 'final_layer.1.running_var', 'downsamp_modules.1.1.weight', 'classifier.weight', 'incre_modules.0.0.downsample.1.weight', 'incre_modules.1.0.bn1.num_batches_tracked', 'downsamp_modules.2.1.weight', 'incre_modules.1.0.downsample.1.weight', 'downsamp_modules.2.1.running_var', 'incre_modules.2.0.conv1.weight', 'incre_modules.2.0.bn2.num_batches_tracked', 'incre_modules.1.0.bn1.running_mean', 'incre_modules.0.0.bn2.bias', 'incre_modules.3.0.bn1.weight', 'final_layer.1.running_mean', 'incre_modules.2.0.bn3.running_var', 'final_layer.1.weight', 'incre_modules.0.0.bn3.bias', 'incre_modules.2.0.downsample.1.weight', 'incre_modules.2.0.bn3.bias', 'downsamp_modules.0.1.num_batches_tracked', 'incre_modules.2.0.conv3.weight', 'incre_modules.1.0.downsample.1.num_batches_tracked', 'incre_modules.1.0.downsample.0.weight', 'incre_modules.1.0.bn1.running_var', 'incre_modules.2.0.bn1.running_var', 'downsamp_modules.2.1.num_batches_tracked', 'incre_modules.2.0.bn3.weight', 'incre_modules.3.0.conv3.weight', 'incre_modules.0.0.conv3.weight', 'incre_modules.3.0.conv2.weight', 'incre_modules.1.0.bn3.running_mean', 'incre_modules.0.0.bn1.weight', 'incre_modules.0.0.bn2.weight', 'downsamp_modules.2.0.bias', 'incre_modules.0.0.bn3.num_batches_tracked', 'incre_modules.1.0.bn2.running_mean', 'incre_modules.1.0.bn2.weight', 'incre_modules.2.0.bn2.running_var', 'incre_modules.2.0.downsample.0.weight', 'incre_modules.1.0.bn3.running_var', 'incre_modules.2.0.bn2.bias', 'incre_modules.1.0.downsample.1.bias', 'incre_modules.2.0.bn3.num_batches_tracked', 'incre_modules.3.0.bn2.bias', 'incre_modules.3.0.bn2.running_var', 'incre_modules.1.0.downsample.1.running_var', 'incre_modules.0.0.bn1.num_batches_tracked', 'incre_modules.1.0.bn1.bias', 'incre_modules.1.0.bn3.bias', 'incre_modules.0.0.downsample.1.bias', 'incre_modules.0.0.bn3.running_mean', 'final_layer.1.num_batches_tracked', 'incre_modules.0.0.downsample.1.running_mean', 'incre_modules.1.0.conv3.weight', 'incre_modules.1.0.bn2.bias', 'incre_modules.2.0.downsample.1.running_mean', 'incre_modules.0.0.downsample.1.num_batches_tracked', 'incre_modules.3.0.bn3.bias', 'downsamp_modules.2.1.bias', 'downsamp_modules.1.0.bias', 'incre_modules.0.0.downsample.1.running_var', 'incre_modules.1.0.downsample.1.running_mean', 'incre_modules.0.0.bn2.running_mean', 'incre_modules.3.0.bn3.num_batches_tracked', 'incre_modules.3.0.bn3.weight', 'incre_modules.0.0.bn1.running_var', 'downsamp_modules.0.1.running_var', 'downsamp_modules.1.1.num_batches_tracked', 'incre_modules.0.0.bn1.running_mean', 'incre_modules.0.0.downsample.0.weight', 'incre_modules.1.0.bn2.running_var', 'incre_modules.1.0.bn1.weight', 'incre_modules.0.0.bn1.bias', 'incre_modules.2.0.bn1.bias', 'downsamp_modules.0.1.running_mean', 'incre_modules.3.0.bn3.running_mean', 'final_layer.1.bias', 'incre_modules.2.0.bn1.weight', 'incre_modules.1.0.bn3.num_batches_tracked', 'incre_modules.3.0.downsample.0.weight', 'incre_modules.1.0.bn3.weight', 'incre_modules.3.0.bn1.bias', 'final_layer.0.weight', 'downsamp_modules.1.1.bias', 'incre_modules.0.0.bn3.weight', 'incre_modules.0.0.conv2.weight', 'incre_modules.3.0.bn2.running_mean', 'incre_modules.2.0.bn1.num_batches_tracked', 'final_layer.0.bias', 'downsamp_modules.0.0.weight', 'incre_modules.0.0.conv1.weight', 'incre_modules.0.0.bn3.running_var', 'downsamp_modules.1.1.running_var', 'incre_modules.3.0.bn1.running_var', 'incre_modules.1.0.conv2.weight', 'incre_modules.3.0.downsample.1.bias', 'incre_modules.0.0.bn2.running_var', 'incre_modules.3.0.downsample.1.running_mean', 'incre_modules.3.0.bn3.running_var', 'incre_modules.2.0.bn2.running_mean', 'incre_modules.3.0.bn1.running_mean', 'incre_modules.2.0.conv2.weight', 'incre_modules.2.0.downsample.1.num_batches_tracked', 'incre_modules.3.0.downsample.1.running_var'}\n","tools/train.py:244: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  epoch_iters = np.int(train_dataset.__len__() /\n","[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n","Epoch: [0/484] Iter:[0/991], Time: 40.72, lr: [0.01], Loss: 4.139797\n","WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers\n","WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 928 closing signal SIGINT\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f14c53054d0>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1456, in _shutdown_workers\n","    self._pin_memory_thread.join()\n","  File \"/usr/lib/python3.7/threading.py\", line 1044, in join\n","    self._wait_for_tstate_lock()\n","  File \"/usr/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n","    elif lock.acquire(block, timeout):\n","KeyboardInterrupt: \n","Traceback (most recent call last):\n","  File \"tools/train.py\", line 322, in <module>\n","    main()\n","  File \"tools/train.py\", line 287, in main\n","    trainloader, optimizer, model, writer_dict)\n","  File \"/content/drive/MyDrive/lecture/HRNet-Semantic-Segmentation/tools/../lib/core/function.py\", line 65, in train\n","    model.zero_grad()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1899, in zero_grad\n","    for p in self.parameters():\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1642, in parameters\n","    for name, param in self.named_parameters(recurse=recurse):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1668, in named_parameters\n","    for elem in gen:\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1614, in _named_members\n","    for k, v in members:\n","KeyboardInterrupt\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n","    \"__main__\", mod_spec)\n","  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 193, in <module>\n","    main()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 189, in main\n","    launch(args)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 174, in launch\n","    run(args)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/run.py\", line 755, in run\n","    )(*cmd_args)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n","    return launch_agent(self._config, self._entrypoint, list(args))\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launcher/api.py\", line 236, in launch_agent\n","    result = agent.run()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/metrics/api.py\", line 125, in wrapper\n","    result = f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 709, in run\n","    result = self._invoke_run(role)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 850, in _invoke_run\n","    time.sleep(monitor_interval)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 59, in _terminate_process_handler\n","    sigval = signal.Signals(signum)\n","  File \"/usr/lib/python3.7/enum.py\", line 315, in __call__\n","    return cls.__new__(cls, value)\n","  File \"/usr/lib/python3.7/enum.py\", line 535, in __new__\n","    if type(value) is cls:\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 60, in _terminate_process_handler\n","    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n","torch.distributed.elastic.multiprocessing.api.SignalException: Process 916 got signal: 2\n"]}]},{"cell_type":"code","source":["# ------------------------------------------------------------------------------\n","# Copyright (c) Microsoft\n","# Licensed under the MIT License.\n","# Written by Ke Sun (sunk@mail.ustc.edu.cn), Jingyi Xie (hsfzxjy@gmail.com)\n","# ------------------------------------------------------------------------------\n","\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import os\n","import logging\n","import functools\n","\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch._utils\n","import torch.nn.functional as F\n","\n","if torch.__version__.startswith('0'):\n","    from lib.sync_bn.inplace_abn.bn import InPlaceABNSync\n","    BatchNorm2d = functools.partial(InPlaceABNSync, activation='none')\n","    BatchNorm2d_class = InPlaceABNSync\n","    relu_inplace = False\n","else:\n","    BatchNorm2d_class = BatchNorm2d = torch.nn.SyncBatchNorm\n","    relu_inplace = True\n","\n","#from lib.models.bn_helper import BatchNorm2d, BatchNorm2d_class, relu_inplace\n","\n","ALIGN_CORNERS = True\n","BN_MOMENTUM = 0.1\n","logger = logging.getLogger(__name__)\n","\n","class ModuleHelper:\n","\n","    @staticmethod\n","    def BNReLU(num_features, bn_type=None, **kwargs):\n","        return nn.Sequential(\n","            BatchNorm2d(num_features, **kwargs),\n","            nn.ReLU()\n","        )\n","\n","    @staticmethod\n","    def BatchNorm2d(*args, **kwargs):\n","        return BatchNorm2d\n","\n","\n","def conv3x3(in_planes, out_planes, stride=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=1, bias=False)\n","\n","\n","class SpatialGather_Module(nn.Module):\n","    \"\"\"\n","        Aggregate the context features according to the initial \n","        predicted probability distribution.\n","        Employ the soft-weighted method to aggregate the context.\n","    \"\"\"\n","    def __init__(self, cls_num=0, scale=1):\n","        super(SpatialGather_Module, self).__init__()\n","        self.cls_num = cls_num\n","        self.scale = scale\n","\n","    def forward(self, feats, probs):\n","        batch_size, c, h, w = probs.size(0), probs.size(1), probs.size(2), probs.size(3)\n","        probs = probs.view(batch_size, c, -1)\n","        feats = feats.view(batch_size, feats.size(1), -1)\n","        feats = feats.permute(0, 2, 1) # batch x hw x c \n","        probs = F.softmax(self.scale * probs, dim=2)# batch x k x hw\n","        ocr_context = torch.matmul(probs, feats)\\\n","        .permute(0, 2, 1).unsqueeze(3)# batch x k x c\n","        return ocr_context\n","\n","\n","class _ObjectAttentionBlock(nn.Module):\n","    '''\n","    The basic implementation for object context block\n","    Input:\n","        N X C X H X W\n","    Parameters:\n","        in_channels       : the dimension of the input feature map\n","        key_channels      : the dimension after the key/query transform\n","        scale             : choose the scale to downsample the input feature maps (save memory cost)\n","        bn_type           : specify the bn type\n","    Return:\n","        N X C X H X W\n","    '''\n","    def __init__(self, \n","                 in_channels, \n","                 key_channels, \n","                 scale=1, \n","                 bn_type=None):\n","        super(_ObjectAttentionBlock, self).__init__()\n","        self.scale = scale\n","        self.in_channels = in_channels\n","        self.key_channels = key_channels\n","        self.pool = nn.MaxPool2d(kernel_size=(scale, scale))\n","        self.f_pixel = nn.Sequential(\n","            nn.Conv2d(in_channels=self.in_channels, out_channels=self.key_channels,\n","                kernel_size=1, stride=1, padding=0, bias=False),\n","            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n","            nn.Conv2d(in_channels=self.key_channels, out_channels=self.key_channels,\n","                kernel_size=1, stride=1, padding=0, bias=False),\n","            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n","        )\n","        self.f_object = nn.Sequential(\n","            nn.Conv2d(in_channels=self.in_channels, out_channels=self.key_channels,\n","                kernel_size=1, stride=1, padding=0, bias=False),\n","            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n","            nn.Conv2d(in_channels=self.key_channels, out_channels=self.key_channels,\n","                kernel_size=1, stride=1, padding=0, bias=False),\n","            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n","        )\n","        self.f_down = nn.Sequential(\n","            nn.Conv2d(in_channels=self.in_channels, out_channels=self.key_channels,\n","                kernel_size=1, stride=1, padding=0, bias=False),\n","            ModuleHelper.BNReLU(self.key_channels, bn_type=bn_type),\n","        )\n","        self.f_up = nn.Sequential(\n","            nn.Conv2d(in_channels=self.key_channels, out_channels=self.in_channels,\n","                kernel_size=1, stride=1, padding=0, bias=False),\n","            ModuleHelper.BNReLU(self.in_channels, bn_type=bn_type),\n","        )\n","\n","    def forward(self, x, proxy):\n","        batch_size, h, w = x.size(0), x.size(2), x.size(3)\n","        if self.scale > 1:\n","            x = self.pool(x)\n","\n","        query = self.f_pixel(x).view(batch_size, self.key_channels, -1)\n","        query = query.permute(0, 2, 1)\n","        key = self.f_object(proxy).view(batch_size, self.key_channels, -1)\n","        value = self.f_down(proxy).view(batch_size, self.key_channels, -1)\n","        value = value.permute(0, 2, 1)\n","\n","        sim_map = torch.matmul(query, key)\n","        sim_map = (self.key_channels**-.5) * sim_map\n","        sim_map = F.softmax(sim_map, dim=-1)   \n","\n","        # add bg context ...\n","        context = torch.matmul(sim_map, value)\n","        context = context.permute(0, 2, 1).contiguous()\n","        context = context.view(batch_size, self.key_channels, *x.size()[2:])\n","        context = self.f_up(context)\n","        if self.scale > 1:\n","            context = F.interpolate(input=context, size=(h, w), mode='bilinear', align_corners=ALIGN_CORNERS)\n","\n","        return context\n","\n","\n","class ObjectAttentionBlock2D(_ObjectAttentionBlock):\n","    def __init__(self, \n","                 in_channels, \n","                 key_channels, \n","                 scale=1, \n","                 bn_type=None):\n","        super(ObjectAttentionBlock2D, self).__init__(in_channels,\n","                                                     key_channels,\n","                                                     scale, \n","                                                     bn_type=bn_type)\n","\n","\n","class SpatialOCR_Module(nn.Module):\n","    \"\"\"\n","    Implementation of the OCR module:\n","    We aggregate the global object representation to update the representation for each pixel.\n","    \"\"\"\n","    def __init__(self, \n","                 in_channels, \n","                 key_channels, \n","                 out_channels, \n","                 scale=1, \n","                 dropout=0.1, \n","                 bn_type=None):\n","        super(SpatialOCR_Module, self).__init__()\n","        self.object_context_block = ObjectAttentionBlock2D(in_channels, \n","                                                           key_channels, \n","                                                           scale, \n","                                                           bn_type)\n","        _in_channels = 2 * in_channels\n","\n","        self.conv_bn_dropout = nn.Sequential(\n","            nn.Conv2d(_in_channels, out_channels, kernel_size=1, padding=0, bias=False),\n","            ModuleHelper.BNReLU(out_channels, bn_type=bn_type),\n","            nn.Dropout2d(dropout)\n","        )\n","\n","    def forward(self, feats, proxy_feats):\n","        context = self.object_context_block(feats, proxy_feats)\n","\n","        output = self.conv_bn_dropout(torch.cat([context, feats], 1))\n","\n","        return output\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n","        self.relu = nn.ReLU(inplace=relu_inplace)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out = out + residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n","        self.bn1 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n","                               padding=1, bias=False)\n","        self.bn2 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n","        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1,\n","                               bias=False)\n","        self.bn3 = BatchNorm2d(planes * self.expansion,\n","                               momentum=BN_MOMENTUM)\n","        self.relu = nn.ReLU(inplace=relu_inplace)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out = out + residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class HighResolutionModule(nn.Module):\n","    def __init__(self, num_branches, blocks, num_blocks, num_inchannels,\n","                 num_channels, fuse_method, multi_scale_output=True):\n","        super(HighResolutionModule, self).__init__()\n","        self._check_branches(\n","            num_branches, blocks, num_blocks, num_inchannels, num_channels)\n","\n","        self.num_inchannels = num_inchannels\n","        self.fuse_method = fuse_method\n","        self.num_branches = num_branches\n","\n","        self.multi_scale_output = multi_scale_output\n","\n","        self.branches = self._make_branches(\n","            num_branches, blocks, num_blocks, num_channels)\n","        self.fuse_layers = self._make_fuse_layers()\n","        self.relu = nn.ReLU(inplace=relu_inplace)\n","\n","    def _check_branches(self, num_branches, blocks, num_blocks,\n","                        num_inchannels, num_channels):\n","        if num_branches != len(num_blocks):\n","            error_msg = 'NUM_BRANCHES({}) <> NUM_BLOCKS({})'.format(\n","                num_branches, len(num_blocks))\n","            logger.error(error_msg)\n","            raise ValueError(error_msg)\n","\n","        if num_branches != len(num_channels):\n","            error_msg = 'NUM_BRANCHES({}) <> NUM_CHANNELS({})'.format(\n","                num_branches, len(num_channels))\n","            logger.error(error_msg)\n","            raise ValueError(error_msg)\n","\n","        if num_branches != len(num_inchannels):\n","            error_msg = 'NUM_BRANCHES({}) <> NUM_INCHANNELS({})'.format(\n","                num_branches, len(num_inchannels))\n","            logger.error(error_msg)\n","            raise ValueError(error_msg)\n","\n","    def _make_one_branch(self, branch_index, block, num_blocks, num_channels,\n","                         stride=1):\n","        downsample = None\n","        if stride != 1 or \\\n","           self.num_inchannels[branch_index] != num_channels[branch_index] * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.num_inchannels[branch_index],\n","                          num_channels[branch_index] * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                BatchNorm2d(num_channels[branch_index] * block.expansion,\n","                            momentum=BN_MOMENTUM),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.num_inchannels[branch_index],\n","                            num_channels[branch_index], stride, downsample))\n","        self.num_inchannels[branch_index] = \\\n","            num_channels[branch_index] * block.expansion\n","        for i in range(1, num_blocks[branch_index]):\n","            layers.append(block(self.num_inchannels[branch_index],\n","                                num_channels[branch_index]))\n","\n","        return nn.Sequential(*layers)\n","\n","    def _make_branches(self, num_branches, block, num_blocks, num_channels):\n","        branches = []\n","\n","        for i in range(num_branches):\n","            branches.append(\n","                self._make_one_branch(i, block, num_blocks, num_channels))\n","\n","        return nn.ModuleList(branches)\n","\n","    def _make_fuse_layers(self):\n","        if self.num_branches == 1:\n","            return None\n","\n","        num_branches = self.num_branches\n","        num_inchannels = self.num_inchannels\n","        fuse_layers = []\n","        for i in range(num_branches if self.multi_scale_output else 1):\n","            fuse_layer = []\n","            for j in range(num_branches):\n","                if j > i:\n","                    fuse_layer.append(nn.Sequential(\n","                        nn.Conv2d(num_inchannels[j],\n","                                  num_inchannels[i],\n","                                  1,\n","                                  1,\n","                                  0,\n","                                  bias=False),\n","                        BatchNorm2d(num_inchannels[i], momentum=BN_MOMENTUM)))\n","                elif j == i:\n","                    fuse_layer.append(None)\n","                else:\n","                    conv3x3s = []\n","                    for k in range(i-j):\n","                        if k == i - j - 1:\n","                            num_outchannels_conv3x3 = num_inchannels[i]\n","                            conv3x3s.append(nn.Sequential(\n","                                nn.Conv2d(num_inchannels[j],\n","                                          num_outchannels_conv3x3,\n","                                          3, 2, 1, bias=False),\n","                                BatchNorm2d(num_outchannels_conv3x3,\n","                                            momentum=BN_MOMENTUM)))\n","                        else:\n","                            num_outchannels_conv3x3 = num_inchannels[j]\n","                            conv3x3s.append(nn.Sequential(\n","                                nn.Conv2d(num_inchannels[j],\n","                                          num_outchannels_conv3x3,\n","                                          3, 2, 1, bias=False),\n","                                BatchNorm2d(num_outchannels_conv3x3,\n","                                            momentum=BN_MOMENTUM),\n","                                nn.ReLU(inplace=relu_inplace)))\n","                    fuse_layer.append(nn.Sequential(*conv3x3s))\n","            fuse_layers.append(nn.ModuleList(fuse_layer))\n","\n","        return nn.ModuleList(fuse_layers)\n","\n","    def get_num_inchannels(self):\n","        return self.num_inchannels\n","\n","    def forward(self, x):\n","        if self.num_branches == 1:\n","            return [self.branches[0](x[0])]\n","\n","        for i in range(self.num_branches):\n","            x[i] = self.branches[i](x[i])\n","\n","        x_fuse = []\n","        for i in range(len(self.fuse_layers)):\n","            y = x[0] if i == 0 else self.fuse_layers[i][0](x[0])\n","            for j in range(1, self.num_branches):\n","                if i == j:\n","                    y = y + x[j]\n","                elif j > i:\n","                    width_output = x[i].shape[-1]\n","                    height_output = x[i].shape[-2]\n","                    y = y + F.interpolate(\n","                        self.fuse_layers[i][j](x[j]),\n","                        size=[height_output, width_output],\n","                        mode='bilinear', align_corners=ALIGN_CORNERS)\n","                else:\n","                    y = y + self.fuse_layers[i][j](x[j])\n","            x_fuse.append(self.relu(y))\n","\n","        return x_fuse\n","\n","\n","blocks_dict = {\n","    'BASIC': BasicBlock,\n","    'BOTTLENECK': Bottleneck\n","}\n","\n","\n","class HighResolutionNet(nn.Module):\n","\n","    def __init__(self, classes=19, config='', **kwargs):\n","        global ALIGN_CORNERS\n","        #extra = config.MODEL.EXTRA\n","        super(HighResolutionNet, self).__init__()\n","        ALIGN_CORNERS = True#config.MODEL.ALIGN_CORNERS\n","\n","        # stem net\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1,\n","                               bias=False)\n","        self.bn1 = BatchNorm2d(64, momentum=BN_MOMENTUM)\n","        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1,\n","                               bias=False)\n","        self.bn2 = BatchNorm2d(64, momentum=BN_MOMENTUM)\n","        self.relu = nn.ReLU(inplace=relu_inplace)\n","\n","        #self.stage1_cfg = extra['STAGE1']\n","        self.stage1_cfg ={'BLOCK': 'BOTTLENECK','FUSE_METHOD': 'SUM','NUM_BLOCKS': [4],\n","      'NUM_CHANNELS': [64],'NUM_MODULES': 1, 'NUM_RANCHES': 1}\n","\n","        num_channels = self.stage1_cfg['NUM_CHANNELS'][0]\n","        block = blocks_dict[self.stage1_cfg['BLOCK']]\n","        num_blocks = self.stage1_cfg['NUM_BLOCKS'][0]\n","        self.layer1 = self._make_layer(block, 64, num_channels, num_blocks)\n","        stage1_out_channel = block.expansion*num_channels\n","\n","        #self.stage2_cfg = extra['STAGE2']\n","        self.stage2_cfg = {'BLOCK': 'BASIC','FUSE_METHOD': 'SUM', 'NUM_BLOCKS': [4, 4],\n","      'NUM_BRANCHES': 2, 'NUM_CHANNELS': [48, 96],'NUM_MODULES': 1}\n","\n","        num_channels = self.stage2_cfg['NUM_CHANNELS']\n","        block = blocks_dict[self.stage2_cfg['BLOCK']]\n","        num_channels = [\n","            num_channels[i] * block.expansion for i in range(len(num_channels))]\n","        self.transition1 = self._make_transition_layer(\n","            [stage1_out_channel], num_channels)\n","        self.stage2, pre_stage_channels = self._make_stage(\n","            self.stage2_cfg, num_channels)\n","\n","        #self.stage3_cfg = extra['STAGE3']\n","        self.stage3_cfg = {'BLOCK': 'BASIC', 'FUSE_METHOD': 'SUM','NUM_BLOCKS': [4, 4, 4],\n","      'NUM_BRANCHES': 3,'NUM_CHANNELS': [48, 96, 192],'NUM_MODULES': 4}\n","\n","        num_channels = self.stage3_cfg['NUM_CHANNELS']\n","        block = blocks_dict[self.stage3_cfg['BLOCK']]\n","        num_channels = [\n","            num_channels[i] * block.expansion for i in range(len(num_channels))]\n","        self.transition2 = self._make_transition_layer(\n","            pre_stage_channels, num_channels)\n","        self.stage3, pre_stage_channels = self._make_stage(\n","            self.stage3_cfg, num_channels)\n","\n","        #self.stage4_cfg = extra['STAGE4']\n","        self.stage4_cfg = {'BLOCK': 'BASIC', 'FUSE_METHOD': 'SUM', 'NUM_BLOCKS': [4, 4, 4, 4],\n","      'NUM_BRANCHES': 4,'NUM_CHANNELS': [48, 96, 192, 384], 'NUM_MODULES': 3}\n","\n","        num_channels = self.stage4_cfg['NUM_CHANNELS']\n","        block = blocks_dict[self.stage4_cfg['BLOCK']]\n","        num_channels = [\n","            num_channels[i] * block.expansion for i in range(len(num_channels))]\n","        self.transition3 = self._make_transition_layer(\n","            pre_stage_channels, num_channels)\n","        self.stage4, pre_stage_channels = self._make_stage(\n","            self.stage4_cfg, num_channels, multi_scale_output=True)\n","\n","        last_inp_channels = np.int(np.sum(pre_stage_channels))\n","        ocr_mid_channels = 512  # config.MODEL.OCR.MID_CHANNELS\n","        ocr_key_channels = 256  # config.MODEL.OCR.KEY_CHANNELS\n","\n","        self.conv3x3_ocr = nn.Sequential(\n","            nn.Conv2d(last_inp_channels, ocr_mid_channels,\n","                      kernel_size=3, stride=1, padding=1),\n","            BatchNorm2d(ocr_mid_channels),\n","            nn.ReLU(inplace=relu_inplace),\n","        )\n","        self.ocr_gather_head = SpatialGather_Module(classes)\n","\n","        self.ocr_distri_head = SpatialOCR_Module(in_channels=ocr_mid_channels,\n","                                                 key_channels=ocr_key_channels,\n","                                                 out_channels=ocr_mid_channels,\n","                                                 scale=1,\n","                                                 dropout=0.05,\n","                                                 )\n","        self.cls_head = nn.Conv2d(\n","            ocr_mid_channels, classes, kernel_size=1, stride=1, padding=0, bias=True)\n","\n","        self.aux_head = nn.Sequential(\n","            nn.Conv2d(last_inp_channels, last_inp_channels,\n","                      kernel_size=1, stride=1, padding=0),\n","            BatchNorm2d(last_inp_channels),\n","            nn.ReLU(inplace=relu_inplace),\n","            nn.Conv2d(last_inp_channels, classes,\n","                      kernel_size=1, stride=1, padding=0, bias=True)\n","        )\n","        \n","    def _make_transition_layer(\n","            self, num_channels_pre_layer, num_channels_cur_layer):\n","        num_branches_cur = len(num_channels_cur_layer)\n","        num_branches_pre = len(num_channels_pre_layer)\n","\n","        transition_layers = []\n","        for i in range(num_branches_cur):\n","            if i < num_branches_pre:\n","                if num_channels_cur_layer[i] != num_channels_pre_layer[i]:\n","                    transition_layers.append(nn.Sequential(\n","                        nn.Conv2d(num_channels_pre_layer[i],\n","                                  num_channels_cur_layer[i],\n","                                  3,\n","                                  1,\n","                                  1,\n","                                  bias=False),\n","                        BatchNorm2d(\n","                            num_channels_cur_layer[i], momentum=BN_MOMENTUM),\n","                        nn.ReLU(inplace=relu_inplace)))\n","                else:\n","                    transition_layers.append(None)\n","            else:\n","                conv3x3s = []\n","                for j in range(i+1-num_branches_pre):\n","                    inchannels = num_channels_pre_layer[-1]\n","                    outchannels = num_channels_cur_layer[i] \\\n","                        if j == i-num_branches_pre else inchannels\n","                    conv3x3s.append(nn.Sequential(\n","                        nn.Conv2d(\n","                            inchannels, outchannels, 3, 2, 1, bias=False),\n","                        BatchNorm2d(outchannels, momentum=BN_MOMENTUM),\n","                        nn.ReLU(inplace=relu_inplace)))\n","                transition_layers.append(nn.Sequential(*conv3x3s))\n","\n","        return nn.ModuleList(transition_layers)\n","\n","    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(inplanes, planes * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                BatchNorm2d(planes * block.expansion, momentum=BN_MOMENTUM),\n","            )\n","\n","        layers = []\n","        layers.append(block(inplanes, planes, stride, downsample))\n","        inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","\n","    def _make_stage(self, layer_config, num_inchannels,\n","                    multi_scale_output=True):\n","        num_modules = layer_config['NUM_MODULES']\n","        num_branches = layer_config['NUM_BRANCHES']\n","        num_blocks = layer_config['NUM_BLOCKS']\n","        num_channels = layer_config['NUM_CHANNELS']\n","        block = blocks_dict[layer_config['BLOCK']]\n","        fuse_method = layer_config['FUSE_METHOD']\n","\n","        modules = []\n","        for i in range(num_modules):\n","            # multi_scale_output is only used last module\n","            if not multi_scale_output and i == num_modules - 1:\n","                reset_multi_scale_output = False\n","            else:\n","                reset_multi_scale_output = True\n","            modules.append(\n","                HighResolutionModule(num_branches,\n","                                     block,\n","                                     num_blocks,\n","                                     num_inchannels,\n","                                     num_channels,\n","                                     fuse_method,\n","                                     reset_multi_scale_output)\n","            )\n","            num_inchannels = modules[-1].get_num_inchannels()\n","\n","        return nn.Sequential(*modules), num_inchannels\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x = self.relu(x)\n","        x = self.layer1(x)\n","\n","        x_list = []\n","        for i in range(self.stage2_cfg['NUM_BRANCHES']):\n","            if self.transition1[i] is not None:\n","                x_list.append(self.transition1[i](x))\n","            else:\n","                x_list.append(x)\n","        y_list = self.stage2(x_list)\n","\n","        x_list = []\n","        for i in range(self.stage3_cfg['NUM_BRANCHES']):\n","            if self.transition2[i] is not None:\n","                if i < self.stage2_cfg['NUM_BRANCHES']:\n","                    x_list.append(self.transition2[i](y_list[i]))\n","                else:\n","                    x_list.append(self.transition2[i](y_list[-1]))\n","            else:\n","                x_list.append(y_list[i])\n","        y_list = self.stage3(x_list)\n","\n","        x_list = []\n","        for i in range(self.stage4_cfg['NUM_BRANCHES']):\n","            if self.transition3[i] is not None:\n","                if i < self.stage3_cfg['NUM_BRANCHES']:\n","                    x_list.append(self.transition3[i](y_list[i]))\n","                else:\n","                    x_list.append(self.transition3[i](y_list[-1]))\n","            else:\n","                x_list.append(y_list[i])\n","        x = self.stage4(x_list)\n","\n","        # Upsampling\n","        x0_h, x0_w = x[0].size(2), x[0].size(3)\n","        x1 = F.interpolate(x[1], size=(x0_h, x0_w),\n","                        mode='bilinear', align_corners=ALIGN_CORNERS)\n","        x2 = F.interpolate(x[2], size=(x0_h, x0_w),\n","                        mode='bilinear', align_corners=ALIGN_CORNERS)\n","        x3 = F.interpolate(x[3], size=(x0_h, x0_w),\n","                        mode='bilinear', align_corners=ALIGN_CORNERS)\n","\n","        feats = torch.cat([x[0], x1, x2, x3], 1)\n","\n","        out_aux_seg = []\n","\n","        # ocr\n","        out_aux = self.aux_head(feats)\n","        # compute contrast feature\n","        feats = self.conv3x3_ocr(feats)\n","\n","        context = self.ocr_gather_head(feats, out_aux)\n","        feats = self.ocr_distri_head(feats, context)\n","\n","        out = self.cls_head(feats)\n","\n","        out_aux_seg.append(out_aux)\n","        out_aux_seg.append(out)\n","\n","        return out_aux_seg\n","\n","    def init_weights(self, pretrained='',):\n","        logger.info('=> init weights from normal distribution')\n","        for name, m in self.named_modules():\n","            if any(part in name for part in {'cls', 'aux', 'ocr'}):\n","                # print('skipped', name)\n","                continue\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.normal_(m.weight, std=0.001)\n","            elif isinstance(m, BatchNorm2d_class):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","        if os.path.isfile(pretrained):\n","            pretrained_dict = torch.load(pretrained, map_location={'cuda:0': 'cpu'})\n","            logger.info('=> loading pretrained model {}'.format(pretrained))\n","            model_dict = self.state_dict()\n","            pretrained_dict = {k.replace('last_layer', 'aux_head').replace('model.', ''): v for k, v in pretrained_dict.items()}  \n","            print(set(model_dict) - set(pretrained_dict))            \n","            print(set(pretrained_dict) - set(model_dict))            \n","            pretrained_dict = {k: v for k, v in pretrained_dict.items()\n","                               if k in model_dict.keys()}\n","            # for k, _ in pretrained_dict.items():\n","                # logger.info(\n","                #     '=> loading {} pretrained model {}'.format(k, pretrained))\n","            model_dict.update(pretrained_dict)\n","            self.load_state_dict(model_dict)\n","        elif pretrained:\n","            raise RuntimeError('No such file {}'.format(pretrained))\n","\n","\n","def get_seg_model(cfg, **kwargs):\n","    model = HighResolutionNet(cfg, **kwargs)\n","    model.init_weights(cfg.MODEL.PRETRAINED)\n","\n","    return model\n"],"metadata":{"id":"KpVJ8DbNxnFE","executionInfo":{"status":"ok","timestamp":1661075846766,"user_tz":-540,"elapsed":3,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["model =  HighResolutionNet()\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TgRPApybyB_E","executionInfo":{"status":"ok","timestamp":1661075851051,"user_tz":-540,"elapsed":1387,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"7d8ab21b-1154-4f5f-a52c-8448e7ae07d6"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["HighResolutionNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","  (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","  (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (transition1): ModuleList(\n","    (0): Sequential(\n","      (0): Conv2d(256, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","    )\n","    (1): Sequential(\n","      (0): Sequential(\n","        (0): Conv2d(256, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","    )\n","  )\n","  (stage2): Sequential(\n","    (0): HighResolutionModule(\n","      (branches): ModuleList(\n","        (0): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","      (fuse_layers): ModuleList(\n","        (0): ModuleList(\n","          (0): None\n","          (1): Sequential(\n","            (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): ModuleList(\n","          (0): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): None\n","        )\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (transition2): ModuleList(\n","    (0): None\n","    (1): None\n","    (2): Sequential(\n","      (0): Sequential(\n","        (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","    )\n","  )\n","  (stage3): Sequential(\n","    (0): HighResolutionModule(\n","      (branches): ModuleList(\n","        (0): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","      (fuse_layers): ModuleList(\n","        (0): ModuleList(\n","          (0): None\n","          (1): Sequential(\n","            (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): Sequential(\n","            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): ModuleList(\n","          (0): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): None\n","          (2): Sequential(\n","            (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): ModuleList(\n","          (0): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU(inplace=True)\n","            )\n","            (1): Sequential(\n","              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (2): None\n","        )\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (1): HighResolutionModule(\n","      (branches): ModuleList(\n","        (0): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","      (fuse_layers): ModuleList(\n","        (0): ModuleList(\n","          (0): None\n","          (1): Sequential(\n","            (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): Sequential(\n","            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): ModuleList(\n","          (0): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): None\n","          (2): Sequential(\n","            (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): ModuleList(\n","          (0): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU(inplace=True)\n","            )\n","            (1): Sequential(\n","              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (2): None\n","        )\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): HighResolutionModule(\n","      (branches): ModuleList(\n","        (0): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","      (fuse_layers): ModuleList(\n","        (0): ModuleList(\n","          (0): None\n","          (1): Sequential(\n","            (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): Sequential(\n","            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): ModuleList(\n","          (0): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): None\n","          (2): Sequential(\n","            (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): ModuleList(\n","          (0): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU(inplace=True)\n","            )\n","            (1): Sequential(\n","              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (2): None\n","        )\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): HighResolutionModule(\n","      (branches): ModuleList(\n","        (0): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","      (fuse_layers): ModuleList(\n","        (0): ModuleList(\n","          (0): None\n","          (1): Sequential(\n","            (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): Sequential(\n","            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): ModuleList(\n","          (0): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): None\n","          (2): Sequential(\n","            (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): ModuleList(\n","          (0): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU(inplace=True)\n","            )\n","            (1): Sequential(\n","              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (2): None\n","        )\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (transition3): ModuleList(\n","    (0): None\n","    (1): None\n","    (2): None\n","    (3): Sequential(\n","      (0): Sequential(\n","        (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","    )\n","  )\n","  (stage4): Sequential(\n","    (0): HighResolutionModule(\n","      (branches): ModuleList(\n","        (0): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (3): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","      (fuse_layers): ModuleList(\n","        (0): ModuleList(\n","          (0): None\n","          (1): Sequential(\n","            (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): Sequential(\n","            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): Sequential(\n","            (0): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): ModuleList(\n","          (0): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): None\n","          (2): Sequential(\n","            (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): Sequential(\n","            (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): ModuleList(\n","          (0): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU(inplace=True)\n","            )\n","            (1): Sequential(\n","              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (2): None\n","          (3): Sequential(\n","            (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (3): ModuleList(\n","          (0): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU(inplace=True)\n","            )\n","            (1): Sequential(\n","              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU(inplace=True)\n","            )\n","            (2): Sequential(\n","              (0): Conv2d(48, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU(inplace=True)\n","            )\n","            (1): Sequential(\n","              (0): Conv2d(96, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (2): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (3): None\n","        )\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (1): HighResolutionModule(\n","      (branches): ModuleList(\n","        (0): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (3): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","      (fuse_layers): ModuleList(\n","        (0): ModuleList(\n","          (0): None\n","          (1): Sequential(\n","            (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): Sequential(\n","            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): Sequential(\n","            (0): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): ModuleList(\n","          (0): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): None\n","          (2): Sequential(\n","            (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): Sequential(\n","            (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): ModuleList(\n","          (0): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU(inplace=True)\n","            )\n","            (1): Sequential(\n","              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (2): None\n","          (3): Sequential(\n","            (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (3): ModuleList(\n","          (0): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU(inplace=True)\n","            )\n","            (1): Sequential(\n","              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU(inplace=True)\n","            )\n","            (2): Sequential(\n","              (0): Conv2d(48, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU(inplace=True)\n","            )\n","            (1): Sequential(\n","              (0): Conv2d(96, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (2): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (3): None\n","        )\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): HighResolutionModule(\n","      (branches): ModuleList(\n","        (0): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (3): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","      (fuse_layers): ModuleList(\n","        (0): ModuleList(\n","          (0): None\n","          (1): Sequential(\n","            (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (2): Sequential(\n","            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): Sequential(\n","            (0): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): ModuleList(\n","          (0): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): None\n","          (2): Sequential(\n","            (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","          (3): Sequential(\n","            (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): ModuleList(\n","          (0): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU(inplace=True)\n","            )\n","            (1): Sequential(\n","              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (2): None\n","          (3): Sequential(\n","            (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (3): ModuleList(\n","          (0): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU(inplace=True)\n","            )\n","            (1): Sequential(\n","              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU(inplace=True)\n","            )\n","            (2): Sequential(\n","              (0): Conv2d(48, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              (2): ReLU(inplace=True)\n","            )\n","            (1): Sequential(\n","              (0): Conv2d(96, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (2): Sequential(\n","            (0): Sequential(\n","              (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (1): SyncBatchNorm(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (3): None\n","        )\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (conv3x3_ocr): Sequential(\n","    (0): Conv2d(720, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (ocr_gather_head): SpatialGather_Module()\n","  (ocr_distri_head): SpatialOCR_Module(\n","    (object_context_block): ObjectAttentionBlock2D(\n","      (pool): MaxPool2d(kernel_size=(1, 1), stride=(1, 1), padding=0, dilation=1, ceil_mode=False)\n","      (f_pixel): Sequential(\n","        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): Sequential(\n","          (0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (1): ReLU()\n","        )\n","        (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): Sequential(\n","          (0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (1): ReLU()\n","        )\n","      )\n","      (f_object): Sequential(\n","        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): Sequential(\n","          (0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (1): ReLU()\n","        )\n","        (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (3): Sequential(\n","          (0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (1): ReLU()\n","        )\n","      )\n","      (f_down): Sequential(\n","        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): Sequential(\n","          (0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (1): ReLU()\n","        )\n","      )\n","      (f_up): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): Sequential(\n","          (0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (1): ReLU()\n","        )\n","      )\n","    )\n","    (conv_bn_dropout): Sequential(\n","      (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): Sequential(\n","        (0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (1): ReLU()\n","      )\n","      (2): Dropout2d(p=0.05, inplace=False)\n","    )\n","  )\n","  (cls_head): Conv2d(512, 19, kernel_size=(1, 1), stride=(1, 1))\n","  (aux_head): Sequential(\n","    (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1))\n","    (1): SyncBatchNorm(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Conv2d(720, 19, kernel_size=(1, 1), stride=(1, 1))\n","  )\n",")\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:492: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"]}]},{"cell_type":"code","source":["model.init_weights('hrnet_ocr_cs_8162_torch11.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yt29mkqpx6oK","executionInfo":{"status":"ok","timestamp":1661075901013,"user_tz":-540,"elapsed":1643,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"3ac360bc-33ba-479b-9407-7e14bbfa7f74"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["set()\n","{'loss.criterion0.weight', 'loss.criterion1.weight'}\n"]}]},{"cell_type":"code","source":["model.init_weights('pretrained_models/hrnetv2_w48_imagenet_pretrained.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_n5EVpK51sAT","executionInfo":{"status":"ok","timestamp":1661075917407,"user_tz":-540,"elapsed":1844,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"d4ef70af-fb34-4372-a30e-3d796e61411c"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["{'ocr_distri_head.object_context_block.f_pixel.1.0.weight', 'ocr_distri_head.object_context_block.f_up.0.weight', 'ocr_distri_head.object_context_block.f_pixel.2.weight', 'ocr_distri_head.object_context_block.f_pixel.1.0.bias', 'aux_head.0.weight', 'cls_head.bias', 'conv3x3_ocr.1.num_batches_tracked', 'ocr_distri_head.object_context_block.f_pixel.3.0.running_mean', 'ocr_distri_head.object_context_block.f_pixel.3.0.bias', 'ocr_distri_head.object_context_block.f_object.1.0.bias', 'cls_head.weight', 'aux_head.3.weight', 'aux_head.3.bias', 'conv3x3_ocr.1.running_var', 'ocr_distri_head.object_context_block.f_up.1.0.running_var', 'ocr_distri_head.conv_bn_dropout.1.0.running_var', 'conv3x3_ocr.1.running_mean', 'ocr_distri_head.object_context_block.f_object.3.0.bias', 'ocr_distri_head.object_context_block.f_object.2.weight', 'ocr_distri_head.object_context_block.f_pixel.1.0.running_var', 'ocr_distri_head.object_context_block.f_down.1.0.running_mean', 'ocr_distri_head.object_context_block.f_object.1.0.weight', 'ocr_distri_head.object_context_block.f_down.1.0.num_batches_tracked', 'ocr_distri_head.object_context_block.f_object.3.0.weight', 'ocr_distri_head.object_context_block.f_pixel.1.0.running_mean', 'ocr_distri_head.conv_bn_dropout.1.0.weight', 'ocr_distri_head.object_context_block.f_object.1.0.running_mean', 'conv3x3_ocr.1.bias', 'ocr_distri_head.object_context_block.f_down.1.0.bias', 'ocr_distri_head.object_context_block.f_pixel.1.0.num_batches_tracked', 'aux_head.0.bias', 'ocr_distri_head.object_context_block.f_down.0.weight', 'ocr_distri_head.conv_bn_dropout.1.0.running_mean', 'conv3x3_ocr.1.weight', 'ocr_distri_head.object_context_block.f_up.1.0.running_mean', 'ocr_distri_head.object_context_block.f_up.1.0.weight', 'ocr_distri_head.object_context_block.f_object.3.0.running_mean', 'aux_head.1.num_batches_tracked', 'ocr_distri_head.object_context_block.f_down.1.0.weight', 'ocr_distri_head.object_context_block.f_pixel.3.0.weight', 'conv3x3_ocr.0.bias', 'ocr_distri_head.object_context_block.f_object.1.0.running_var', 'aux_head.1.weight', 'aux_head.1.running_var', 'ocr_distri_head.object_context_block.f_up.1.0.bias', 'aux_head.1.running_mean', 'ocr_distri_head.object_context_block.f_object.0.weight', 'ocr_distri_head.object_context_block.f_up.1.0.num_batches_tracked', 'ocr_distri_head.object_context_block.f_object.3.0.running_var', 'ocr_distri_head.conv_bn_dropout.1.0.bias', 'ocr_distri_head.conv_bn_dropout.1.0.num_batches_tracked', 'ocr_distri_head.object_context_block.f_down.1.0.running_var', 'ocr_distri_head.conv_bn_dropout.0.weight', 'ocr_distri_head.object_context_block.f_object.3.0.num_batches_tracked', 'ocr_distri_head.object_context_block.f_pixel.3.0.num_batches_tracked', 'conv3x3_ocr.0.weight', 'ocr_distri_head.object_context_block.f_pixel.3.0.running_var', 'aux_head.1.bias', 'ocr_distri_head.object_context_block.f_object.1.0.num_batches_tracked', 'ocr_distri_head.object_context_block.f_pixel.0.weight'}\n","{'incre_modules.0.0.bn1.num_batches_tracked', 'incre_modules.2.0.bn3.num_batches_tracked', 'incre_modules.3.0.bn1.weight', 'incre_modules.2.0.downsample.1.running_var', 'incre_modules.3.0.bn2.weight', 'incre_modules.1.0.bn1.weight', 'incre_modules.2.0.conv1.weight', 'downsamp_modules.2.1.num_batches_tracked', 'incre_modules.3.0.bn3.weight', 'incre_modules.0.0.downsample.1.running_var', 'incre_modules.0.0.bn2.running_var', 'incre_modules.1.0.conv1.weight', 'incre_modules.3.0.downsample.1.weight', 'incre_modules.0.0.downsample.1.running_mean', 'incre_modules.1.0.downsample.1.weight', 'downsamp_modules.0.1.running_var', 'incre_modules.0.0.conv1.weight', 'downsamp_modules.0.0.bias', 'downsamp_modules.1.0.bias', 'incre_modules.1.0.bn3.weight', 'incre_modules.3.0.bn1.num_batches_tracked', 'incre_modules.3.0.downsample.1.num_batches_tracked', 'classifier.weight', 'classifier.bias', 'incre_modules.0.0.bn3.num_batches_tracked', 'incre_modules.1.0.downsample.0.weight', 'downsamp_modules.0.1.weight', 'incre_modules.1.0.bn2.running_var', 'incre_modules.3.0.bn2.running_mean', 'incre_modules.1.0.bn3.running_var', 'incre_modules.2.0.downsample.0.weight', 'incre_modules.3.0.bn1.bias', 'incre_modules.1.0.downsample.1.running_mean', 'downsamp_modules.0.0.weight', 'downsamp_modules.1.1.running_mean', 'incre_modules.1.0.bn1.running_mean', 'incre_modules.1.0.conv3.weight', 'incre_modules.3.0.bn1.running_var', 'incre_modules.3.0.bn2.running_var', 'downsamp_modules.0.1.running_mean', 'incre_modules.2.0.bn1.weight', 'incre_modules.0.0.bn3.bias', 'downsamp_modules.0.1.bias', 'incre_modules.2.0.bn2.weight', 'final_layer.1.num_batches_tracked', 'incre_modules.1.0.bn3.num_batches_tracked', 'incre_modules.0.0.bn1.weight', 'incre_modules.1.0.bn3.running_mean', 'downsamp_modules.2.1.weight', 'downsamp_modules.2.1.bias', 'incre_modules.1.0.bn2.weight', 'incre_modules.2.0.bn3.running_mean', 'incre_modules.0.0.bn2.num_batches_tracked', 'incre_modules.0.0.bn3.weight', 'incre_modules.0.0.downsample.1.bias', 'downsamp_modules.1.0.weight', 'incre_modules.2.0.bn1.bias', 'incre_modules.3.0.downsample.1.bias', 'incre_modules.0.0.bn3.running_var', 'incre_modules.0.0.conv3.weight', 'incre_modules.1.0.bn1.running_var', 'incre_modules.3.0.downsample.0.weight', 'incre_modules.0.0.bn2.bias', 'incre_modules.1.0.downsample.1.num_batches_tracked', 'incre_modules.3.0.bn1.running_mean', 'downsamp_modules.1.1.weight', 'incre_modules.3.0.downsample.1.running_mean', 'incre_modules.3.0.conv3.weight', 'final_layer.0.bias', 'incre_modules.0.0.bn3.running_mean', 'final_layer.0.weight', 'downsamp_modules.2.0.bias', 'incre_modules.0.0.downsample.1.num_batches_tracked', 'incre_modules.3.0.bn2.num_batches_tracked', 'incre_modules.3.0.bn2.bias', 'incre_modules.0.0.bn2.running_mean', 'incre_modules.1.0.bn2.running_mean', 'downsamp_modules.0.1.num_batches_tracked', 'final_layer.1.running_var', 'incre_modules.3.0.downsample.1.running_var', 'incre_modules.3.0.conv2.weight', 'incre_modules.1.0.bn3.bias', 'incre_modules.2.0.downsample.1.running_mean', 'incre_modules.2.0.conv3.weight', 'incre_modules.3.0.bn3.num_batches_tracked', 'incre_modules.1.0.bn1.bias', 'incre_modules.0.0.conv2.weight', 'incre_modules.1.0.conv2.weight', 'incre_modules.2.0.bn1.running_var', 'downsamp_modules.2.1.running_var', 'incre_modules.2.0.bn1.running_mean', 'downsamp_modules.2.0.weight', 'downsamp_modules.1.1.bias', 'incre_modules.0.0.bn1.bias', 'downsamp_modules.1.1.num_batches_tracked', 'incre_modules.2.0.bn2.num_batches_tracked', 'incre_modules.3.0.bn3.running_var', 'incre_modules.2.0.bn1.num_batches_tracked', 'final_layer.1.running_mean', 'incre_modules.0.0.bn1.running_var', 'incre_modules.2.0.bn2.bias', 'incre_modules.2.0.bn2.running_mean', 'incre_modules.1.0.bn1.num_batches_tracked', 'incre_modules.1.0.downsample.1.bias', 'incre_modules.2.0.downsample.1.bias', 'incre_modules.1.0.bn2.num_batches_tracked', 'incre_modules.2.0.downsample.1.weight', 'incre_modules.3.0.bn3.bias', 'incre_modules.2.0.downsample.1.num_batches_tracked', 'downsamp_modules.2.1.running_mean', 'final_layer.1.weight', 'downsamp_modules.1.1.running_var', 'incre_modules.2.0.conv2.weight', 'final_layer.1.bias', 'incre_modules.3.0.conv1.weight', 'incre_modules.0.0.bn1.running_mean', 'incre_modules.0.0.downsample.1.weight', 'incre_modules.1.0.downsample.1.running_var', 'incre_modules.0.0.bn2.weight', 'incre_modules.1.0.bn2.bias', 'incre_modules.0.0.downsample.0.weight', 'incre_modules.2.0.bn3.weight', 'incre_modules.2.0.bn2.running_var', 'incre_modules.3.0.bn3.running_mean', 'incre_modules.2.0.bn3.running_var', 'incre_modules.2.0.bn3.bias'}\n"]}]},{"cell_type":"code","source":["for name, param in model.named_parameters():\n","    print('layer name:', name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qL7ssVtI1v0r","executionInfo":{"status":"ok","timestamp":1661075948562,"user_tz":-540,"elapsed":454,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"0ff2d59e-f069-479a-fee5-82f6c63454c0"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["layer name: conv1.weight\n","layer name: bn1.weight\n","layer name: bn1.bias\n","layer name: conv2.weight\n","layer name: bn2.weight\n","layer name: bn2.bias\n","layer name: layer1.0.conv1.weight\n","layer name: layer1.0.bn1.weight\n","layer name: layer1.0.bn1.bias\n","layer name: layer1.0.conv2.weight\n","layer name: layer1.0.bn2.weight\n","layer name: layer1.0.bn2.bias\n","layer name: layer1.0.conv3.weight\n","layer name: layer1.0.bn3.weight\n","layer name: layer1.0.bn3.bias\n","layer name: layer1.0.downsample.0.weight\n","layer name: layer1.0.downsample.1.weight\n","layer name: layer1.0.downsample.1.bias\n","layer name: layer1.1.conv1.weight\n","layer name: layer1.1.bn1.weight\n","layer name: layer1.1.bn1.bias\n","layer name: layer1.1.conv2.weight\n","layer name: layer1.1.bn2.weight\n","layer name: layer1.1.bn2.bias\n","layer name: layer1.1.conv3.weight\n","layer name: layer1.1.bn3.weight\n","layer name: layer1.1.bn3.bias\n","layer name: layer1.2.conv1.weight\n","layer name: layer1.2.bn1.weight\n","layer name: layer1.2.bn1.bias\n","layer name: layer1.2.conv2.weight\n","layer name: layer1.2.bn2.weight\n","layer name: layer1.2.bn2.bias\n","layer name: layer1.2.conv3.weight\n","layer name: layer1.2.bn3.weight\n","layer name: layer1.2.bn3.bias\n","layer name: layer1.3.conv1.weight\n","layer name: layer1.3.bn1.weight\n","layer name: layer1.3.bn1.bias\n","layer name: layer1.3.conv2.weight\n","layer name: layer1.3.bn2.weight\n","layer name: layer1.3.bn2.bias\n","layer name: layer1.3.conv3.weight\n","layer name: layer1.3.bn3.weight\n","layer name: layer1.3.bn3.bias\n","layer name: transition1.0.0.weight\n","layer name: transition1.0.1.weight\n","layer name: transition1.0.1.bias\n","layer name: transition1.1.0.0.weight\n","layer name: transition1.1.0.1.weight\n","layer name: transition1.1.0.1.bias\n","layer name: stage2.0.branches.0.0.conv1.weight\n","layer name: stage2.0.branches.0.0.bn1.weight\n","layer name: stage2.0.branches.0.0.bn1.bias\n","layer name: stage2.0.branches.0.0.conv2.weight\n","layer name: stage2.0.branches.0.0.bn2.weight\n","layer name: stage2.0.branches.0.0.bn2.bias\n","layer name: stage2.0.branches.0.1.conv1.weight\n","layer name: stage2.0.branches.0.1.bn1.weight\n","layer name: stage2.0.branches.0.1.bn1.bias\n","layer name: stage2.0.branches.0.1.conv2.weight\n","layer name: stage2.0.branches.0.1.bn2.weight\n","layer name: stage2.0.branches.0.1.bn2.bias\n","layer name: stage2.0.branches.0.2.conv1.weight\n","layer name: stage2.0.branches.0.2.bn1.weight\n","layer name: stage2.0.branches.0.2.bn1.bias\n","layer name: stage2.0.branches.0.2.conv2.weight\n","layer name: stage2.0.branches.0.2.bn2.weight\n","layer name: stage2.0.branches.0.2.bn2.bias\n","layer name: stage2.0.branches.0.3.conv1.weight\n","layer name: stage2.0.branches.0.3.bn1.weight\n","layer name: stage2.0.branches.0.3.bn1.bias\n","layer name: stage2.0.branches.0.3.conv2.weight\n","layer name: stage2.0.branches.0.3.bn2.weight\n","layer name: stage2.0.branches.0.3.bn2.bias\n","layer name: stage2.0.branches.1.0.conv1.weight\n","layer name: stage2.0.branches.1.0.bn1.weight\n","layer name: stage2.0.branches.1.0.bn1.bias\n","layer name: stage2.0.branches.1.0.conv2.weight\n","layer name: stage2.0.branches.1.0.bn2.weight\n","layer name: stage2.0.branches.1.0.bn2.bias\n","layer name: stage2.0.branches.1.1.conv1.weight\n","layer name: stage2.0.branches.1.1.bn1.weight\n","layer name: stage2.0.branches.1.1.bn1.bias\n","layer name: stage2.0.branches.1.1.conv2.weight\n","layer name: stage2.0.branches.1.1.bn2.weight\n","layer name: stage2.0.branches.1.1.bn2.bias\n","layer name: stage2.0.branches.1.2.conv1.weight\n","layer name: stage2.0.branches.1.2.bn1.weight\n","layer name: stage2.0.branches.1.2.bn1.bias\n","layer name: stage2.0.branches.1.2.conv2.weight\n","layer name: stage2.0.branches.1.2.bn2.weight\n","layer name: stage2.0.branches.1.2.bn2.bias\n","layer name: stage2.0.branches.1.3.conv1.weight\n","layer name: stage2.0.branches.1.3.bn1.weight\n","layer name: stage2.0.branches.1.3.bn1.bias\n","layer name: stage2.0.branches.1.3.conv2.weight\n","layer name: stage2.0.branches.1.3.bn2.weight\n","layer name: stage2.0.branches.1.3.bn2.bias\n","layer name: stage2.0.fuse_layers.0.1.0.weight\n","layer name: stage2.0.fuse_layers.0.1.1.weight\n","layer name: stage2.0.fuse_layers.0.1.1.bias\n","layer name: stage2.0.fuse_layers.1.0.0.0.weight\n","layer name: stage2.0.fuse_layers.1.0.0.1.weight\n","layer name: stage2.0.fuse_layers.1.0.0.1.bias\n","layer name: transition2.2.0.0.weight\n","layer name: transition2.2.0.1.weight\n","layer name: transition2.2.0.1.bias\n","layer name: stage3.0.branches.0.0.conv1.weight\n","layer name: stage3.0.branches.0.0.bn1.weight\n","layer name: stage3.0.branches.0.0.bn1.bias\n","layer name: stage3.0.branches.0.0.conv2.weight\n","layer name: stage3.0.branches.0.0.bn2.weight\n","layer name: stage3.0.branches.0.0.bn2.bias\n","layer name: stage3.0.branches.0.1.conv1.weight\n","layer name: stage3.0.branches.0.1.bn1.weight\n","layer name: stage3.0.branches.0.1.bn1.bias\n","layer name: stage3.0.branches.0.1.conv2.weight\n","layer name: stage3.0.branches.0.1.bn2.weight\n","layer name: stage3.0.branches.0.1.bn2.bias\n","layer name: stage3.0.branches.0.2.conv1.weight\n","layer name: stage3.0.branches.0.2.bn1.weight\n","layer name: stage3.0.branches.0.2.bn1.bias\n","layer name: stage3.0.branches.0.2.conv2.weight\n","layer name: stage3.0.branches.0.2.bn2.weight\n","layer name: stage3.0.branches.0.2.bn2.bias\n","layer name: stage3.0.branches.0.3.conv1.weight\n","layer name: stage3.0.branches.0.3.bn1.weight\n","layer name: stage3.0.branches.0.3.bn1.bias\n","layer name: stage3.0.branches.0.3.conv2.weight\n","layer name: stage3.0.branches.0.3.bn2.weight\n","layer name: stage3.0.branches.0.3.bn2.bias\n","layer name: stage3.0.branches.1.0.conv1.weight\n","layer name: stage3.0.branches.1.0.bn1.weight\n","layer name: stage3.0.branches.1.0.bn1.bias\n","layer name: stage3.0.branches.1.0.conv2.weight\n","layer name: stage3.0.branches.1.0.bn2.weight\n","layer name: stage3.0.branches.1.0.bn2.bias\n","layer name: stage3.0.branches.1.1.conv1.weight\n","layer name: stage3.0.branches.1.1.bn1.weight\n","layer name: stage3.0.branches.1.1.bn1.bias\n","layer name: stage3.0.branches.1.1.conv2.weight\n","layer name: stage3.0.branches.1.1.bn2.weight\n","layer name: stage3.0.branches.1.1.bn2.bias\n","layer name: stage3.0.branches.1.2.conv1.weight\n","layer name: stage3.0.branches.1.2.bn1.weight\n","layer name: stage3.0.branches.1.2.bn1.bias\n","layer name: stage3.0.branches.1.2.conv2.weight\n","layer name: stage3.0.branches.1.2.bn2.weight\n","layer name: stage3.0.branches.1.2.bn2.bias\n","layer name: stage3.0.branches.1.3.conv1.weight\n","layer name: stage3.0.branches.1.3.bn1.weight\n","layer name: stage3.0.branches.1.3.bn1.bias\n","layer name: stage3.0.branches.1.3.conv2.weight\n","layer name: stage3.0.branches.1.3.bn2.weight\n","layer name: stage3.0.branches.1.3.bn2.bias\n","layer name: stage3.0.branches.2.0.conv1.weight\n","layer name: stage3.0.branches.2.0.bn1.weight\n","layer name: stage3.0.branches.2.0.bn1.bias\n","layer name: stage3.0.branches.2.0.conv2.weight\n","layer name: stage3.0.branches.2.0.bn2.weight\n","layer name: stage3.0.branches.2.0.bn2.bias\n","layer name: stage3.0.branches.2.1.conv1.weight\n","layer name: stage3.0.branches.2.1.bn1.weight\n","layer name: stage3.0.branches.2.1.bn1.bias\n","layer name: stage3.0.branches.2.1.conv2.weight\n","layer name: stage3.0.branches.2.1.bn2.weight\n","layer name: stage3.0.branches.2.1.bn2.bias\n","layer name: stage3.0.branches.2.2.conv1.weight\n","layer name: stage3.0.branches.2.2.bn1.weight\n","layer name: stage3.0.branches.2.2.bn1.bias\n","layer name: stage3.0.branches.2.2.conv2.weight\n","layer name: stage3.0.branches.2.2.bn2.weight\n","layer name: stage3.0.branches.2.2.bn2.bias\n","layer name: stage3.0.branches.2.3.conv1.weight\n","layer name: stage3.0.branches.2.3.bn1.weight\n","layer name: stage3.0.branches.2.3.bn1.bias\n","layer name: stage3.0.branches.2.3.conv2.weight\n","layer name: stage3.0.branches.2.3.bn2.weight\n","layer name: stage3.0.branches.2.3.bn2.bias\n","layer name: stage3.0.fuse_layers.0.1.0.weight\n","layer name: stage3.0.fuse_layers.0.1.1.weight\n","layer name: stage3.0.fuse_layers.0.1.1.bias\n","layer name: stage3.0.fuse_layers.0.2.0.weight\n","layer name: stage3.0.fuse_layers.0.2.1.weight\n","layer name: stage3.0.fuse_layers.0.2.1.bias\n","layer name: stage3.0.fuse_layers.1.0.0.0.weight\n","layer name: stage3.0.fuse_layers.1.0.0.1.weight\n","layer name: stage3.0.fuse_layers.1.0.0.1.bias\n","layer name: stage3.0.fuse_layers.1.2.0.weight\n","layer name: stage3.0.fuse_layers.1.2.1.weight\n","layer name: stage3.0.fuse_layers.1.2.1.bias\n","layer name: stage3.0.fuse_layers.2.0.0.0.weight\n","layer name: stage3.0.fuse_layers.2.0.0.1.weight\n","layer name: stage3.0.fuse_layers.2.0.0.1.bias\n","layer name: stage3.0.fuse_layers.2.0.1.0.weight\n","layer name: stage3.0.fuse_layers.2.0.1.1.weight\n","layer name: stage3.0.fuse_layers.2.0.1.1.bias\n","layer name: stage3.0.fuse_layers.2.1.0.0.weight\n","layer name: stage3.0.fuse_layers.2.1.0.1.weight\n","layer name: stage3.0.fuse_layers.2.1.0.1.bias\n","layer name: stage3.1.branches.0.0.conv1.weight\n","layer name: stage3.1.branches.0.0.bn1.weight\n","layer name: stage3.1.branches.0.0.bn1.bias\n","layer name: stage3.1.branches.0.0.conv2.weight\n","layer name: stage3.1.branches.0.0.bn2.weight\n","layer name: stage3.1.branches.0.0.bn2.bias\n","layer name: stage3.1.branches.0.1.conv1.weight\n","layer name: stage3.1.branches.0.1.bn1.weight\n","layer name: stage3.1.branches.0.1.bn1.bias\n","layer name: stage3.1.branches.0.1.conv2.weight\n","layer name: stage3.1.branches.0.1.bn2.weight\n","layer name: stage3.1.branches.0.1.bn2.bias\n","layer name: stage3.1.branches.0.2.conv1.weight\n","layer name: stage3.1.branches.0.2.bn1.weight\n","layer name: stage3.1.branches.0.2.bn1.bias\n","layer name: stage3.1.branches.0.2.conv2.weight\n","layer name: stage3.1.branches.0.2.bn2.weight\n","layer name: stage3.1.branches.0.2.bn2.bias\n","layer name: stage3.1.branches.0.3.conv1.weight\n","layer name: stage3.1.branches.0.3.bn1.weight\n","layer name: stage3.1.branches.0.3.bn1.bias\n","layer name: stage3.1.branches.0.3.conv2.weight\n","layer name: stage3.1.branches.0.3.bn2.weight\n","layer name: stage3.1.branches.0.3.bn2.bias\n","layer name: stage3.1.branches.1.0.conv1.weight\n","layer name: stage3.1.branches.1.0.bn1.weight\n","layer name: stage3.1.branches.1.0.bn1.bias\n","layer name: stage3.1.branches.1.0.conv2.weight\n","layer name: stage3.1.branches.1.0.bn2.weight\n","layer name: stage3.1.branches.1.0.bn2.bias\n","layer name: stage3.1.branches.1.1.conv1.weight\n","layer name: stage3.1.branches.1.1.bn1.weight\n","layer name: stage3.1.branches.1.1.bn1.bias\n","layer name: stage3.1.branches.1.1.conv2.weight\n","layer name: stage3.1.branches.1.1.bn2.weight\n","layer name: stage3.1.branches.1.1.bn2.bias\n","layer name: stage3.1.branches.1.2.conv1.weight\n","layer name: stage3.1.branches.1.2.bn1.weight\n","layer name: stage3.1.branches.1.2.bn1.bias\n","layer name: stage3.1.branches.1.2.conv2.weight\n","layer name: stage3.1.branches.1.2.bn2.weight\n","layer name: stage3.1.branches.1.2.bn2.bias\n","layer name: stage3.1.branches.1.3.conv1.weight\n","layer name: stage3.1.branches.1.3.bn1.weight\n","layer name: stage3.1.branches.1.3.bn1.bias\n","layer name: stage3.1.branches.1.3.conv2.weight\n","layer name: stage3.1.branches.1.3.bn2.weight\n","layer name: stage3.1.branches.1.3.bn2.bias\n","layer name: stage3.1.branches.2.0.conv1.weight\n","layer name: stage3.1.branches.2.0.bn1.weight\n","layer name: stage3.1.branches.2.0.bn1.bias\n","layer name: stage3.1.branches.2.0.conv2.weight\n","layer name: stage3.1.branches.2.0.bn2.weight\n","layer name: stage3.1.branches.2.0.bn2.bias\n","layer name: stage3.1.branches.2.1.conv1.weight\n","layer name: stage3.1.branches.2.1.bn1.weight\n","layer name: stage3.1.branches.2.1.bn1.bias\n","layer name: stage3.1.branches.2.1.conv2.weight\n","layer name: stage3.1.branches.2.1.bn2.weight\n","layer name: stage3.1.branches.2.1.bn2.bias\n","layer name: stage3.1.branches.2.2.conv1.weight\n","layer name: stage3.1.branches.2.2.bn1.weight\n","layer name: stage3.1.branches.2.2.bn1.bias\n","layer name: stage3.1.branches.2.2.conv2.weight\n","layer name: stage3.1.branches.2.2.bn2.weight\n","layer name: stage3.1.branches.2.2.bn2.bias\n","layer name: stage3.1.branches.2.3.conv1.weight\n","layer name: stage3.1.branches.2.3.bn1.weight\n","layer name: stage3.1.branches.2.3.bn1.bias\n","layer name: stage3.1.branches.2.3.conv2.weight\n","layer name: stage3.1.branches.2.3.bn2.weight\n","layer name: stage3.1.branches.2.3.bn2.bias\n","layer name: stage3.1.fuse_layers.0.1.0.weight\n","layer name: stage3.1.fuse_layers.0.1.1.weight\n","layer name: stage3.1.fuse_layers.0.1.1.bias\n","layer name: stage3.1.fuse_layers.0.2.0.weight\n","layer name: stage3.1.fuse_layers.0.2.1.weight\n","layer name: stage3.1.fuse_layers.0.2.1.bias\n","layer name: stage3.1.fuse_layers.1.0.0.0.weight\n","layer name: stage3.1.fuse_layers.1.0.0.1.weight\n","layer name: stage3.1.fuse_layers.1.0.0.1.bias\n","layer name: stage3.1.fuse_layers.1.2.0.weight\n","layer name: stage3.1.fuse_layers.1.2.1.weight\n","layer name: stage3.1.fuse_layers.1.2.1.bias\n","layer name: stage3.1.fuse_layers.2.0.0.0.weight\n","layer name: stage3.1.fuse_layers.2.0.0.1.weight\n","layer name: stage3.1.fuse_layers.2.0.0.1.bias\n","layer name: stage3.1.fuse_layers.2.0.1.0.weight\n","layer name: stage3.1.fuse_layers.2.0.1.1.weight\n","layer name: stage3.1.fuse_layers.2.0.1.1.bias\n","layer name: stage3.1.fuse_layers.2.1.0.0.weight\n","layer name: stage3.1.fuse_layers.2.1.0.1.weight\n","layer name: stage3.1.fuse_layers.2.1.0.1.bias\n","layer name: stage3.2.branches.0.0.conv1.weight\n","layer name: stage3.2.branches.0.0.bn1.weight\n","layer name: stage3.2.branches.0.0.bn1.bias\n","layer name: stage3.2.branches.0.0.conv2.weight\n","layer name: stage3.2.branches.0.0.bn2.weight\n","layer name: stage3.2.branches.0.0.bn2.bias\n","layer name: stage3.2.branches.0.1.conv1.weight\n","layer name: stage3.2.branches.0.1.bn1.weight\n","layer name: stage3.2.branches.0.1.bn1.bias\n","layer name: stage3.2.branches.0.1.conv2.weight\n","layer name: stage3.2.branches.0.1.bn2.weight\n","layer name: stage3.2.branches.0.1.bn2.bias\n","layer name: stage3.2.branches.0.2.conv1.weight\n","layer name: stage3.2.branches.0.2.bn1.weight\n","layer name: stage3.2.branches.0.2.bn1.bias\n","layer name: stage3.2.branches.0.2.conv2.weight\n","layer name: stage3.2.branches.0.2.bn2.weight\n","layer name: stage3.2.branches.0.2.bn2.bias\n","layer name: stage3.2.branches.0.3.conv1.weight\n","layer name: stage3.2.branches.0.3.bn1.weight\n","layer name: stage3.2.branches.0.3.bn1.bias\n","layer name: stage3.2.branches.0.3.conv2.weight\n","layer name: stage3.2.branches.0.3.bn2.weight\n","layer name: stage3.2.branches.0.3.bn2.bias\n","layer name: stage3.2.branches.1.0.conv1.weight\n","layer name: stage3.2.branches.1.0.bn1.weight\n","layer name: stage3.2.branches.1.0.bn1.bias\n","layer name: stage3.2.branches.1.0.conv2.weight\n","layer name: stage3.2.branches.1.0.bn2.weight\n","layer name: stage3.2.branches.1.0.bn2.bias\n","layer name: stage3.2.branches.1.1.conv1.weight\n","layer name: stage3.2.branches.1.1.bn1.weight\n","layer name: stage3.2.branches.1.1.bn1.bias\n","layer name: stage3.2.branches.1.1.conv2.weight\n","layer name: stage3.2.branches.1.1.bn2.weight\n","layer name: stage3.2.branches.1.1.bn2.bias\n","layer name: stage3.2.branches.1.2.conv1.weight\n","layer name: stage3.2.branches.1.2.bn1.weight\n","layer name: stage3.2.branches.1.2.bn1.bias\n","layer name: stage3.2.branches.1.2.conv2.weight\n","layer name: stage3.2.branches.1.2.bn2.weight\n","layer name: stage3.2.branches.1.2.bn2.bias\n","layer name: stage3.2.branches.1.3.conv1.weight\n","layer name: stage3.2.branches.1.3.bn1.weight\n","layer name: stage3.2.branches.1.3.bn1.bias\n","layer name: stage3.2.branches.1.3.conv2.weight\n","layer name: stage3.2.branches.1.3.bn2.weight\n","layer name: stage3.2.branches.1.3.bn2.bias\n","layer name: stage3.2.branches.2.0.conv1.weight\n","layer name: stage3.2.branches.2.0.bn1.weight\n","layer name: stage3.2.branches.2.0.bn1.bias\n","layer name: stage3.2.branches.2.0.conv2.weight\n","layer name: stage3.2.branches.2.0.bn2.weight\n","layer name: stage3.2.branches.2.0.bn2.bias\n","layer name: stage3.2.branches.2.1.conv1.weight\n","layer name: stage3.2.branches.2.1.bn1.weight\n","layer name: stage3.2.branches.2.1.bn1.bias\n","layer name: stage3.2.branches.2.1.conv2.weight\n","layer name: stage3.2.branches.2.1.bn2.weight\n","layer name: stage3.2.branches.2.1.bn2.bias\n","layer name: stage3.2.branches.2.2.conv1.weight\n","layer name: stage3.2.branches.2.2.bn1.weight\n","layer name: stage3.2.branches.2.2.bn1.bias\n","layer name: stage3.2.branches.2.2.conv2.weight\n","layer name: stage3.2.branches.2.2.bn2.weight\n","layer name: stage3.2.branches.2.2.bn2.bias\n","layer name: stage3.2.branches.2.3.conv1.weight\n","layer name: stage3.2.branches.2.3.bn1.weight\n","layer name: stage3.2.branches.2.3.bn1.bias\n","layer name: stage3.2.branches.2.3.conv2.weight\n","layer name: stage3.2.branches.2.3.bn2.weight\n","layer name: stage3.2.branches.2.3.bn2.bias\n","layer name: stage3.2.fuse_layers.0.1.0.weight\n","layer name: stage3.2.fuse_layers.0.1.1.weight\n","layer name: stage3.2.fuse_layers.0.1.1.bias\n","layer name: stage3.2.fuse_layers.0.2.0.weight\n","layer name: stage3.2.fuse_layers.0.2.1.weight\n","layer name: stage3.2.fuse_layers.0.2.1.bias\n","layer name: stage3.2.fuse_layers.1.0.0.0.weight\n","layer name: stage3.2.fuse_layers.1.0.0.1.weight\n","layer name: stage3.2.fuse_layers.1.0.0.1.bias\n","layer name: stage3.2.fuse_layers.1.2.0.weight\n","layer name: stage3.2.fuse_layers.1.2.1.weight\n","layer name: stage3.2.fuse_layers.1.2.1.bias\n","layer name: stage3.2.fuse_layers.2.0.0.0.weight\n","layer name: stage3.2.fuse_layers.2.0.0.1.weight\n","layer name: stage3.2.fuse_layers.2.0.0.1.bias\n","layer name: stage3.2.fuse_layers.2.0.1.0.weight\n","layer name: stage3.2.fuse_layers.2.0.1.1.weight\n","layer name: stage3.2.fuse_layers.2.0.1.1.bias\n","layer name: stage3.2.fuse_layers.2.1.0.0.weight\n","layer name: stage3.2.fuse_layers.2.1.0.1.weight\n","layer name: stage3.2.fuse_layers.2.1.0.1.bias\n","layer name: stage3.3.branches.0.0.conv1.weight\n","layer name: stage3.3.branches.0.0.bn1.weight\n","layer name: stage3.3.branches.0.0.bn1.bias\n","layer name: stage3.3.branches.0.0.conv2.weight\n","layer name: stage3.3.branches.0.0.bn2.weight\n","layer name: stage3.3.branches.0.0.bn2.bias\n","layer name: stage3.3.branches.0.1.conv1.weight\n","layer name: stage3.3.branches.0.1.bn1.weight\n","layer name: stage3.3.branches.0.1.bn1.bias\n","layer name: stage3.3.branches.0.1.conv2.weight\n","layer name: stage3.3.branches.0.1.bn2.weight\n","layer name: stage3.3.branches.0.1.bn2.bias\n","layer name: stage3.3.branches.0.2.conv1.weight\n","layer name: stage3.3.branches.0.2.bn1.weight\n","layer name: stage3.3.branches.0.2.bn1.bias\n","layer name: stage3.3.branches.0.2.conv2.weight\n","layer name: stage3.3.branches.0.2.bn2.weight\n","layer name: stage3.3.branches.0.2.bn2.bias\n","layer name: stage3.3.branches.0.3.conv1.weight\n","layer name: stage3.3.branches.0.3.bn1.weight\n","layer name: stage3.3.branches.0.3.bn1.bias\n","layer name: stage3.3.branches.0.3.conv2.weight\n","layer name: stage3.3.branches.0.3.bn2.weight\n","layer name: stage3.3.branches.0.3.bn2.bias\n","layer name: stage3.3.branches.1.0.conv1.weight\n","layer name: stage3.3.branches.1.0.bn1.weight\n","layer name: stage3.3.branches.1.0.bn1.bias\n","layer name: stage3.3.branches.1.0.conv2.weight\n","layer name: stage3.3.branches.1.0.bn2.weight\n","layer name: stage3.3.branches.1.0.bn2.bias\n","layer name: stage3.3.branches.1.1.conv1.weight\n","layer name: stage3.3.branches.1.1.bn1.weight\n","layer name: stage3.3.branches.1.1.bn1.bias\n","layer name: stage3.3.branches.1.1.conv2.weight\n","layer name: stage3.3.branches.1.1.bn2.weight\n","layer name: stage3.3.branches.1.1.bn2.bias\n","layer name: stage3.3.branches.1.2.conv1.weight\n","layer name: stage3.3.branches.1.2.bn1.weight\n","layer name: stage3.3.branches.1.2.bn1.bias\n","layer name: stage3.3.branches.1.2.conv2.weight\n","layer name: stage3.3.branches.1.2.bn2.weight\n","layer name: stage3.3.branches.1.2.bn2.bias\n","layer name: stage3.3.branches.1.3.conv1.weight\n","layer name: stage3.3.branches.1.3.bn1.weight\n","layer name: stage3.3.branches.1.3.bn1.bias\n","layer name: stage3.3.branches.1.3.conv2.weight\n","layer name: stage3.3.branches.1.3.bn2.weight\n","layer name: stage3.3.branches.1.3.bn2.bias\n","layer name: stage3.3.branches.2.0.conv1.weight\n","layer name: stage3.3.branches.2.0.bn1.weight\n","layer name: stage3.3.branches.2.0.bn1.bias\n","layer name: stage3.3.branches.2.0.conv2.weight\n","layer name: stage3.3.branches.2.0.bn2.weight\n","layer name: stage3.3.branches.2.0.bn2.bias\n","layer name: stage3.3.branches.2.1.conv1.weight\n","layer name: stage3.3.branches.2.1.bn1.weight\n","layer name: stage3.3.branches.2.1.bn1.bias\n","layer name: stage3.3.branches.2.1.conv2.weight\n","layer name: stage3.3.branches.2.1.bn2.weight\n","layer name: stage3.3.branches.2.1.bn2.bias\n","layer name: stage3.3.branches.2.2.conv1.weight\n","layer name: stage3.3.branches.2.2.bn1.weight\n","layer name: stage3.3.branches.2.2.bn1.bias\n","layer name: stage3.3.branches.2.2.conv2.weight\n","layer name: stage3.3.branches.2.2.bn2.weight\n","layer name: stage3.3.branches.2.2.bn2.bias\n","layer name: stage3.3.branches.2.3.conv1.weight\n","layer name: stage3.3.branches.2.3.bn1.weight\n","layer name: stage3.3.branches.2.3.bn1.bias\n","layer name: stage3.3.branches.2.3.conv2.weight\n","layer name: stage3.3.branches.2.3.bn2.weight\n","layer name: stage3.3.branches.2.3.bn2.bias\n","layer name: stage3.3.fuse_layers.0.1.0.weight\n","layer name: stage3.3.fuse_layers.0.1.1.weight\n","layer name: stage3.3.fuse_layers.0.1.1.bias\n","layer name: stage3.3.fuse_layers.0.2.0.weight\n","layer name: stage3.3.fuse_layers.0.2.1.weight\n","layer name: stage3.3.fuse_layers.0.2.1.bias\n","layer name: stage3.3.fuse_layers.1.0.0.0.weight\n","layer name: stage3.3.fuse_layers.1.0.0.1.weight\n","layer name: stage3.3.fuse_layers.1.0.0.1.bias\n","layer name: stage3.3.fuse_layers.1.2.0.weight\n","layer name: stage3.3.fuse_layers.1.2.1.weight\n","layer name: stage3.3.fuse_layers.1.2.1.bias\n","layer name: stage3.3.fuse_layers.2.0.0.0.weight\n","layer name: stage3.3.fuse_layers.2.0.0.1.weight\n","layer name: stage3.3.fuse_layers.2.0.0.1.bias\n","layer name: stage3.3.fuse_layers.2.0.1.0.weight\n","layer name: stage3.3.fuse_layers.2.0.1.1.weight\n","layer name: stage3.3.fuse_layers.2.0.1.1.bias\n","layer name: stage3.3.fuse_layers.2.1.0.0.weight\n","layer name: stage3.3.fuse_layers.2.1.0.1.weight\n","layer name: stage3.3.fuse_layers.2.1.0.1.bias\n","layer name: transition3.3.0.0.weight\n","layer name: transition3.3.0.1.weight\n","layer name: transition3.3.0.1.bias\n","layer name: stage4.0.branches.0.0.conv1.weight\n","layer name: stage4.0.branches.0.0.bn1.weight\n","layer name: stage4.0.branches.0.0.bn1.bias\n","layer name: stage4.0.branches.0.0.conv2.weight\n","layer name: stage4.0.branches.0.0.bn2.weight\n","layer name: stage4.0.branches.0.0.bn2.bias\n","layer name: stage4.0.branches.0.1.conv1.weight\n","layer name: stage4.0.branches.0.1.bn1.weight\n","layer name: stage4.0.branches.0.1.bn1.bias\n","layer name: stage4.0.branches.0.1.conv2.weight\n","layer name: stage4.0.branches.0.1.bn2.weight\n","layer name: stage4.0.branches.0.1.bn2.bias\n","layer name: stage4.0.branches.0.2.conv1.weight\n","layer name: stage4.0.branches.0.2.bn1.weight\n","layer name: stage4.0.branches.0.2.bn1.bias\n","layer name: stage4.0.branches.0.2.conv2.weight\n","layer name: stage4.0.branches.0.2.bn2.weight\n","layer name: stage4.0.branches.0.2.bn2.bias\n","layer name: stage4.0.branches.0.3.conv1.weight\n","layer name: stage4.0.branches.0.3.bn1.weight\n","layer name: stage4.0.branches.0.3.bn1.bias\n","layer name: stage4.0.branches.0.3.conv2.weight\n","layer name: stage4.0.branches.0.3.bn2.weight\n","layer name: stage4.0.branches.0.3.bn2.bias\n","layer name: stage4.0.branches.1.0.conv1.weight\n","layer name: stage4.0.branches.1.0.bn1.weight\n","layer name: stage4.0.branches.1.0.bn1.bias\n","layer name: stage4.0.branches.1.0.conv2.weight\n","layer name: stage4.0.branches.1.0.bn2.weight\n","layer name: stage4.0.branches.1.0.bn2.bias\n","layer name: stage4.0.branches.1.1.conv1.weight\n","layer name: stage4.0.branches.1.1.bn1.weight\n","layer name: stage4.0.branches.1.1.bn1.bias\n","layer name: stage4.0.branches.1.1.conv2.weight\n","layer name: stage4.0.branches.1.1.bn2.weight\n","layer name: stage4.0.branches.1.1.bn2.bias\n","layer name: stage4.0.branches.1.2.conv1.weight\n","layer name: stage4.0.branches.1.2.bn1.weight\n","layer name: stage4.0.branches.1.2.bn1.bias\n","layer name: stage4.0.branches.1.2.conv2.weight\n","layer name: stage4.0.branches.1.2.bn2.weight\n","layer name: stage4.0.branches.1.2.bn2.bias\n","layer name: stage4.0.branches.1.3.conv1.weight\n","layer name: stage4.0.branches.1.3.bn1.weight\n","layer name: stage4.0.branches.1.3.bn1.bias\n","layer name: stage4.0.branches.1.3.conv2.weight\n","layer name: stage4.0.branches.1.3.bn2.weight\n","layer name: stage4.0.branches.1.3.bn2.bias\n","layer name: stage4.0.branches.2.0.conv1.weight\n","layer name: stage4.0.branches.2.0.bn1.weight\n","layer name: stage4.0.branches.2.0.bn1.bias\n","layer name: stage4.0.branches.2.0.conv2.weight\n","layer name: stage4.0.branches.2.0.bn2.weight\n","layer name: stage4.0.branches.2.0.bn2.bias\n","layer name: stage4.0.branches.2.1.conv1.weight\n","layer name: stage4.0.branches.2.1.bn1.weight\n","layer name: stage4.0.branches.2.1.bn1.bias\n","layer name: stage4.0.branches.2.1.conv2.weight\n","layer name: stage4.0.branches.2.1.bn2.weight\n","layer name: stage4.0.branches.2.1.bn2.bias\n","layer name: stage4.0.branches.2.2.conv1.weight\n","layer name: stage4.0.branches.2.2.bn1.weight\n","layer name: stage4.0.branches.2.2.bn1.bias\n","layer name: stage4.0.branches.2.2.conv2.weight\n","layer name: stage4.0.branches.2.2.bn2.weight\n","layer name: stage4.0.branches.2.2.bn2.bias\n","layer name: stage4.0.branches.2.3.conv1.weight\n","layer name: stage4.0.branches.2.3.bn1.weight\n","layer name: stage4.0.branches.2.3.bn1.bias\n","layer name: stage4.0.branches.2.3.conv2.weight\n","layer name: stage4.0.branches.2.3.bn2.weight\n","layer name: stage4.0.branches.2.3.bn2.bias\n","layer name: stage4.0.branches.3.0.conv1.weight\n","layer name: stage4.0.branches.3.0.bn1.weight\n","layer name: stage4.0.branches.3.0.bn1.bias\n","layer name: stage4.0.branches.3.0.conv2.weight\n","layer name: stage4.0.branches.3.0.bn2.weight\n","layer name: stage4.0.branches.3.0.bn2.bias\n","layer name: stage4.0.branches.3.1.conv1.weight\n","layer name: stage4.0.branches.3.1.bn1.weight\n","layer name: stage4.0.branches.3.1.bn1.bias\n","layer name: stage4.0.branches.3.1.conv2.weight\n","layer name: stage4.0.branches.3.1.bn2.weight\n","layer name: stage4.0.branches.3.1.bn2.bias\n","layer name: stage4.0.branches.3.2.conv1.weight\n","layer name: stage4.0.branches.3.2.bn1.weight\n","layer name: stage4.0.branches.3.2.bn1.bias\n","layer name: stage4.0.branches.3.2.conv2.weight\n","layer name: stage4.0.branches.3.2.bn2.weight\n","layer name: stage4.0.branches.3.2.bn2.bias\n","layer name: stage4.0.branches.3.3.conv1.weight\n","layer name: stage4.0.branches.3.3.bn1.weight\n","layer name: stage4.0.branches.3.3.bn1.bias\n","layer name: stage4.0.branches.3.3.conv2.weight\n","layer name: stage4.0.branches.3.3.bn2.weight\n","layer name: stage4.0.branches.3.3.bn2.bias\n","layer name: stage4.0.fuse_layers.0.1.0.weight\n","layer name: stage4.0.fuse_layers.0.1.1.weight\n","layer name: stage4.0.fuse_layers.0.1.1.bias\n","layer name: stage4.0.fuse_layers.0.2.0.weight\n","layer name: stage4.0.fuse_layers.0.2.1.weight\n","layer name: stage4.0.fuse_layers.0.2.1.bias\n","layer name: stage4.0.fuse_layers.0.3.0.weight\n","layer name: stage4.0.fuse_layers.0.3.1.weight\n","layer name: stage4.0.fuse_layers.0.3.1.bias\n","layer name: stage4.0.fuse_layers.1.0.0.0.weight\n","layer name: stage4.0.fuse_layers.1.0.0.1.weight\n","layer name: stage4.0.fuse_layers.1.0.0.1.bias\n","layer name: stage4.0.fuse_layers.1.2.0.weight\n","layer name: stage4.0.fuse_layers.1.2.1.weight\n","layer name: stage4.0.fuse_layers.1.2.1.bias\n","layer name: stage4.0.fuse_layers.1.3.0.weight\n","layer name: stage4.0.fuse_layers.1.3.1.weight\n","layer name: stage4.0.fuse_layers.1.3.1.bias\n","layer name: stage4.0.fuse_layers.2.0.0.0.weight\n","layer name: stage4.0.fuse_layers.2.0.0.1.weight\n","layer name: stage4.0.fuse_layers.2.0.0.1.bias\n","layer name: stage4.0.fuse_layers.2.0.1.0.weight\n","layer name: stage4.0.fuse_layers.2.0.1.1.weight\n","layer name: stage4.0.fuse_layers.2.0.1.1.bias\n","layer name: stage4.0.fuse_layers.2.1.0.0.weight\n","layer name: stage4.0.fuse_layers.2.1.0.1.weight\n","layer name: stage4.0.fuse_layers.2.1.0.1.bias\n","layer name: stage4.0.fuse_layers.2.3.0.weight\n","layer name: stage4.0.fuse_layers.2.3.1.weight\n","layer name: stage4.0.fuse_layers.2.3.1.bias\n","layer name: stage4.0.fuse_layers.3.0.0.0.weight\n","layer name: stage4.0.fuse_layers.3.0.0.1.weight\n","layer name: stage4.0.fuse_layers.3.0.0.1.bias\n","layer name: stage4.0.fuse_layers.3.0.1.0.weight\n","layer name: stage4.0.fuse_layers.3.0.1.1.weight\n","layer name: stage4.0.fuse_layers.3.0.1.1.bias\n","layer name: stage4.0.fuse_layers.3.0.2.0.weight\n","layer name: stage4.0.fuse_layers.3.0.2.1.weight\n","layer name: stage4.0.fuse_layers.3.0.2.1.bias\n","layer name: stage4.0.fuse_layers.3.1.0.0.weight\n","layer name: stage4.0.fuse_layers.3.1.0.1.weight\n","layer name: stage4.0.fuse_layers.3.1.0.1.bias\n","layer name: stage4.0.fuse_layers.3.1.1.0.weight\n","layer name: stage4.0.fuse_layers.3.1.1.1.weight\n","layer name: stage4.0.fuse_layers.3.1.1.1.bias\n","layer name: stage4.0.fuse_layers.3.2.0.0.weight\n","layer name: stage4.0.fuse_layers.3.2.0.1.weight\n","layer name: stage4.0.fuse_layers.3.2.0.1.bias\n","layer name: stage4.1.branches.0.0.conv1.weight\n","layer name: stage4.1.branches.0.0.bn1.weight\n","layer name: stage4.1.branches.0.0.bn1.bias\n","layer name: stage4.1.branches.0.0.conv2.weight\n","layer name: stage4.1.branches.0.0.bn2.weight\n","layer name: stage4.1.branches.0.0.bn2.bias\n","layer name: stage4.1.branches.0.1.conv1.weight\n","layer name: stage4.1.branches.0.1.bn1.weight\n","layer name: stage4.1.branches.0.1.bn1.bias\n","layer name: stage4.1.branches.0.1.conv2.weight\n","layer name: stage4.1.branches.0.1.bn2.weight\n","layer name: stage4.1.branches.0.1.bn2.bias\n","layer name: stage4.1.branches.0.2.conv1.weight\n","layer name: stage4.1.branches.0.2.bn1.weight\n","layer name: stage4.1.branches.0.2.bn1.bias\n","layer name: stage4.1.branches.0.2.conv2.weight\n","layer name: stage4.1.branches.0.2.bn2.weight\n","layer name: stage4.1.branches.0.2.bn2.bias\n","layer name: stage4.1.branches.0.3.conv1.weight\n","layer name: stage4.1.branches.0.3.bn1.weight\n","layer name: stage4.1.branches.0.3.bn1.bias\n","layer name: stage4.1.branches.0.3.conv2.weight\n","layer name: stage4.1.branches.0.3.bn2.weight\n","layer name: stage4.1.branches.0.3.bn2.bias\n","layer name: stage4.1.branches.1.0.conv1.weight\n","layer name: stage4.1.branches.1.0.bn1.weight\n","layer name: stage4.1.branches.1.0.bn1.bias\n","layer name: stage4.1.branches.1.0.conv2.weight\n","layer name: stage4.1.branches.1.0.bn2.weight\n","layer name: stage4.1.branches.1.0.bn2.bias\n","layer name: stage4.1.branches.1.1.conv1.weight\n","layer name: stage4.1.branches.1.1.bn1.weight\n","layer name: stage4.1.branches.1.1.bn1.bias\n","layer name: stage4.1.branches.1.1.conv2.weight\n","layer name: stage4.1.branches.1.1.bn2.weight\n","layer name: stage4.1.branches.1.1.bn2.bias\n","layer name: stage4.1.branches.1.2.conv1.weight\n","layer name: stage4.1.branches.1.2.bn1.weight\n","layer name: stage4.1.branches.1.2.bn1.bias\n","layer name: stage4.1.branches.1.2.conv2.weight\n","layer name: stage4.1.branches.1.2.bn2.weight\n","layer name: stage4.1.branches.1.2.bn2.bias\n","layer name: stage4.1.branches.1.3.conv1.weight\n","layer name: stage4.1.branches.1.3.bn1.weight\n","layer name: stage4.1.branches.1.3.bn1.bias\n","layer name: stage4.1.branches.1.3.conv2.weight\n","layer name: stage4.1.branches.1.3.bn2.weight\n","layer name: stage4.1.branches.1.3.bn2.bias\n","layer name: stage4.1.branches.2.0.conv1.weight\n","layer name: stage4.1.branches.2.0.bn1.weight\n","layer name: stage4.1.branches.2.0.bn1.bias\n","layer name: stage4.1.branches.2.0.conv2.weight\n","layer name: stage4.1.branches.2.0.bn2.weight\n","layer name: stage4.1.branches.2.0.bn2.bias\n","layer name: stage4.1.branches.2.1.conv1.weight\n","layer name: stage4.1.branches.2.1.bn1.weight\n","layer name: stage4.1.branches.2.1.bn1.bias\n","layer name: stage4.1.branches.2.1.conv2.weight\n","layer name: stage4.1.branches.2.1.bn2.weight\n","layer name: stage4.1.branches.2.1.bn2.bias\n","layer name: stage4.1.branches.2.2.conv1.weight\n","layer name: stage4.1.branches.2.2.bn1.weight\n","layer name: stage4.1.branches.2.2.bn1.bias\n","layer name: stage4.1.branches.2.2.conv2.weight\n","layer name: stage4.1.branches.2.2.bn2.weight\n","layer name: stage4.1.branches.2.2.bn2.bias\n","layer name: stage4.1.branches.2.3.conv1.weight\n","layer name: stage4.1.branches.2.3.bn1.weight\n","layer name: stage4.1.branches.2.3.bn1.bias\n","layer name: stage4.1.branches.2.3.conv2.weight\n","layer name: stage4.1.branches.2.3.bn2.weight\n","layer name: stage4.1.branches.2.3.bn2.bias\n","layer name: stage4.1.branches.3.0.conv1.weight\n","layer name: stage4.1.branches.3.0.bn1.weight\n","layer name: stage4.1.branches.3.0.bn1.bias\n","layer name: stage4.1.branches.3.0.conv2.weight\n","layer name: stage4.1.branches.3.0.bn2.weight\n","layer name: stage4.1.branches.3.0.bn2.bias\n","layer name: stage4.1.branches.3.1.conv1.weight\n","layer name: stage4.1.branches.3.1.bn1.weight\n","layer name: stage4.1.branches.3.1.bn1.bias\n","layer name: stage4.1.branches.3.1.conv2.weight\n","layer name: stage4.1.branches.3.1.bn2.weight\n","layer name: stage4.1.branches.3.1.bn2.bias\n","layer name: stage4.1.branches.3.2.conv1.weight\n","layer name: stage4.1.branches.3.2.bn1.weight\n","layer name: stage4.1.branches.3.2.bn1.bias\n","layer name: stage4.1.branches.3.2.conv2.weight\n","layer name: stage4.1.branches.3.2.bn2.weight\n","layer name: stage4.1.branches.3.2.bn2.bias\n","layer name: stage4.1.branches.3.3.conv1.weight\n","layer name: stage4.1.branches.3.3.bn1.weight\n","layer name: stage4.1.branches.3.3.bn1.bias\n","layer name: stage4.1.branches.3.3.conv2.weight\n","layer name: stage4.1.branches.3.3.bn2.weight\n","layer name: stage4.1.branches.3.3.bn2.bias\n","layer name: stage4.1.fuse_layers.0.1.0.weight\n","layer name: stage4.1.fuse_layers.0.1.1.weight\n","layer name: stage4.1.fuse_layers.0.1.1.bias\n","layer name: stage4.1.fuse_layers.0.2.0.weight\n","layer name: stage4.1.fuse_layers.0.2.1.weight\n","layer name: stage4.1.fuse_layers.0.2.1.bias\n","layer name: stage4.1.fuse_layers.0.3.0.weight\n","layer name: stage4.1.fuse_layers.0.3.1.weight\n","layer name: stage4.1.fuse_layers.0.3.1.bias\n","layer name: stage4.1.fuse_layers.1.0.0.0.weight\n","layer name: stage4.1.fuse_layers.1.0.0.1.weight\n","layer name: stage4.1.fuse_layers.1.0.0.1.bias\n","layer name: stage4.1.fuse_layers.1.2.0.weight\n","layer name: stage4.1.fuse_layers.1.2.1.weight\n","layer name: stage4.1.fuse_layers.1.2.1.bias\n","layer name: stage4.1.fuse_layers.1.3.0.weight\n","layer name: stage4.1.fuse_layers.1.3.1.weight\n","layer name: stage4.1.fuse_layers.1.3.1.bias\n","layer name: stage4.1.fuse_layers.2.0.0.0.weight\n","layer name: stage4.1.fuse_layers.2.0.0.1.weight\n","layer name: stage4.1.fuse_layers.2.0.0.1.bias\n","layer name: stage4.1.fuse_layers.2.0.1.0.weight\n","layer name: stage4.1.fuse_layers.2.0.1.1.weight\n","layer name: stage4.1.fuse_layers.2.0.1.1.bias\n","layer name: stage4.1.fuse_layers.2.1.0.0.weight\n","layer name: stage4.1.fuse_layers.2.1.0.1.weight\n","layer name: stage4.1.fuse_layers.2.1.0.1.bias\n","layer name: stage4.1.fuse_layers.2.3.0.weight\n","layer name: stage4.1.fuse_layers.2.3.1.weight\n","layer name: stage4.1.fuse_layers.2.3.1.bias\n","layer name: stage4.1.fuse_layers.3.0.0.0.weight\n","layer name: stage4.1.fuse_layers.3.0.0.1.weight\n","layer name: stage4.1.fuse_layers.3.0.0.1.bias\n","layer name: stage4.1.fuse_layers.3.0.1.0.weight\n","layer name: stage4.1.fuse_layers.3.0.1.1.weight\n","layer name: stage4.1.fuse_layers.3.0.1.1.bias\n","layer name: stage4.1.fuse_layers.3.0.2.0.weight\n","layer name: stage4.1.fuse_layers.3.0.2.1.weight\n","layer name: stage4.1.fuse_layers.3.0.2.1.bias\n","layer name: stage4.1.fuse_layers.3.1.0.0.weight\n","layer name: stage4.1.fuse_layers.3.1.0.1.weight\n","layer name: stage4.1.fuse_layers.3.1.0.1.bias\n","layer name: stage4.1.fuse_layers.3.1.1.0.weight\n","layer name: stage4.1.fuse_layers.3.1.1.1.weight\n","layer name: stage4.1.fuse_layers.3.1.1.1.bias\n","layer name: stage4.1.fuse_layers.3.2.0.0.weight\n","layer name: stage4.1.fuse_layers.3.2.0.1.weight\n","layer name: stage4.1.fuse_layers.3.2.0.1.bias\n","layer name: stage4.2.branches.0.0.conv1.weight\n","layer name: stage4.2.branches.0.0.bn1.weight\n","layer name: stage4.2.branches.0.0.bn1.bias\n","layer name: stage4.2.branches.0.0.conv2.weight\n","layer name: stage4.2.branches.0.0.bn2.weight\n","layer name: stage4.2.branches.0.0.bn2.bias\n","layer name: stage4.2.branches.0.1.conv1.weight\n","layer name: stage4.2.branches.0.1.bn1.weight\n","layer name: stage4.2.branches.0.1.bn1.bias\n","layer name: stage4.2.branches.0.1.conv2.weight\n","layer name: stage4.2.branches.0.1.bn2.weight\n","layer name: stage4.2.branches.0.1.bn2.bias\n","layer name: stage4.2.branches.0.2.conv1.weight\n","layer name: stage4.2.branches.0.2.bn1.weight\n","layer name: stage4.2.branches.0.2.bn1.bias\n","layer name: stage4.2.branches.0.2.conv2.weight\n","layer name: stage4.2.branches.0.2.bn2.weight\n","layer name: stage4.2.branches.0.2.bn2.bias\n","layer name: stage4.2.branches.0.3.conv1.weight\n","layer name: stage4.2.branches.0.3.bn1.weight\n","layer name: stage4.2.branches.0.3.bn1.bias\n","layer name: stage4.2.branches.0.3.conv2.weight\n","layer name: stage4.2.branches.0.3.bn2.weight\n","layer name: stage4.2.branches.0.3.bn2.bias\n","layer name: stage4.2.branches.1.0.conv1.weight\n","layer name: stage4.2.branches.1.0.bn1.weight\n","layer name: stage4.2.branches.1.0.bn1.bias\n","layer name: stage4.2.branches.1.0.conv2.weight\n","layer name: stage4.2.branches.1.0.bn2.weight\n","layer name: stage4.2.branches.1.0.bn2.bias\n","layer name: stage4.2.branches.1.1.conv1.weight\n","layer name: stage4.2.branches.1.1.bn1.weight\n","layer name: stage4.2.branches.1.1.bn1.bias\n","layer name: stage4.2.branches.1.1.conv2.weight\n","layer name: stage4.2.branches.1.1.bn2.weight\n","layer name: stage4.2.branches.1.1.bn2.bias\n","layer name: stage4.2.branches.1.2.conv1.weight\n","layer name: stage4.2.branches.1.2.bn1.weight\n","layer name: stage4.2.branches.1.2.bn1.bias\n","layer name: stage4.2.branches.1.2.conv2.weight\n","layer name: stage4.2.branches.1.2.bn2.weight\n","layer name: stage4.2.branches.1.2.bn2.bias\n","layer name: stage4.2.branches.1.3.conv1.weight\n","layer name: stage4.2.branches.1.3.bn1.weight\n","layer name: stage4.2.branches.1.3.bn1.bias\n","layer name: stage4.2.branches.1.3.conv2.weight\n","layer name: stage4.2.branches.1.3.bn2.weight\n","layer name: stage4.2.branches.1.3.bn2.bias\n","layer name: stage4.2.branches.2.0.conv1.weight\n","layer name: stage4.2.branches.2.0.bn1.weight\n","layer name: stage4.2.branches.2.0.bn1.bias\n","layer name: stage4.2.branches.2.0.conv2.weight\n","layer name: stage4.2.branches.2.0.bn2.weight\n","layer name: stage4.2.branches.2.0.bn2.bias\n","layer name: stage4.2.branches.2.1.conv1.weight\n","layer name: stage4.2.branches.2.1.bn1.weight\n","layer name: stage4.2.branches.2.1.bn1.bias\n","layer name: stage4.2.branches.2.1.conv2.weight\n","layer name: stage4.2.branches.2.1.bn2.weight\n","layer name: stage4.2.branches.2.1.bn2.bias\n","layer name: stage4.2.branches.2.2.conv1.weight\n","layer name: stage4.2.branches.2.2.bn1.weight\n","layer name: stage4.2.branches.2.2.bn1.bias\n","layer name: stage4.2.branches.2.2.conv2.weight\n","layer name: stage4.2.branches.2.2.bn2.weight\n","layer name: stage4.2.branches.2.2.bn2.bias\n","layer name: stage4.2.branches.2.3.conv1.weight\n","layer name: stage4.2.branches.2.3.bn1.weight\n","layer name: stage4.2.branches.2.3.bn1.bias\n","layer name: stage4.2.branches.2.3.conv2.weight\n","layer name: stage4.2.branches.2.3.bn2.weight\n","layer name: stage4.2.branches.2.3.bn2.bias\n","layer name: stage4.2.branches.3.0.conv1.weight\n","layer name: stage4.2.branches.3.0.bn1.weight\n","layer name: stage4.2.branches.3.0.bn1.bias\n","layer name: stage4.2.branches.3.0.conv2.weight\n","layer name: stage4.2.branches.3.0.bn2.weight\n","layer name: stage4.2.branches.3.0.bn2.bias\n","layer name: stage4.2.branches.3.1.conv1.weight\n","layer name: stage4.2.branches.3.1.bn1.weight\n","layer name: stage4.2.branches.3.1.bn1.bias\n","layer name: stage4.2.branches.3.1.conv2.weight\n","layer name: stage4.2.branches.3.1.bn2.weight\n","layer name: stage4.2.branches.3.1.bn2.bias\n","layer name: stage4.2.branches.3.2.conv1.weight\n","layer name: stage4.2.branches.3.2.bn1.weight\n","layer name: stage4.2.branches.3.2.bn1.bias\n","layer name: stage4.2.branches.3.2.conv2.weight\n","layer name: stage4.2.branches.3.2.bn2.weight\n","layer name: stage4.2.branches.3.2.bn2.bias\n","layer name: stage4.2.branches.3.3.conv1.weight\n","layer name: stage4.2.branches.3.3.bn1.weight\n","layer name: stage4.2.branches.3.3.bn1.bias\n","layer name: stage4.2.branches.3.3.conv2.weight\n","layer name: stage4.2.branches.3.3.bn2.weight\n","layer name: stage4.2.branches.3.3.bn2.bias\n","layer name: stage4.2.fuse_layers.0.1.0.weight\n","layer name: stage4.2.fuse_layers.0.1.1.weight\n","layer name: stage4.2.fuse_layers.0.1.1.bias\n","layer name: stage4.2.fuse_layers.0.2.0.weight\n","layer name: stage4.2.fuse_layers.0.2.1.weight\n","layer name: stage4.2.fuse_layers.0.2.1.bias\n","layer name: stage4.2.fuse_layers.0.3.0.weight\n","layer name: stage4.2.fuse_layers.0.3.1.weight\n","layer name: stage4.2.fuse_layers.0.3.1.bias\n","layer name: stage4.2.fuse_layers.1.0.0.0.weight\n","layer name: stage4.2.fuse_layers.1.0.0.1.weight\n","layer name: stage4.2.fuse_layers.1.0.0.1.bias\n","layer name: stage4.2.fuse_layers.1.2.0.weight\n","layer name: stage4.2.fuse_layers.1.2.1.weight\n","layer name: stage4.2.fuse_layers.1.2.1.bias\n","layer name: stage4.2.fuse_layers.1.3.0.weight\n","layer name: stage4.2.fuse_layers.1.3.1.weight\n","layer name: stage4.2.fuse_layers.1.3.1.bias\n","layer name: stage4.2.fuse_layers.2.0.0.0.weight\n","layer name: stage4.2.fuse_layers.2.0.0.1.weight\n","layer name: stage4.2.fuse_layers.2.0.0.1.bias\n","layer name: stage4.2.fuse_layers.2.0.1.0.weight\n","layer name: stage4.2.fuse_layers.2.0.1.1.weight\n","layer name: stage4.2.fuse_layers.2.0.1.1.bias\n","layer name: stage4.2.fuse_layers.2.1.0.0.weight\n","layer name: stage4.2.fuse_layers.2.1.0.1.weight\n","layer name: stage4.2.fuse_layers.2.1.0.1.bias\n","layer name: stage4.2.fuse_layers.2.3.0.weight\n","layer name: stage4.2.fuse_layers.2.3.1.weight\n","layer name: stage4.2.fuse_layers.2.3.1.bias\n","layer name: stage4.2.fuse_layers.3.0.0.0.weight\n","layer name: stage4.2.fuse_layers.3.0.0.1.weight\n","layer name: stage4.2.fuse_layers.3.0.0.1.bias\n","layer name: stage4.2.fuse_layers.3.0.1.0.weight\n","layer name: stage4.2.fuse_layers.3.0.1.1.weight\n","layer name: stage4.2.fuse_layers.3.0.1.1.bias\n","layer name: stage4.2.fuse_layers.3.0.2.0.weight\n","layer name: stage4.2.fuse_layers.3.0.2.1.weight\n","layer name: stage4.2.fuse_layers.3.0.2.1.bias\n","layer name: stage4.2.fuse_layers.3.1.0.0.weight\n","layer name: stage4.2.fuse_layers.3.1.0.1.weight\n","layer name: stage4.2.fuse_layers.3.1.0.1.bias\n","layer name: stage4.2.fuse_layers.3.1.1.0.weight\n","layer name: stage4.2.fuse_layers.3.1.1.1.weight\n","layer name: stage4.2.fuse_layers.3.1.1.1.bias\n","layer name: stage4.2.fuse_layers.3.2.0.0.weight\n","layer name: stage4.2.fuse_layers.3.2.0.1.weight\n","layer name: stage4.2.fuse_layers.3.2.0.1.bias\n","layer name: conv3x3_ocr.0.weight\n","layer name: conv3x3_ocr.0.bias\n","layer name: conv3x3_ocr.1.weight\n","layer name: conv3x3_ocr.1.bias\n","layer name: ocr_distri_head.object_context_block.f_pixel.0.weight\n","layer name: ocr_distri_head.object_context_block.f_pixel.1.0.weight\n","layer name: ocr_distri_head.object_context_block.f_pixel.1.0.bias\n","layer name: ocr_distri_head.object_context_block.f_pixel.2.weight\n","layer name: ocr_distri_head.object_context_block.f_pixel.3.0.weight\n","layer name: ocr_distri_head.object_context_block.f_pixel.3.0.bias\n","layer name: ocr_distri_head.object_context_block.f_object.0.weight\n","layer name: ocr_distri_head.object_context_block.f_object.1.0.weight\n","layer name: ocr_distri_head.object_context_block.f_object.1.0.bias\n","layer name: ocr_distri_head.object_context_block.f_object.2.weight\n","layer name: ocr_distri_head.object_context_block.f_object.3.0.weight\n","layer name: ocr_distri_head.object_context_block.f_object.3.0.bias\n","layer name: ocr_distri_head.object_context_block.f_down.0.weight\n","layer name: ocr_distri_head.object_context_block.f_down.1.0.weight\n","layer name: ocr_distri_head.object_context_block.f_down.1.0.bias\n","layer name: ocr_distri_head.object_context_block.f_up.0.weight\n","layer name: ocr_distri_head.object_context_block.f_up.1.0.weight\n","layer name: ocr_distri_head.object_context_block.f_up.1.0.bias\n","layer name: ocr_distri_head.conv_bn_dropout.0.weight\n","layer name: ocr_distri_head.conv_bn_dropout.1.0.weight\n","layer name: ocr_distri_head.conv_bn_dropout.1.0.bias\n","layer name: cls_head.weight\n","layer name: cls_head.bias\n","layer name: aux_head.0.weight\n","layer name: aux_head.0.bias\n","layer name: aux_head.1.weight\n","layer name: aux_head.1.bias\n","layer name: aux_head.3.weight\n","layer name: aux_head.3.bias\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"Rad6E3-e13lT"},"execution_count":null,"outputs":[]}]}