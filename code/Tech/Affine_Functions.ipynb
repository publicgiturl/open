{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1-1 : Affine Functions with 1 Featrue"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code.1-1-1 : Affine Function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!pip install tensorflow-gpu\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "x = tf.constant([[10.]]) # Input setting(Note : input -> matrix)\n",
    "dense = Dense(units=1, activation = 'linear') # imp. an affine function\n",
    "\n",
    "print(x)\n",
    "print(x.shape)\n",
    "\n",
    "y_tf = dense(x) # w, b // z = xw+b // forward propagation + params initialization\n",
    "\n",
    "print(y_tf)\n",
    "\n",
    "W, B = dense.get_weights()\n",
    "print(W, B)\n",
    "y_man = tf.linalg.matmul(x,W) + B  # forward propagation(manual)\n",
    "\n",
    "# print results\n",
    "print('===== Input/Weight/Bias =====')\n",
    "print(f'x : {x.shape} / {x.numpy()}')\n",
    "print(f'W : {y_tf.shape} / {W}')\n",
    "print(f'B : {B.shape} / {B}')\n",
    "\n",
    "print('===== Ouputs =====')\n",
    "print(f\"y(Tensorflow) : {y_tf.shape} / {y_tf.numpy()}\")\n",
    "print(f\"y(Manual) : {y_man.shape} / {y_man.numpy()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[10.]], shape=(1, 1), dtype=float32)\n",
      "(1, 1)\n",
      "tf.Tensor([[-2.0495725]], shape=(1, 1), dtype=float32)\n",
      "[[-0.20495725]] [0.]\n",
      "===== Input/Weight/Bias =====\n",
      "x : (1, 1) / [[10.]]\n",
      "W : (1, 1) / [[-0.20495725]]\n",
      "B : (1,) / [0.]\n",
      "===== Ouputs =====\n",
      "y(Tensorflow) : (1, 1) / [[-2.0495725]]\n",
      "y(Manual) : (1, 1) / [[-2.0495725]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code.1-1-1 : Params Initialization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.initializers.initializers_v2.Constant object at 0x0000012ABCF82EC8> <tensorflow.python.keras.initializers.initializers_v2.Constant object at 0x0000012ABCF82FC8>\n",
      "tf.Tensor([[120.]], shape=(1, 1), dtype=float32)\n",
      "W : (1, 1) / [[10.]]\n",
      "B : (1,) / [20.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "# weight/bias setting\n",
    "w,b = tf.constant(10.), tf.constant(20.)\n",
    "w_init, b_init = Constant(w), Constant(b)\n",
    "\n",
    "print(w_init, b_init)\n",
    "\n",
    "# imp. an affine function\n",
    "dense = Dense(units=1, activation = 'linear',\n",
    "              kernel_initializer = w_init,\n",
    "              bias_initializer = b_init)\n",
    "\n",
    "y_tf = dense(x)\n",
    "W, B = dense.get_weights()\n",
    "print(y_tf)\n",
    "\n",
    "# print results\n",
    "print(f'W : {W.shape} / {W}')\n",
    "print(f'B : {B.shape} / {B}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1-2 : Affine Functions with n Features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code.1-2-1 : Affine Functions with n Featrues"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10) \n",
      " tf.Tensor(\n",
      "[[5.5458355 1.9355118 6.746477  6.4523163 5.092597  1.2913358 4.933592\n",
      "  4.6577883 7.342676  9.051614 ]], shape=(1, 10), dtype=float32)\n",
      "===== Input/Weight/Bias =====\n",
      "x : (1, 10) / [[5.5458355 1.9355118 6.746477  6.4523163 5.092597  1.2913358 4.933592\n",
      "  4.6577883 7.342676  9.051614 ]]\n",
      "W : (10, 1) / [[-0.47694248]\n",
      " [-0.6814187 ]\n",
      " [-0.20151943]\n",
      " [ 0.66904074]\n",
      " [-0.3782255 ]\n",
      " [ 0.23593342]\n",
      " [-0.45601368]\n",
      " [-0.19695729]\n",
      " [ 0.25848818]\n",
      " [ 0.6749005 ]]\n",
      "B : (1,) / [0.]\n",
      "===== Ouputs =====\n",
      "y(Tensorflow) : (1, 1) / [[2.2116594]]\n",
      "y(Manual) : (1, 1) / [[2.2116594]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "x = tf.random.uniform(shape = (1,10), minval=0, maxval=10)\n",
    "print(x.shape, '\\n', x)\n",
    "\n",
    "dense = Dense(units=1)\n",
    "\n",
    "y_tf = dense(x)\n",
    "\n",
    "W, B = dense.get_weights()\n",
    "\n",
    "y_man = tf.linalg.matmul(x, W) + B\n",
    "\n",
    "# print results\n",
    "print('===== Input/Weight/Bias =====')\n",
    "print(f'x : {x.shape} / {x.numpy()}')\n",
    "print(f'W : {W.shape} / {W}')\n",
    "print(f'B : {B.shape} / {B}')\n",
    "\n",
    "print('===== Ouputs =====')\n",
    "print(f\"y(Tensorflow) : {y_tf.shape} / {y_tf.numpy()}\")\n",
    "print(f\"y(Manual) : {y_man.shape} / {y_man.numpy()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1-3: Activation Layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code. 1-3-1: Activation Layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (1, 5), [[-0.39082974  0.10974757 -1.7390275  -0.94429874  0.66350085]]\n",
      "Sigmoid(Tensorflow) : (1, 5), [[0.40351757 0.52740943 0.14943649 0.28003284 0.66004634]]\n",
      "Sigmoid(manual) : (1, 5), [[0.40351757 0.52740943 0.14943649 0.28003284 0.6600464 ]]\n",
      "\n",
      "\n",
      "Tanh(Tensorflow) : (1, 5), [[-0.37207532  0.10930905 -0.9401138  -0.73719114  0.58068854]]\n",
      "Tanh(manual) : (1, 5), [[-0.37207532  0.10930903 -0.9401138  -0.7371911   0.58068854]]\n",
      "\n",
      "\n",
      "ReLU(Tensorflow) : (1, 5), [[0.         0.10974757 0.         0.         0.66350085]]\n",
      "ReLU(manual) : (1, 5), [[0.         0.10974757 0.         0.         0.66350085]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.math import exp, maximum\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "x = tf.random.normal(shape=(1,5)) # input setting\n",
    "\n",
    "# imp. activation function\n",
    "sigmoid = Activation('sigmoid')\n",
    "tanh = Activation('tanh')\n",
    "relu = Activation('relu')\n",
    "\n",
    "# forward prpagation(Tensorflow)\n",
    "y_sigmoid_tf = sigmoid(x)\n",
    "y_tanh_tf = tanh(x)\n",
    "y_relu_tf = relu(x)\n",
    "\n",
    "# forward prpagation(mannual)\n",
    "y_sigmoid_man = 1 / (1 + exp(-x))\n",
    "y_tanh_man = (exp(x) - exp(-x)) / (exp(x) + exp(-x))\n",
    "y_relu_man = maximum(x, 0)\n",
    "\n",
    "print(f'x : {x.shape}, {x.numpy()}')\n",
    "\n",
    "print(f'Sigmoid(Tensorflow) : {y_sigmoid_tf.shape}, {y_sigmoid_tf.numpy()}')\n",
    "print(f'Sigmoid(manual) : {y_sigmoid_man.shape}, {y_sigmoid_man.numpy()}')\n",
    "print('\\n')\n",
    "print(f'Tanh(Tensorflow) : {y_tanh_tf.shape}, {y_tanh_tf.numpy()}')\n",
    "print(f'Tanh(manual) : {y_tanh_man.shape}, {y_tanh_man.numpy()}')\n",
    "print('\\n')\n",
    "print(f'ReLU(Tensorflow) : {y_relu_tf.shape}, {y_relu_tf.numpy()}')\n",
    "print(f'ReLU(manual) : {y_relu_man.shape}, {y_relu_man.numpy()}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code. 1-3-2 : Activation in Dense Layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AN with Sigmoid : (1, 1), [[0.31697944]]\n",
      "AN with Tanh : (1, 1), [[0.9979504]]\n",
      "AN with Relu : (1, 1), [[0.]]\n",
      "\n",
      " ======== \n",
      "\n",
      "Activation value(Tensorflow) : (1, 1), [[0.31697944]]\n",
      "Activation value(manual) : (1, 1), [[0.31697944]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.math import exp\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "x = tf.random.normal(shape=(1, 5))  # input setting\n",
    "\n",
    "# imp. artifical neurons\n",
    "dense_sigmoid = Dense(units=1, activation='sigmoid')\n",
    "dense_tanh = Dense(units=1, activation='tanh')\n",
    "dense_relu = Dense(units=1, activation='relu')\n",
    "\n",
    "# forward propagation\n",
    "y_sigmoid = dense_sigmoid(x)\n",
    "y_tanh = dense_tanh(x)\n",
    "y_relu = dense_relu(x)\n",
    "\n",
    "print(f'AN with Sigmoid : {y_sigmoid.shape}, {y_sigmoid.numpy()}')\n",
    "print(f'AN with Tanh : {y_tanh.shape}, {y_tanh.numpy()}')\n",
    "print(f'AN with Relu : {y_relu.shape}, {y_relu.numpy()}')\n",
    "\n",
    "print(\"\\n ======== \\n\")\n",
    "\n",
    "# forward propagation(manual)\n",
    "W, b = dense_sigmoid.get_weights()\n",
    "z = tf.linalg.matmul(x, W) + b\n",
    "a = 1 / (1+exp(-z))\n",
    "\n",
    "print(f\"Activation value(Tensorflow) : {y_sigmoid.shape}, {y_sigmoid.numpy()}\")\n",
    "print(f\"Activation value(manual) : {a.shape}, {a.numpy()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1-4 : Artifical Neurons"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code.1-4-1 : Artificial Neurons"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation : tanh\n",
      "y_tf : (1, 1), [[0.5059361]]\n",
      "y_man : (1, 1), [[0.5059361]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "검증\n",
    "tensorflow에서 기본적으로 제공되는 Dense layer 실제로 어떻게 동작하고 작동하는지 검증\n",
    "y = ax + b의 과정을 검증\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.math import exp, maximum\n",
    "\n",
    "# activation = 'sigmoid'\n",
    "activation = 'tanh'\n",
    "# activation = 'relu'\n",
    "\n",
    "x = tf.random.uniform(shape=(1, 10)) # input setting\n",
    "\n",
    "dense = Dense(units=1, activation=activation) # imp. an affine + activation\n",
    "\n",
    "y_tf = dense(x)\n",
    "W, b = dense.get_weights()\n",
    "\n",
    "# calculate activation value manually\n",
    "y_man = tf.linalg.matmul(x, W) + b\n",
    "if activation == 'sigmoid':\n",
    "    y_man = 1 / (1 + exp(-y_man))\n",
    "elif activation == 'tanh':\n",
    "    y_man = (exp(y_man) - exp(-y_man)) / (exp(y_man) + exp(-y_man))\n",
    "elif activation == 'relu':\n",
    "    y_man = maximum(x, 0)\n",
    "\n",
    "print(f'Activation : {activation}')\n",
    "print(f'y_tf : {y_tf.shape}, {y_tf.numpy()}')\n",
    "print(f'y_man : {y_man.shape}, {y_man.numpy()}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1-5 : Minibatches"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code.1-5-1 : Shapes of Dense Layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x : (8, 10)\n",
      "Shape of W : (10, 1)\n",
      "Shape of B : (1,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "N, n_features = 8, 10 # set input params\n",
    "x = tf.random.normal(shape=(N, n_features)) # generate minibatch\n",
    "\n",
    "dense = Dense(units=1, activation='relu') # imp. an AN\n",
    "y = dense(x) # forward propagation\n",
    "\n",
    "W, b = dense.get_weights() # get weight / bias\n",
    "\n",
    "# print results\n",
    "print(f\"Shape of x : {x.shape}\")\n",
    "print(f\"Shape of W : {W.shape}\")\n",
    "print(f\"Shape of B : {b.shape}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code.1-5-2 : Ouput Calculations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output(tensorflow) : [[0.7586473 ]\n",
      " [0.08524176]\n",
      " [0.26782224]\n",
      " [0.57971865]\n",
      " [0.4382735 ]\n",
      " [0.27700454]\n",
      " [0.52964973]\n",
      " [0.85626656]]\n",
      "Outpu(Manual : [[0.7586473 ]\n",
      " [0.08524176]\n",
      " [0.26782224]\n",
      " [0.57971865]\n",
      " [0.4382735 ]\n",
      " [0.27700454]\n",
      " [0.52964973]\n",
      " [0.85626656]]\n",
      "tf.Tensor(\n",
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]], shape=(8, 1), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "N, n_features = 8, 10 # set input params\n",
    "x = tf.random.normal(shape=(N, n_features)) # generate minibatch\n",
    "\n",
    "dense = Dense(units=1, activation='sigmoid') # imp. an AN\n",
    "y_tf = dense(x) # forward propagation(tensorflow)\n",
    "\n",
    "W, b = dense.get_weights() # get weight / bias\n",
    "\n",
    "y_man = tf.linalg.matmul(x, W) + b # forward propagation(Manual)\n",
    "y_man = 1 / (1 + tf.math.exp(-y_man))\n",
    "\n",
    "# print results\n",
    "print(f\"Output(tensorflow) : {y_tf.numpy()}\")\n",
    "print(f\"Outpu(Manual : {y_man.numpy()}\")\n",
    "print(tf.math.equal(y_tf, y_man))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Forward Propagation of Neural Networks\n",
    "\n",
    "## Lecture.2 Dense Layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-feb1f727",
   "language": "python",
   "display_name": "PyCharm (code)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}