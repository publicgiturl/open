{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e8a5dc",
   "metadata": {},
   "source": [
    "### Openpcdet\n",
    "\n",
    "- Multi gpus based : \n",
    "    - python -m torch.distributed.launch --nproc_per_node 4 train.py --cfg_file cfgs/kitti_models/PVRCNNPlusPlus.yaml --launcher pytorch --extra_tag test\n",
    "    - nproc_per_node : GPU개수에 맞게 사용할 GPU(GPU개수보다 많은 숫자 불가)\n",
    "    - cfg_file : 학습 시킬 config 경로\n",
    "    - launcher : 생략 시 Multi GPU 사용이 안됨. 0,1,2,3 모두가 잡히긴 하나 분산작업이 되지 않음\n",
    "+ Error\n",
    "    - Key_Error : road_plane -> Config에서 사용하는 모델의 yaml수정(USE_ROAD_PLANE : True -> False)\n",
    "    - DatasetLoader 이중으로 할 경우 Distributed Gpu pid 계속해서 증가해서 Cuda_Memory_Err발생\n",
    "+ Logger\n",
    "    - logger.info(log내용 기록)\n",
    "\n",
    "### Custom_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dac225d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-84c5bfd27d01>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-84c5bfd27d01>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    DATA_CONFIG:\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### PV_RCNN - pvrcnn.yaml\n",
    "CLASS_NAMES: ['Pedestrian', 'Stroller', 'Cart','Wheelchair']\n",
    "\n",
    "DATA_CONFIG:\n",
    "    _BASE_CONFIG_: /data/test_model/mm/OpenPCDet/tools/cfgs/dataset_configs/sosai_dataset.yaml\n",
    "\n",
    "MODEL:\n",
    "    NAME: PVRCNN\n",
    "\n",
    "    VFE:\n",
    "        NAME: MeanVFE\n",
    "\n",
    "    BACKBONE_3D:\n",
    "        NAME: VoxelBackBone8x\n",
    "\n",
    "    MAP_TO_BEV:\n",
    "        NAME: HeightCompression\n",
    "        NUM_BEV_FEATURES: 256\n",
    "\n",
    "    BACKBONE_2D:\n",
    "        NAME: BaseBEVBackbone\n",
    "\n",
    "        LAYER_NUMS: [5, 5]\n",
    "        LAYER_STRIDES: [1, 2]\n",
    "        NUM_FILTERS: [128, 256]\n",
    "        UPSAMPLE_STRIDES: [1, 2]\n",
    "        NUM_UPSAMPLE_FILTERS: [256, 256]\n",
    "\n",
    "    DENSE_HEAD:\n",
    "        NAME: AnchorHeadSingle\n",
    "        CLASS_AGNOSTIC: False\n",
    "\n",
    "        USE_DIRECTION_CLASSIFIER: True\n",
    "        DIR_OFFSET: 0.78539\n",
    "        DIR_LIMIT_OFFSET: 0.0\n",
    "        NUM_DIR_BINS: 2\n",
    "\n",
    "        ANCHOR_GENERATOR_CONFIG: [\n",
    "            {\n",
    "                'class_name': 'Pedestrian',\n",
    "                'anchor_sizes': [[0.4, 0.6, 1.8]],\n",
    "                'anchor_rotations': [0, 1.57],\n",
    "                'anchor_bottom_heights': [0],\n",
    "                'align_center': False,\n",
    "                'feature_map_stride': 8,\n",
    "                'matched_threshold': 0.5,\n",
    "                'unmatched_threshold': 0.35\n",
    "            },\n",
    "            {\n",
    "                'class_name': 'Stroller',\n",
    "                'anchor_sizes': [[0.8, 0.5, 1.0]],\n",
    "                'anchor_rotations': [0, 1.57],\n",
    "                'anchor_bottom_heights': [0],\n",
    "                'align_center': False,\n",
    "                'feature_map_stride': 8,\n",
    "                'matched_threshold': 0.5,\n",
    "                'unmatched_threshold': 0.35\n",
    "            },\n",
    "            {\n",
    "                'class_name': 'Cart',\n",
    "                'anchor_sizes': [[0.5, 0.3, 0.7]],\n",
    "                'anchor_rotations': [0, 1.57],\n",
    "                'anchor_bottom_heights': [0],\n",
    "                'align_center': False,\n",
    "                'feature_map_stride': 8,\n",
    "                'matched_threshold': 0.5,\n",
    "                'unmatched_threshold': 0.35\n",
    "            },\n",
    "            {\n",
    "                'class_name': 'Wheelchair',\n",
    "                'anchor_sizes': [[1.1, 0.6, 0.9]],\n",
    "                'anchor_rotations': [0, 1.57],\n",
    "                'anchor_bottom_heights': [0],\n",
    "                'align_center': False,\n",
    "                'feature_map_stride': 8,\n",
    "                'matched_threshold': 0.5,\n",
    "                'unmatched_threshold': 0.35\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        TARGET_ASSIGNER_CONFIG:\n",
    "            NAME: AxisAlignedTargetAssigner\n",
    "            POS_FRACTION: -1.0\n",
    "            SAMPLE_SIZE: 512\n",
    "            NORM_BY_NUM_EXAMPLES: False\n",
    "            MATCH_HEIGHT: False\n",
    "            BOX_CODER: ResidualCoder\n",
    "\n",
    "        LOSS_CONFIG:\n",
    "            LOSS_WEIGHTS: {\n",
    "                'cls_weight': 1.0,\n",
    "                'loc_weight': 2.0,\n",
    "                'dir_weight': 0.2,\n",
    "                'code_weights': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "            }\n",
    "\n",
    "    PFE:\n",
    "        NAME: VoxelSetAbstraction\n",
    "        POINT_SOURCE: raw_points\n",
    "        NUM_KEYPOINTS: 2048\n",
    "        NUM_OUTPUT_FEATURES: 128\n",
    "        SAMPLE_METHOD: FPS\n",
    "\n",
    "        FEATURES_SOURCE: ['bev', 'x_conv1', 'x_conv2', 'x_conv3', 'x_conv4', 'raw_points']\n",
    "        SA_LAYER:\n",
    "            raw_points:\n",
    "                MLPS: [[16, 16], [16, 16]]\n",
    "                POOL_RADIUS: [0.4, 0.8]\n",
    "                NSAMPLE: [16, 16]\n",
    "            x_conv1:\n",
    "                DOWNSAMPLE_FACTOR: 1\n",
    "                MLPS: [[16, 16], [16, 16]]\n",
    "                POOL_RADIUS: [0.4, 0.8]\n",
    "                NSAMPLE: [16, 16]\n",
    "            x_conv2:\n",
    "                DOWNSAMPLE_FACTOR: 2\n",
    "                MLPS: [[32, 32], [32, 32]]\n",
    "                POOL_RADIUS: [0.8, 1.2]\n",
    "                NSAMPLE: [16, 32]\n",
    "            x_conv3:\n",
    "                DOWNSAMPLE_FACTOR: 4\n",
    "                MLPS: [[64, 64], [64, 64]]\n",
    "                POOL_RADIUS: [1.2, 2.4]\n",
    "                NSAMPLE: [16, 32]\n",
    "            x_conv4:\n",
    "                DOWNSAMPLE_FACTOR: 8\n",
    "                MLPS: [[64, 64], [64, 64]]\n",
    "                POOL_RADIUS: [2.4, 4.8]\n",
    "                NSAMPLE: [16, 32]\n",
    "\n",
    "    POINT_HEAD:\n",
    "        NAME: PointHeadSimple\n",
    "        CLS_FC: [256, 256]\n",
    "        CLASS_AGNOSTIC: True\n",
    "        USE_POINT_FEATURES_BEFORE_FUSION: True\n",
    "        TARGET_CONFIG:\n",
    "            GT_EXTRA_WIDTH: [0.2, 0.2, 0.2]\n",
    "        LOSS_CONFIG:\n",
    "            LOSS_REG: smooth-l1\n",
    "            LOSS_WEIGHTS: {\n",
    "                'point_cls_weight': 1.0,\n",
    "            }\n",
    "\n",
    "    ROI_HEAD:\n",
    "        NAME: PVRCNNHead\n",
    "        CLASS_AGNOSTIC: True\n",
    "\n",
    "        SHARED_FC: [256, 256]\n",
    "        CLS_FC: [256, 256]\n",
    "        REG_FC: [256, 256]\n",
    "        DP_RATIO: 0.3\n",
    "\n",
    "        NMS_CONFIG:\n",
    "            TRAIN:\n",
    "                NMS_TYPE: nms_gpu\n",
    "                MULTI_CLASSES_NMS: False\n",
    "                NMS_PRE_MAXSIZE: 9000\n",
    "                NMS_POST_MAXSIZE: 512\n",
    "                NMS_THRESH: 0.8\n",
    "            TEST:\n",
    "                NMS_TYPE: nms_gpu\n",
    "                MULTI_CLASSES_NMS: False\n",
    "                NMS_PRE_MAXSIZE: 1024\n",
    "                NMS_POST_MAXSIZE: 100\n",
    "                NMS_THRESH: 0.7\n",
    "\n",
    "        ROI_GRID_POOL:\n",
    "            GRID_SIZE: 6\n",
    "            MLPS: [[64, 64], [64, 64]]\n",
    "            POOL_RADIUS: [0.8, 1.6]\n",
    "            NSAMPLE: [16, 16]\n",
    "            POOL_METHOD: max_pool\n",
    "\n",
    "        TARGET_CONFIG:\n",
    "            BOX_CODER: ResidualCoder\n",
    "            ROI_PER_IMAGE: 128\n",
    "            FG_RATIO: 0.5\n",
    "\n",
    "            SAMPLE_ROI_BY_EACH_CLASS: True\n",
    "            CLS_SCORE_TYPE: roi_iou\n",
    "\n",
    "            CLS_FG_THRESH: 0.75\n",
    "            CLS_BG_THRESH: 0.25\n",
    "            CLS_BG_THRESH_LO: 0.1\n",
    "            HARD_BG_RATIO: 0.8\n",
    "\n",
    "            REG_FG_THRESH: 0.55\n",
    "\n",
    "        LOSS_CONFIG:\n",
    "            CLS_LOSS: BinaryCrossEntropy\n",
    "            REG_LOSS: smooth-l1\n",
    "            CORNER_LOSS_REGULARIZATION: True\n",
    "            LOSS_WEIGHTS: {\n",
    "                'rcnn_cls_weight': 1.0,\n",
    "                'rcnn_reg_weight': 1.0,\n",
    "                'rcnn_corner_weight': 1.0,\n",
    "                'code_weights': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "            }\n",
    "\n",
    "    POST_PROCESSING:\n",
    "        RECALL_THRESH_LIST: [0.3, 0.5, 0.7]\n",
    "        SCORE_THRESH: 0.1\n",
    "        OUTPUT_RAW_SCORE: False\n",
    "\n",
    "        EVAL_METRIC: kitti\n",
    "\n",
    "        NMS_CONFIG:\n",
    "            MULTI_CLASSES_NMS: False\n",
    "            NMS_TYPE: nms_gpu\n",
    "            NMS_THRESH: 0.1\n",
    "            NMS_PRE_MAXSIZE: 4096\n",
    "            NMS_POST_MAXSIZE: 500\n",
    "\n",
    "\n",
    "OPTIMIZATION:\n",
    "    BATCH_SIZE_PER_GPU: 2\n",
    "    NUM_EPOCHS: 80\n",
    "\n",
    "    OPTIMIZER: adam_onecycle\n",
    "    LR: 0.01\n",
    "    WEIGHT_DECAY: 0.01\n",
    "    MOMENTUM: 0.9\n",
    "\n",
    "    MOMS: [0.95, 0.85]\n",
    "    PCT_START: 0.4\n",
    "    DIV_FACTOR: 10\n",
    "    DECAY_STEP_LIST: [35, 45]\n",
    "    LR_DECAY: 0.1\n",
    "    LR_CLIP: 0.0000001\n",
    "\n",
    "    LR_WARMUP: False\n",
    "    WARMUP_EPOCH: 1\n",
    "\n",
    "    GRAD_NORM_CLIP: 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e65c3a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pcdet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a9667d4f5613>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpcdet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoint_feature_encoder\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPointFeatureEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpcdet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maugmentor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_augmentor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataAugmentor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpcdet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_processor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataProcessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pcdet'"
     ]
    }
   ],
   "source": [
    "### Custom_Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from pcdet.datasets.processor.point_feature_encoder import PointFeatureEncoder\n",
    "from pcdet.datasets.augmentor.data_augmentor import DataAugmentor\n",
    "from pcdet.datasets.processor.data_processor import DataProcessor\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from pcdet.datasets.kitti.kitti_object_eval_python.eval import *\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "class Onss_Dataset(Dataset):\n",
    "    def __init__(self, split_dir, mode='train'):\n",
    "\n",
    "        assert mode in ['train', 'valid', 'test']\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            # split_path = './split/train.txt'\n",
    "            split_path = split_dir + '/train.txt'\n",
    "        elif self.mode == 'valid':\n",
    "            # split_path = './split/valid.txt'\n",
    "            split_path = split_dir + '/valid.txt'\n",
    "        elif self.mode == 'test':\n",
    "            # split_path = './split/test.txt'\n",
    "            split_path = split_dir + '/test.txt'\n",
    "\n",
    "        self.samples = [line.rstrip() for line in open(split_path).readlines()]  # folder path, file number\n",
    "        # number of sample data\n",
    "        self.num_samples = len(self.samples)\n",
    "\n",
    "        self.class_names = ['Pedestrian', 'Stroller', 'Cart', 'Wheelchair']\n",
    "\n",
    "    #     def get_image(self, idx):\n",
    "    #         import cv2\n",
    "    #         img_dir_path = self.samples[idx].split(' ')[0]\n",
    "    #         img_idx = self.samples[idx].split(' ')[-1]\n",
    "    #         img_file = img_dir_path + '/cam/c_%s.png'%(img_idx)\n",
    "    #         assert os.path.exists(img_file)\n",
    "    #         return cv2.imread(img_file)  # (H, W, 3) BGR mode\n",
    "\n",
    "    def get_lidar(self, idx):\n",
    "        '''\n",
    "        < Return >\n",
    "            np_lidar_points : lidar points // numpy, (n,4), (x,y,z,intensity)\n",
    "        '''\n",
    "        lidar_dir_path = os.path.join(self.samples[idx].split(':')[0], 'lidar/lidar')\n",
    "        lidar_idx = self.samples[idx].split(':')[1]\n",
    "        lidar_file = lidar_dir_path + '/%s.bin' % lidar_idx\n",
    "        assert os.path.exists(lidar_file)\n",
    "\n",
    "        return np.fromfile(lidar_file, dtype=np.float32).reshape(-1, 4)\n",
    "\n",
    "    #     def get_calib(self, idx):\n",
    "    #         calib_dir_path = self.samples[idx].split(' ')[0]\n",
    "    #         calib_file = calib_dir_path + '/calb/calibration.txt'\n",
    "    #         assert os.path.exists(calib_file)\n",
    "    #         # TODO: calibration matrix\n",
    "    #         calib = [line.rstrip() for line in open(calib_file).readlines()]   # folder path, file number\n",
    "    #         return calib\n",
    "\n",
    "    def get_annos(self, idx):\n",
    "        '''\n",
    "        get lidar annotations\n",
    "        < Retrun >\n",
    "            objects\n",
    "        '''\n",
    "        label_dir_path = os.path.join(self.samples[idx].split(':')[0], 'lidar/lidar_label')\n",
    "        label_idx = self.samples[idx].split(':')[1]\n",
    "        label_file = label_dir_path + '/llab_%s.txt' % label_idx\n",
    "\n",
    "        assert os.path.exists(label_file)\n",
    "\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            if lines != []:\n",
    "                list_cls = [float(line.split(' ')[1]) + 1 for line in lines]\n",
    "                list_pos = [np.array([float(line.split(' ')[2]), float(line.split(' ')[3]), float(line.split(' ')[4])],\n",
    "                                     dtype='float32') for line in lines]\n",
    "                list_lwh = [np.array([float(line.split(' ')[5]), float(line.split(' ')[6]), float(line.split(' ')[7])],\n",
    "                                     dtype='float32') for line in lines]\n",
    "                list_ori = [float(line.split(' ')[8]) for line in lines]  # orientation(heading)\n",
    "\n",
    "                annos = {}\n",
    "                annos['cls'] = np.array(list_cls, dtype=np.float32)\n",
    "                annos['name'] = [self.class_names[int(id - 1)] for id in list_cls]\n",
    "                annos['pos'] = np.concatenate([pos.reshape(1, 3) for pos in list_pos], axis=0)\n",
    "                annos['lwh'] = np.concatenate([lwh.reshape(1, 3) for lwh in list_lwh], axis=0)\n",
    "                annos['ori'] = np.array(list_ori, dtype=np.float32)\n",
    "                annos['location'] = np.concatenate([pos.reshape(1, 3) for pos in list_pos], axis=0)\n",
    "                annos['dimensions'] = np.concatenate([lwh.reshape(1, 3) for lwh in list_lwh], axis=0)\n",
    "                annos['rotation_y'] = np.array(list_ori, dtype=np.float32)\n",
    "            else:\n",
    "                annos = None\n",
    "        return annos\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# pointpillar Dataset\n",
    "#######################################################\n",
    "class OnssDataset(Onss_Dataset):\n",
    "    def __init__(self, split_dir, mode='train', dataset_cfg=None):\n",
    "        super().__init__(split_dir=split_dir, mode=mode)\n",
    "\n",
    "        self.dataset_cfg = dataset_cfg\n",
    "\n",
    "        # Feature encoder\n",
    "        self.point_cloud_range = np.array(self.dataset_cfg.POINT_CLOUD_RANGE, dtype=np.float32)\n",
    "        self.point_feature_encoder = PointFeatureEncoder(\n",
    "            self.dataset_cfg.POINT_FEATURE_ENCODING,\n",
    "            point_cloud_range=self.point_cloud_range\n",
    "        )\n",
    "\n",
    "        # Not use augmentor\n",
    "        self.data_augmentor = None\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            # create data processor\n",
    "            self.data_processor = DataProcessor(\n",
    "                self.dataset_cfg.DATA_PROCESSOR, point_cloud_range=self.point_cloud_range, training=True,\n",
    "                num_point_features=3\n",
    "            )\n",
    "        else:\n",
    "            self.data_processor = DataProcessor(\n",
    "                self.dataset_cfg.DATA_PROCESSOR, point_cloud_range=self.point_cloud_range, training=False\n",
    "            )\n",
    "\n",
    "        self.grid_size = self.data_processor.grid_size\n",
    "        self.voxel_size = self.data_processor.voxel_size\n",
    "\n",
    "        self.total_epochs = 0\n",
    "\n",
    "    def prepare_data(self, data_dict):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dict:\n",
    "                points: (N, 3 + C_in)\n",
    "                gt_names: optional, (N), int\n",
    "                gt_boxes: optional, (N, 7 + C) [x, y, z, dx, dy, dz, heading, ...]\n",
    "                ...\n",
    "\n",
    "        Returns:\n",
    "            data_dict:\n",
    "                frame_id: string\n",
    "                points: (N, 3 + C_in)\n",
    "                gt_names: optional, (N), int\n",
    "                gt_boxes: optional, (N, 7 + C) [x, y, z, dx, dy, dz, heading, ...]\n",
    "\n",
    "                use_lead_xyz: bool\n",
    "                voxels: optional (num_voxels, max_points_per_voxel, 3 + C)\n",
    "                voxel_coords: optional (num_voxels, 3)\n",
    "                voxel_num_points: optional (num_voxels)\n",
    "                ...\n",
    "        \"\"\"\n",
    "        if self.mode != 'test':\n",
    "            if len(data_dict['gt_boxes']) == 0:\n",
    "                new_index = np.random.randint(self.__len__())\n",
    "                return self.__getitem__(new_index)\n",
    "\n",
    "        data_dict = self.point_feature_encoder.forward(data_dict)\n",
    "\n",
    "        # Data Processing\n",
    "        data_dict = self.data_processor.forward(data_dict=data_dict)  # return voxels, voxel_coords, voxel_num_points\n",
    "\n",
    "        return data_dict\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load data\n",
    "        points = self.get_lidar(index)\n",
    "        if self.mode == 'test':\n",
    "            annos = None\n",
    "        else:\n",
    "            annos = self.get_annos(index)\n",
    "\n",
    "        if annos is not None:\n",
    "            gt_names = annos['cls']\n",
    "            # gt_boxes: [pos_x, pos_y, pos_x, length, width, height, heading, class]\n",
    "            tmp_gt_boxes = np.hstack((annos['pos'], annos['lwh']))\n",
    "            gt_boxes = np.hstack((tmp_gt_boxes, annos['ori'].reshape(-1, 1)))\n",
    "            gt_boxes = np.hstack((gt_boxes, gt_names.reshape(-1, 1))).astype(np.float32)\n",
    "\n",
    "            location = annos['pos']\n",
    "            dimensions = annos['lwh']\n",
    "            rotation_y = annos['ori']\n",
    "\n",
    "            # train and valid\n",
    "            input_dict = {'frame_id': self.samples[index],\n",
    "                          'points': points,\n",
    "                          'gt_boxes': gt_boxes,\n",
    "                          'location': location,\n",
    "                          'dimensions': dimensions,\n",
    "                          'rotation_y': rotation_y\n",
    "                          }\n",
    "        else:\n",
    "            # test\n",
    "            input_dict = {'frame_id': self.samples[index],\n",
    "                          'points': points,\n",
    "                          'gt_boxes': []}\n",
    "\n",
    "        # prepare data\n",
    "        data_dict = self.prepare_data(data_dict=input_dict)\n",
    "\n",
    "        return data_dict\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_batch(batch_list, _unused=False):\n",
    "        data_dict = defaultdict(list)\n",
    "        for cur_sample in batch_list:\n",
    "            for key, val in cur_sample.items():\n",
    "                data_dict[key].append(val)\n",
    "        batch_size = len(batch_list)\n",
    "        ret = {}\n",
    "\n",
    "        for key, val in data_dict.items():\n",
    "            try:\n",
    "                if key in ['voxels', 'voxel_num_points']:\n",
    "                    ret[key] = np.concatenate(val, axis=0)\n",
    "                elif key in ['points', 'voxel_coords']:\n",
    "                    coors = []\n",
    "                    for i, coor in enumerate(val):\n",
    "                        coor_pad = np.pad(coor, ((0, 0), (1, 0)), mode='constant', constant_values=i)\n",
    "                        coors.append(coor_pad)\n",
    "                    ret[key] = np.concatenate(coors, axis=0)\n",
    "                elif key in ['gt_boxes']:\n",
    "                    max_gt = max([len(x) for x in val])\n",
    "                    batch_gt_boxes3d = np.zeros((batch_size, max_gt, val[0].shape[-1]), dtype=np.float32)\n",
    "                    for k in range(batch_size):\n",
    "                        batch_gt_boxes3d[k, :val[k].__len__(), :] = val[k]\n",
    "                    ret[key] = batch_gt_boxes3d\n",
    "                elif key in ['location', 'dimensions', 'rotation_y']:\n",
    "                    ret[key] = np.concatenate(val, axis=0)\n",
    "\n",
    "                else:\n",
    "                    ret[key] = np.stack(val, axis=0)\n",
    "            except:\n",
    "                print('Error in collate_batch: key=%s' % key)\n",
    "                raise TypeError\n",
    "\n",
    "        ret['batch_size'] = batch_size\n",
    "        return ret\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_prediction_dicts(batch_dict, pred_dicts, class_names, output_path=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch_dict:\n",
    "                frame_id:\n",
    "            pred_dicts: list of pred_dicts\n",
    "                pred_boxes: (N, 7), Tensor\n",
    "                pred_scores: (N), Tensor\n",
    "                pred_labels: (N), Tensor\n",
    "            class_names:\n",
    "            output_path:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        def get_template_prediction(num_samples):\n",
    "            ret_dict = {\n",
    "                'name': np.zeros(num_samples), 'score': np.zeros(num_samples),\n",
    "                'boxes_lidar': np.zeros([num_samples, 7])\n",
    "            }\n",
    "            return ret_dict\n",
    "\n",
    "        def generate_single_sample_dict(box_dict):\n",
    "            pred_scores = box_dict['pred_scores'].cpu().numpy()\n",
    "            pred_boxes = box_dict['pred_boxes'].cpu().numpy()\n",
    "            pred_labels = box_dict['pred_labels'].cpu().numpy()\n",
    "            pred_dict = get_template_prediction(pred_scores.shape[0])\n",
    "            if pred_scores.shape[0] == 0:\n",
    "                return pred_dict\n",
    "\n",
    "            pred_dict['name'] = np.array(class_names)[pred_labels - 1]\n",
    "            pred_dict['score'] = pred_scores\n",
    "            pred_dict['boxes_lidar'] = pred_boxes\n",
    "            pred_dict['location'] = pred_boxes[:, 0:3]\n",
    "            pred_dict['dimensions'] = pred_boxes[:, 3:6]\n",
    "            pred_dict['rotation_y'] = pred_boxes[:, 6]\n",
    "\n",
    "            return pred_dict\n",
    "\n",
    "        annos = []\n",
    "        for index, box_dict in enumerate(pred_dicts):\n",
    "            single_pred_dict = generate_single_sample_dict(box_dict)\n",
    "            single_pred_dict['frame_id'] = batch_dict['frame_id'][index]\n",
    "            # single_pred_dict['metadata'] = batch_dict['metadata'][index]\n",
    "            annos.append(single_pred_dict)\n",
    "\n",
    "        return annos\n",
    "\n",
    "    def clean_data(self, gt_anno, dt_anno, current_class, difficulty):\n",
    "        CLASS_NAMES = ['Pedestrian', 'Stroller', 'Cart', 'Wheelchair']\n",
    "        MIN_HEIGHT = [40, 25, 25]\n",
    "        MAX_OCCLUSION = [0, 1, 2]\n",
    "        MAX_TRUNCATION = [0.15, 0.3, 0.5]\n",
    "        dc_bboxes, ignored_gt, ignored_dt = [], [], []\n",
    "        current_cls_name = CLASS_NAMES[current_class].lower()\n",
    "        num_gt = len(gt_anno[\"name\"])\n",
    "        num_dt = len(dt_anno[\"name\"])\n",
    "        num_valid_gt = 0\n",
    "\n",
    "        for i in range(num_gt):\n",
    "            gt_name = gt_anno[\"name\"][i].lower()\n",
    "            valid_class = -1\n",
    "            if (gt_name == current_cls_name):\n",
    "                valid_class = 1\n",
    "            else:\n",
    "                valid_class = -1\n",
    "\n",
    "            ignore = False\n",
    "            if valid_class == 1 and not ignore:\n",
    "                ignored_gt.append(0)\n",
    "                num_valid_gt += 1\n",
    "            elif (valid_class == 0 or (ignore and (valid_class == 1))):\n",
    "                ignored_gt.append(1)\n",
    "            else:\n",
    "                ignored_gt.append(-1)\n",
    "\n",
    "        for i in range(num_dt):\n",
    "            if (dt_anno[\"name\"][i].lower() == current_cls_name):\n",
    "                valid_class = 1\n",
    "            else:\n",
    "                valid_class = -1\n",
    "\n",
    "            if valid_class == 1:\n",
    "                ignored_dt.append(0)\n",
    "            else:\n",
    "                ignored_dt.append(-1)\n",
    "\n",
    "        return num_valid_gt, ignored_gt, ignored_dt, dc_bboxes\n",
    "\n",
    "    def _prepare_data(self, gt_annos, dt_annos, current_class, difficulty):\n",
    "        gt_datas_list = []\n",
    "        dt_datas_list = []\n",
    "        total_dc_num = []\n",
    "        ignored_gts, ignored_dets, dontcares = [], [], []\n",
    "        total_num_valid_gt = 0\n",
    "        for i in range(len(gt_annos)):\n",
    "            rets = self.clean_data(gt_annos[i], dt_annos[i], current_class, difficulty)\n",
    "            num_valid_gt, ignored_gt, ignored_det, dc_bboxes = rets\n",
    "\n",
    "            ignored_gts.append(np.array(ignored_gt, dtype=np.int64))\n",
    "            ignored_dets.append(np.array(ignored_det, dtype=np.int64))\n",
    "            if len(dc_bboxes) == 0:\n",
    "                dc_bboxes = np.zeros((0, 4)).astype(np.float64)\n",
    "            else:\n",
    "                dc_bboxes = np.stack(dc_bboxes, 0).astype(np.float64)\n",
    "            total_dc_num.append(dc_bboxes.shape[0])\n",
    "            dontcares.append(dc_bboxes)\n",
    "            total_num_valid_gt += num_valid_gt\n",
    "            gt_datas = np.concatenate([gt_annos[i][\"pos\"], gt_annos[i][\"cls\"][..., np.newaxis]], 1)\n",
    "            dt_datas = np.concatenate([\n",
    "                dt_annos[i][\"score\"][..., np.newaxis]\n",
    "            ], 1)\n",
    "            gt_datas_list.append(gt_datas)\n",
    "            dt_datas_list.append(dt_datas)\n",
    "        total_dc_num = np.stack(total_dc_num, axis=0)\n",
    "        return (gt_datas_list, dt_datas_list, ignored_gts, ignored_dets, dontcares,\n",
    "                total_dc_num, total_num_valid_gt)\n",
    "\n",
    "    def eval_class(self,\n",
    "                   gt_annos,\n",
    "                   dt_annos,\n",
    "                   current_classes,\n",
    "                   difficultys,\n",
    "                   metric,\n",
    "                   min_overlaps,\n",
    "                   compute_aos=False,\n",
    "                   num_parts=100):\n",
    "        \"\"\"Kitti eval. support 2d/bev/3d/aos eval. support 0.5:0.05:0.95 coco AP.\n",
    "        Args:\n",
    "            gt_annos: dict, must from get_label_annos() in kitti_common.py\n",
    "            dt_annos: dict, must from get_label_annos() in kitti_common.py\n",
    "            current_classes: list of int, 0: car, 1: pedestrian, 2: cyclist\n",
    "            difficultys: list of int. eval difficulty, 0: easy, 1: normal, 2: hard\n",
    "            metric: eval type. 0: bbox, 1: bev, 2: 3d\n",
    "            min_overlaps: float, min overlap. format: [num_overlap, metric, class].\n",
    "            num_parts: int. a parameter for fast calculate algorithm\n",
    "\n",
    "        Returns:\n",
    "            dict of recall, precision and aos\n",
    "        \"\"\"\n",
    "        assert len(gt_annos) == len(dt_annos)\n",
    "\n",
    "        num_examples = len(gt_annos)\n",
    "        split_parts = get_split_parts(num_examples, num_parts)\n",
    "\n",
    "        rets = calculate_iou_partly(gt_annos, dt_annos, metric, num_parts)\n",
    "        overlaps, parted_overlaps, total_dt_num, total_gt_num = rets\n",
    "        N_SAMPLE_PTS = 41\n",
    "\n",
    "        num_minoverlap = len(min_overlaps)\n",
    "        num_class = len(current_classes)\n",
    "        num_difficulty = len(difficultys)\n",
    "\n",
    "        precision = np.zeros([num_class, num_difficulty, num_minoverlap, N_SAMPLE_PTS])\n",
    "        recall = np.zeros([num_class, num_difficulty, num_minoverlap, N_SAMPLE_PTS])\n",
    "        aos = np.zeros([num_class, num_difficulty, num_minoverlap, N_SAMPLE_PTS])\n",
    "\n",
    "        for m, current_class in enumerate(current_classes):\n",
    "            for l, difficulty in enumerate(difficultys):\n",
    "                rets = self._prepare_data(gt_annos, dt_annos, current_class, difficulty)\n",
    "                (gt_datas_list, dt_datas_list, ignored_gts, ignored_dets,\n",
    "                 dontcares, total_dc_num, total_num_valid_gt) = rets\n",
    "                for k, min_overlap in enumerate(min_overlaps[:, metric, m]):\n",
    "                    thresholdss = []\n",
    "                    for i in range(len(gt_annos)):\n",
    "                        rets = compute_statistics_jit(\n",
    "                            overlaps[i],\n",
    "                            gt_datas_list[i],\n",
    "                            dt_datas_list[i],\n",
    "                            ignored_gts[i],\n",
    "                            ignored_dets[i],\n",
    "                            dontcares[i],\n",
    "                            metric,\n",
    "                            min_overlap=min_overlap,\n",
    "                            thresh=0.0,\n",
    "                            compute_fp=False)\n",
    "                        _, _, _, _, thresholds = rets\n",
    "                        thresholdss += thresholds.tolist()\n",
    "                    thresholdss = np.array(thresholdss)\n",
    "                    thresholds = get_thresholds(thresholdss, total_num_valid_gt)\n",
    "                    thresholds = np.array(thresholds)\n",
    "\n",
    "                    pr = np.zeros([len(thresholds), 4])\n",
    "                    idx = 0\n",
    "                    for j, num_part in enumerate(split_parts):\n",
    "                        gt_datas_part = np.concatenate(gt_datas_list[idx:idx + num_part], 0)\n",
    "                        dt_datas_part = np.concatenate(dt_datas_list[idx:idx + num_part], 0)\n",
    "                        dc_datas_part = np.concatenate(dontcares[idx:idx + num_part], 0)\n",
    "                        ignored_dets_part = np.concatenate(ignored_dets[idx:idx + num_part], 0)\n",
    "                        ignored_gts_part = np.concatenate(ignored_gts[idx:idx + num_part], 0)\n",
    "                        fused_compute_statistics(\n",
    "                            parted_overlaps[j],\n",
    "                            pr,\n",
    "                            total_gt_num[idx:idx + num_part],\n",
    "                            total_dt_num[idx:idx + num_part],\n",
    "                            total_dc_num[idx:idx + num_part],\n",
    "                            gt_datas_part,\n",
    "                            dt_datas_part,\n",
    "                            dc_datas_part,\n",
    "                            ignored_gts_part,\n",
    "                            ignored_dets_part,\n",
    "                            metric,\n",
    "                            min_overlap=min_overlap,\n",
    "                            thresholds=thresholds,\n",
    "                            compute_aos=compute_aos)\n",
    "                        idx += num_part\n",
    "\n",
    "                    for i in range(len(thresholds)):\n",
    "                        recall[m, l, k, i] = pr[i, 0] / (pr[i, 0] + pr[i, 2])\n",
    "                        precision[m, l, k, i] = pr[i, 0] / (pr[i, 0] + pr[i, 1])\n",
    "                        if compute_aos:\n",
    "                            aos[m, l, k, i] = pr[i, 3] / (pr[i, 0] + pr[i, 1])\n",
    "                    for i in range(len(thresholds)):\n",
    "                        precision[m, l, k, i] = np.max(precision[m, l, k, i:], axis=-1)\n",
    "                        recall[m, l, k, i] = np.max(recall[m, l, k, i:], axis=-1)\n",
    "                        if compute_aos:\n",
    "                            aos[m, l, k, i] = np.max(aos[m, l, k, i:], axis=-1)\n",
    "        ret_dict = {\n",
    "            \"recall\": recall,\n",
    "            \"precision\": precision,\n",
    "            \"orientation\": aos,\n",
    "        }\n",
    "        return ret_dict\n",
    "\n",
    "    def evaluation(self, det_annos, class_names, **kwargs):\n",
    "\n",
    "        dt_annos = copy.deepcopy(det_annos)\n",
    "        gt_annos = [copy.deepcopy(self.get_annos(idx)) for idx in range(self.num_samples)]\n",
    "\n",
    "        current_classes = self.class_names\n",
    "        overlap_0_5 = np.array([[0.3, 0.3, 0.3, 0.3],  # for easy [Pedestrian, Stroller, Cart, Wheelchair]\n",
    "                                [0.3, 0.3, 0.3, 0.3],  # for moderate [Pedestrian, Stroller, Cart, Wheelchair]\n",
    "                                [0.3, 0.3, 0.3, 0.3]])  # for hard [Pedestrian, Stroller, Cart, Wheelchair]\n",
    "        min_overlaps = np.stack([overlap_0_5], axis=0)\n",
    "        class_to_name = {\n",
    "            0: 'Pedestrian',\n",
    "            1: 'Stroller',\n",
    "            2: 'Cart',\n",
    "            3: 'Wheelchair'\n",
    "        }\n",
    "        name_to_class = {v: n for n, v in class_to_name.items()}\n",
    "        if not isinstance(current_classes, (list, tuple)):\n",
    "            current_classes = [current_classes]\n",
    "        current_classes_int = []\n",
    "        for curcls in current_classes:\n",
    "            if isinstance(curcls, str):\n",
    "                current_classes_int.append(name_to_class[curcls])\n",
    "            else:\n",
    "                current_classes_int.append(curcls)\n",
    "        current_classes = current_classes_int\n",
    "        min_overlaps = min_overlaps[:, :, current_classes]\n",
    "        result = '\\n'\n",
    "\n",
    "        difficultys = [0, 1, 2]\n",
    "        ret = self.eval_class(gt_annos, dt_annos, current_classes, difficultys, 2, min_overlaps)\n",
    "        mAP3d = get_mAP(ret[\"precision\"])\n",
    "\n",
    "        ret_dict = {}\n",
    "        for j, curcls in enumerate(current_classes):\n",
    "            # mAP threshold array: [num_minoverlap, metric, class]\n",
    "            # mAP result: [num_class, num_diff, num_minoverlap]\n",
    "            for i in range(min_overlaps.shape[0]):\n",
    "                result += print_str(\n",
    "                    (f\"{class_to_name[curcls]} \"\n",
    "                     \"AP@{:.2f}:\".format(min_overlaps[i, 2, j])))\n",
    "                result += print_str((f\"3d   AP:{mAP3d[j, 2, i]:.4f}, \"))\n",
    "        return result, ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d98c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Custom_train.py\n",
    "import argparse\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from test import repeat_eval_ckpt\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from pcdet.config import cfg, cfg_from_list, cfg_from_yaml_file, log_config_to_file\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.models import build_network, model_fn_decorator\n",
    "from pcdet.utils import common_utils\n",
    "from train_utils.optimization import build_optimizer, build_scheduler\n",
    "from train_utils.train_utils import train_model\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from pcdet.datasets.onss.onss_dataset import OnssDataset\n",
    "\n",
    "### parser추가 가능(원하는 기능을 추가로 필요 시)\n",
    "def parse_config():\n",
    "    parser = argparse.ArgumentParser(description='arg parser')\n",
    "    parser.add_argument('--cfg_file', type=str, default=None, help='specify the config for training')\n",
    "\n",
    "    parser.add_argument('--batch_size', type=int, default=None, required=False, help='batch size for training')\n",
    "    parser.add_argument('--epochs', type=int, default=None, required=False, help='number of epochs to train for')\n",
    "    parser.add_argument('--workers', type=int, default=8, help='number of workers for dataloader')\n",
    "    parser.add_argument('--extra_tag', type=str, default='default', help='extra tag for this experiment')\n",
    "    parser.add_argument('--ckpt', type=str, default=None, help='checkpoint to start from')\n",
    "    parser.add_argument('--pretrained_model', type=str, default=None, help='pretrained_model')\n",
    "    parser.add_argument('--launcher', choices=['none', 'pytorch', 'slurm'], default='none')\n",
    "    parser.add_argument('--tcp_port', type=int, default=18888, help='tcp port for distrbuted training')\n",
    "    parser.add_argument('--sync_bn', action='store_true', default=False, help='whether to use sync bn')\n",
    "    parser.add_argument('--fix_random_seed', action='store_true', default=False, help='')\n",
    "    parser.add_argument('--ckpt_save_interval', type=int, default=1, help='number of training epochs')\n",
    "    parser.add_argument('--local_rank', type=int, default=0, help='local rank for distributed training')\n",
    "    parser.add_argument('--max_ckpt_save_num', type=int, default=30, help='max number of saved checkpoint')\n",
    "    parser.add_argument('--merge_all_iters_to_one_epoch', action='store_true', default=False, help='')\n",
    "    parser.add_argument('--set', dest='set_cfgs', default=None, nargs=argparse.REMAINDER,\n",
    "                        help='set extra config keys if needed')\n",
    "    parser.add_argument('--max_waiting_mins', type=int, default=0, help='max waiting minutes')\n",
    "    parser.add_argument('--start_epoch', type=int, default=0, help='')\n",
    "    parser.add_argument('--save_to_file', action='store_true', default=False, help='')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    cfg_from_yaml_file(args.cfg_file, cfg)\n",
    "    cfg.TAG = Path(args.cfg_file).stem\n",
    "    cfg.EXP_GROUP_PATH = '/'.join(args.cfg_file.split('/')[1:-1])  # remove 'cfgs' and 'xxxx.yaml'\n",
    "\n",
    "    if args.set_cfgs is not None:\n",
    "        cfg_from_list(args.set_cfgs, cfg)\n",
    "\n",
    "    return args, cfg\n",
    "\n",
    "\n",
    "def main():\n",
    "    args, cfg = parse_config()\n",
    "    if args.launcher == 'none':\n",
    "        dist_train = False\n",
    "        total_gpus = 1\n",
    "    else:\n",
    "        total_gpus, cfg.LOCAL_RANK = getattr(common_utils, 'init_dist_%s' % args.launcher)(\n",
    "            args.tcp_port, args.local_rank, backend='nccl'\n",
    "        )\n",
    "        dist_train = True\n",
    "\n",
    "    if args.batch_size is None:\n",
    "        args.batch_size = cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU\n",
    "    else:\n",
    "        assert args.batch_size % total_gpus == 0, 'Batch size should match the number of gpus'\n",
    "        args.batch_size = args.batch_size // total_gpus\n",
    "\n",
    "    args.epochs = cfg.OPTIMIZATION.NUM_EPOCHS if args.epochs is None else args.epochs\n",
    "\n",
    "    if args.fix_random_seed:\n",
    "        common_utils.set_random_seed(666+cfg.LOCAL_RANK)\n",
    "\n",
    "    output_dir = cfg.ROOT_DIR / 'output' / cfg.EXP_GROUP_PATH / cfg.TAG / args.extra_tag\n",
    "    ckpt_dir = output_dir / 'ckpt'\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    log_file = output_dir / ('log_train_%s.txt' % datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "    logger = common_utils.create_logger(log_file, rank=cfg.LOCAL_RANK)\n",
    "\n",
    "    # log to file\n",
    "    logger.info('**********************Start logging**********************')\n",
    "    gpu_list = os.environ['CUDA_VISIBLE_DEVICES'] if 'CUDA_VISIBLE_DEVICES' in os.environ.keys() else 'ALL'\n",
    "    logger.info('CUDA_VISIBLE_DEVICES=%s' % gpu_list)\n",
    "\n",
    "    if dist_train:\n",
    "        logger.info('total_batch_size: %d' % (total_gpus * args.batch_size))\n",
    "    for key, val in vars(args).items():\n",
    "        logger.info('{:16} {}'.format(key, val))\n",
    "    log_config_to_file(cfg, logger=logger)\n",
    "    if cfg.LOCAL_RANK == 0:\n",
    "        os.system('cp %s %s' % (args.cfg_file, output_dir))\n",
    "\n",
    "    tb_log = SummaryWriter(log_dir=str(output_dir / 'tensorboard')) if cfg.LOCAL_RANK == 0 else None\n",
    "\n",
    "    # train dataset load\n",
    "    train_set = OnssDataset(split_dir='/extra_data/data/lidar_test/split/', mode='train', dataset_cfg=cfg.DATA_CONFIG)\n",
    "    train_sampler = None\n",
    "    train_loader = DataLoader(\n",
    "        train_set, batch_size=args.batch_size, pin_memory=True, num_workers=args.workers,\n",
    "        shuffle=True, collate_fn=train_set.collate_batch,\n",
    "        drop_last=False, sampler=train_sampler, timeout=0\n",
    "    )\n",
    "\n",
    "    model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=train_set)\n",
    "    if args.sync_bn:\n",
    "        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "    model.cuda()\n",
    "\n",
    "    optimizer = build_optimizer(model, cfg.OPTIMIZATION)\n",
    "\n",
    "    # load checkpoint if it is possible\n",
    "    start_epoch = it = 0\n",
    "    last_epoch = -1\n",
    "    if args.pretrained_model is not None:\n",
    "        model.load_params_from_file(filename=args.pretrained_model, to_cpu=dist, logger=logger)\n",
    "\n",
    "    if args.ckpt is not None:\n",
    "        it, start_epoch = model.load_params_with_optimizer(args.ckpt, to_cpu=dist, optimizer=optimizer, logger=logger)\n",
    "        last_epoch = start_epoch + 1\n",
    "    else:\n",
    "        ckpt_list = glob.glob(str(ckpt_dir / '*checkpoint_epoch_*.pth'))\n",
    "        if len(ckpt_list) > 0:\n",
    "            ckpt_list.sort(key=os.path.getmtime)\n",
    "            it, start_epoch = model.load_params_with_optimizer(\n",
    "                ckpt_list[-1], to_cpu=dist, optimizer=optimizer, logger=logger\n",
    "            )\n",
    "            last_epoch = start_epoch + 1\n",
    "\n",
    "    model.train()  # before wrap to DistributedDataParallel to support fixed some parameters\n",
    "    if dist_train:\n",
    "        model = nn.parallel.DistributedDataParallel(model, device_ids=[cfg.LOCAL_RANK % torch.cuda.device_count()])\n",
    "    logger.info(model)\n",
    "\n",
    "    lr_scheduler, lr_warmup_scheduler = build_scheduler(\n",
    "        optimizer, total_iters_each_epoch=len(train_loader), total_epochs=args.epochs,\n",
    "        last_epoch=last_epoch, optim_cfg=cfg.OPTIMIZATION\n",
    "    )\n",
    "\n",
    "    # -----------------------start training---------------------------\n",
    "    logger.info('**********************Start training %s/%s(%s)**********************'\n",
    "                % (cfg.EXP_GROUP_PATH, cfg.TAG, args.extra_tag))\n",
    "\n",
    "    train_model(\n",
    "        model,\n",
    "        optimizer,\n",
    "        train_loader,\n",
    "        model_func=model_fn_decorator(),\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        optim_cfg=cfg.OPTIMIZATION,\n",
    "        start_epoch=start_epoch,\n",
    "        total_epochs=args.epochs,\n",
    "        start_iter=it,\n",
    "        rank=cfg.LOCAL_RANK,\n",
    "        tb_log=tb_log,\n",
    "        ckpt_save_dir=ckpt_dir,\n",
    "        train_sampler=train_sampler,\n",
    "        lr_warmup_scheduler=lr_warmup_scheduler,\n",
    "        ckpt_save_interval=args.ckpt_save_interval,\n",
    "        max_ckpt_save_num=args.max_ckpt_save_num,\n",
    "        merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch\n",
    "    )\n",
    "\n",
    "    logger.info('**********************End training %s/%s(%s)**********************\\n\\n\\n'\n",
    "                % (cfg.EXP_GROUP_PATH, cfg.TAG, args.extra_tag))\n",
    "\n",
    "    logger.info('**********************Start evaluation %s/%s(%s)**********************' %\n",
    "                (cfg.EXP_GROUP_PATH, cfg.TAG, args.extra_tag))\n",
    "\n",
    "    # test dataset load\n",
    "    test_set = OnssDataset(split_dir='/extra_data/data/lidar_test/split/', mode='valid', dataset_cfg=cfg.DATA_CONFIG)\n",
    "    test_sampler = None\n",
    "    test_loader = DataLoader(\n",
    "        test_set, batch_size=args.batch_size, pin_memory=True, num_workers=args.workers,\n",
    "        shuffle=False, collate_fn=test_set.collate_batch,\n",
    "        drop_last=False, sampler=test_sampler, timeout=0\n",
    "    )\n",
    "\n",
    "    eval_output_dir = output_dir / 'eval' / 'eval_with_train'\n",
    "    eval_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    args.start_epoch = max(args.epochs - 10, 0)  # Only evaluate the last 10 epochs\n",
    "\n",
    "    repeat_eval_ckpt(\n",
    "        model.module if dist_train else model,\n",
    "        test_loader, args, eval_output_dir, logger, ckpt_dir,\n",
    "        dist_test=dist_train\n",
    "    )\n",
    "    logger.info('**********************End evaluation %s/%s(%s)**********************' %\n",
    "                (cfg.EXP_GROUP_PATH, cfg.TAG, args.extra_tag))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2402652a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393b8bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d2359a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b571a2da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e29d519",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
