{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "part4-ch4-swinT.ipynb",
   "provenance": [],
   "machine_shape": "hm",
   "mount_file_id": "1AnaIuWDz1m1PI4_uY_MlfvT-UmeuKM2N",
   "authorship_tag": "ABX9TyPNirXdK3uEcuDUlyk08UTY"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "cd /content/drive/MyDrive/lecture"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5CcN98h8KGca",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661081344868,
     "user_tz": -540,
     "elapsed": 2,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "outputId": "337e0f45-5794-4541-86ef-e59b798894ee",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/drive/MyDrive/lecture\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/microsoft/Swin-Transformer.git"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lK_WmF5ZKdhy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661081369113,
     "user_tz": -540,
     "elapsed": 2101,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "outputId": "499efa17-cb85-4c6d-d83f-eb1f372b0c0b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'Swin-Transformer'...\n",
      "remote: Enumerating objects: 338, done.\u001B[K\n",
      "remote: Counting objects: 100% (71/71), done.\u001B[K\n",
      "remote: Compressing objects: 100% (49/49), done.\u001B[K\n",
      "remote: Total 338 (delta 35), reused 48 (delta 21), pack-reused 267\u001B[K\n",
      "Receiving objects: 100% (338/338), 1.04 MiB | 2.47 MiB/s, done.\n",
      "Resolving deltas: 100% (185/185), done.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "cd Swin-Transformer"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-U8NxKSUKi4C",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661081378434,
     "user_tz": -540,
     "elapsed": 2,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "outputId": "cc35783c-7ed4-4236-96eb-dcd86ab7b9f7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/drive/MyDrive/lecture/Swin-Transformer\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install timm"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2u0DBAk_Klra",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661081398449,
     "user_tz": -540,
     "elapsed": 3504,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "outputId": "d4abe2f7-071e-4c76-f70c-3a1642446699",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.6.7)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.13.1+cu113)\n",
      "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.12.1+cu113)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.1.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2022.6.15)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install yacs"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hw45XMLtKpoi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661081406366,
     "user_tz": -540,
     "elapsed": 3349,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "outputId": "a7de48bd-47fc-4c79-9723-6b13d86c1b91",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 31,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: yacs in /usr/local/lib/python3.7/dist-packages (0.1.8)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from yacs) (6.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -U PyYAML"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96lxzH2kKrtK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661081416400,
     "user_tz": -540,
     "elapsed": 5058,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "outputId": "913f488e-edbf-43ba-a238-7081c2e05837",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (6.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "pretrained model download"
   ],
   "metadata": {
    "id": "d3pHz9nHK5me",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pwd"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s9QReOv4LOnK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661081560279,
     "user_tz": -540,
     "elapsed": 4,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "outputId": "2e342441-7d08-4509-ceb5-cd7b8b1a8c94",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/drive/MyDrive/lecture/Swin-Transformer\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!wget https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_base_patch4_window16_256.pth"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTXyVhJeK4wi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661081618734,
     "user_tz": -540,
     "elapsed": 51780,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "outputId": "bea1b04c-d2cd-4090-c832-494f085932f6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2022-08-21 11:32:42--  https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_base_patch4_window16_256.pth\n",
      "Resolving github.com (github.com)... 20.27.177.113\n",
      "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/357198522/b74c3b85-8c43-41ac-b361-c6b1d16e9c02?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220821%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220821T113243Z&X-Amz-Expires=300&X-Amz-Signature=22c5764c8a7275b09c995d41d7f99b5b759db51482e249e0339be5ff7be731aa&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=357198522&response-content-disposition=attachment%3B%20filename%3Dswinv2_base_patch4_window16_256.pth&response-content-type=application%2Foctet-stream [following]\n",
      "--2022-08-21 11:32:43--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/357198522/b74c3b85-8c43-41ac-b361-c6b1d16e9c02?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220821%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220821T113243Z&X-Amz-Expires=300&X-Amz-Signature=22c5764c8a7275b09c995d41d7f99b5b759db51482e249e0339be5ff7be731aa&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=357198522&response-content-disposition=attachment%3B%20filename%3Dswinv2_base_patch4_window16_256.pth&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 368861515 (352M) [application/octet-stream]\n",
      "Saving to: ‘swinv2_base_patch4_window16_256.pth’\n",
      "\n",
      "swinv2_base_patch4_ 100%[===================>] 351.77M  5.69MB/s    in 50s     \n",
      "\n",
      "2022-08-21 11:33:34 (6.99 MB/s) - ‘swinv2_base_patch4_window16_256.pth’ saved [368861515/368861515]\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!python -m torch.distributed.launch --nproc_per_node 1 --master_port 12345 main.py --eval \\\n",
    "--cfg configs/swinv2/swinv2_base_patch4_window16_256.yaml --resume swinv2_base_patch4_window16_256.pth \\\n",
    " --data-path /content/drive/MyDrive/AI-NN/datasets/hym_data/"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SXGfexShKtyL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661082032285,
     "user_tz": -540,
     "elapsed": 36767,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "outputId": "98209193-8878-4741-a792-40fa6c4a08ed",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 37,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use_env is set by default in torchrun.\n",
      "If your script expects `--local_rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  FutureWarning,\n",
      "[Warning] Fused window process have not been installed. Please refer to get_started.md for installation.\n",
      "Tutel has not been installed. To use Swin-MoE, please install Tutel; otherwise, just ignore this.\n",
      "To use FusedLAMB or FusedAdam, please install apex.\n",
      "=> merge config from configs/swinv2/swinv2_base_patch4_window16_256.yaml\n",
      "RANK and WORLD_SIZE in environ: 0/1\n",
      "\u001B[32m[2022-08-21 11:39:55 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 342)\u001B[0m: INFO Full config saved to output/swinv2_base_patch4_window16_256/default/config.json\n",
      "\u001B[32m[2022-08-21 11:39:55 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 345)\u001B[0m: INFO AMP_ENABLE: true\n",
      "AMP_OPT_LEVEL: ''\n",
      "AUG:\n",
      "  AUTO_AUGMENT: rand-m9-mstd0.5-inc1\n",
      "  COLOR_JITTER: 0.4\n",
      "  CUTMIX: 1.0\n",
      "  CUTMIX_MINMAX: null\n",
      "  MIXUP: 0.8\n",
      "  MIXUP_MODE: batch\n",
      "  MIXUP_PROB: 1.0\n",
      "  MIXUP_SWITCH_PROB: 0.5\n",
      "  RECOUNT: 1\n",
      "  REMODE: pixel\n",
      "  REPROB: 0.25\n",
      "BASE:\n",
      "- ''\n",
      "DATA:\n",
      "  BATCH_SIZE: 32\n",
      "  CACHE_MODE: part\n",
      "  DATASET: imagenet\n",
      "  DATA_PATH: /content/drive/MyDrive/AI-NN/datasets/hym_data/\n",
      "  IMG_SIZE: 256\n",
      "  INTERPOLATION: bicubic\n",
      "  NUM_WORKERS: 2\n",
      "  PIN_MEMORY: true\n",
      "  ZIP_MODE: false\n",
      "EVAL_MODE: true\n",
      "FUSED_LAYERNORM: false\n",
      "FUSED_WINDOW_PROCESS: false\n",
      "LOCAL_RANK: 0\n",
      "MODEL:\n",
      "  DROP_PATH_RATE: 0.5\n",
      "  DROP_RATE: 0.0\n",
      "  LABEL_SMOOTHING: 0.1\n",
      "  NAME: swinv2_base_patch4_window16_256\n",
      "  NUM_CLASSES: 2\n",
      "  PRETRAINED: ''\n",
      "  RESUME: swinv2_base_patch4_window16_256.pth\n",
      "  SWIN:\n",
      "    APE: false\n",
      "    DEPTHS:\n",
      "    - 2\n",
      "    - 2\n",
      "    - 6\n",
      "    - 2\n",
      "    EMBED_DIM: 96\n",
      "    IN_CHANS: 3\n",
      "    MLP_RATIO: 4.0\n",
      "    NUM_HEADS:\n",
      "    - 3\n",
      "    - 6\n",
      "    - 12\n",
      "    - 24\n",
      "    PATCH_NORM: true\n",
      "    PATCH_SIZE: 4\n",
      "    QKV_BIAS: true\n",
      "    QK_SCALE: null\n",
      "    WINDOW_SIZE: 7\n",
      "  SWINV2:\n",
      "    APE: false\n",
      "    DEPTHS:\n",
      "    - 2\n",
      "    - 2\n",
      "    - 18\n",
      "    - 2\n",
      "    EMBED_DIM: 128\n",
      "    IN_CHANS: 3\n",
      "    MLP_RATIO: 4.0\n",
      "    NUM_HEADS:\n",
      "    - 4\n",
      "    - 8\n",
      "    - 16\n",
      "    - 32\n",
      "    PATCH_NORM: true\n",
      "    PATCH_SIZE: 4\n",
      "    PRETRAINED_WINDOW_SIZES:\n",
      "    - 0\n",
      "    - 0\n",
      "    - 0\n",
      "    - 0\n",
      "    QKV_BIAS: true\n",
      "    WINDOW_SIZE: 16\n",
      "  SWIN_MLP:\n",
      "    APE: false\n",
      "    DEPTHS:\n",
      "    - 2\n",
      "    - 2\n",
      "    - 6\n",
      "    - 2\n",
      "    EMBED_DIM: 96\n",
      "    IN_CHANS: 3\n",
      "    MLP_RATIO: 4.0\n",
      "    NUM_HEADS:\n",
      "    - 3\n",
      "    - 6\n",
      "    - 12\n",
      "    - 24\n",
      "    PATCH_NORM: true\n",
      "    PATCH_SIZE: 4\n",
      "    WINDOW_SIZE: 7\n",
      "  SWIN_MOE:\n",
      "    APE: false\n",
      "    AUX_LOSS_WEIGHT: 0.01\n",
      "    CAPACITY_FACTOR: 1.25\n",
      "    COSINE_ROUTER: false\n",
      "    COSINE_ROUTER_DIM: 256\n",
      "    COSINE_ROUTER_INIT_T: 0.5\n",
      "    DEPTHS:\n",
      "    - 2\n",
      "    - 2\n",
      "    - 6\n",
      "    - 2\n",
      "    EMBED_DIM: 96\n",
      "    GATE_NOISE: 1.0\n",
      "    INIT_STD: 0.02\n",
      "    IN_CHANS: 3\n",
      "    IS_GSHARD_LOSS: false\n",
      "    MLP_FC2_BIAS: true\n",
      "    MLP_RATIO: 4.0\n",
      "    MOE_BLOCKS:\n",
      "    - - -1\n",
      "    - - -1\n",
      "    - - -1\n",
      "    - - -1\n",
      "    MOE_DROP: 0.0\n",
      "    NORMALIZE_GATE: false\n",
      "    NUM_HEADS:\n",
      "    - 3\n",
      "    - 6\n",
      "    - 12\n",
      "    - 24\n",
      "    NUM_LOCAL_EXPERTS: 1\n",
      "    PATCH_NORM: true\n",
      "    PATCH_SIZE: 4\n",
      "    PRETRAINED_WINDOW_SIZES:\n",
      "    - 0\n",
      "    - 0\n",
      "    - 0\n",
      "    - 0\n",
      "    QKV_BIAS: true\n",
      "    QK_SCALE: null\n",
      "    TOP_VALUE: 1\n",
      "    USE_BPR: true\n",
      "    WINDOW_SIZE: 7\n",
      "  TYPE: swinv2\n",
      "OUTPUT: output/swinv2_base_patch4_window16_256/default\n",
      "PRINT_FREQ: 10\n",
      "SAVE_FREQ: 1\n",
      "SEED: 0\n",
      "TAG: default\n",
      "TEST:\n",
      "  CROP: true\n",
      "  SEQUENTIAL: false\n",
      "  SHUFFLE: false\n",
      "THROUGHPUT_MODE: false\n",
      "TRAIN:\n",
      "  ACCUMULATION_STEPS: 1\n",
      "  AUTO_RESUME: true\n",
      "  BASE_LR: 3.125e-05\n",
      "  CLIP_GRAD: 5.0\n",
      "  EPOCHS: 10\n",
      "  LR_SCHEDULER:\n",
      "    DECAY_EPOCHS: 30\n",
      "    DECAY_RATE: 0.1\n",
      "    NAME: cosine\n",
      "  MIN_LR: 3.125e-07\n",
      "  MOE:\n",
      "    SAVE_MASTER: false\n",
      "  OPTIMIZER:\n",
      "    BETAS:\n",
      "    - 0.9\n",
      "    - 0.999\n",
      "    EPS: 1.0e-08\n",
      "    MOMENTUM: 0.9\n",
      "    NAME: adamw\n",
      "  START_EPOCH: 0\n",
      "  USE_CHECKPOINT: false\n",
      "  WARMUP_EPOCHS: 20\n",
      "  WARMUP_LR: 3.125e-08\n",
      "  WEIGHT_DECAY: 0.05\n",
      "\n",
      "\u001B[32m[2022-08-21 11:39:55 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 346)\u001B[0m: INFO {\"cfg\": \"configs/swinv2/swinv2_base_patch4_window16_256.yaml\", \"opts\": null, \"batch_size\": null, \"data_path\": \"/content/drive/MyDrive/AI-NN/datasets/hym_data/\", \"zip\": false, \"cache_mode\": \"part\", \"pretrained\": null, \"resume\": \"swinv2_base_patch4_window16_256.pth\", \"accumulation_steps\": null, \"use_checkpoint\": false, \"disable_amp\": false, \"amp_opt_level\": null, \"output\": \"output\", \"tag\": null, \"eval\": true, \"throughput\": false, \"local_rank\": 0, \"fused_window_process\": false, \"fused_layernorm\": false, \"optim\": null}\n",
      "local rank 0 / global rank 0 successfully build train dataset\n",
      "local rank 0 / global rank 0 successfully build val dataset\n",
      "\u001B[32m[2022-08-21 11:39:55 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 87)\u001B[0m: INFO Creating model:swinv2/swinv2_base_patch4_window16_256\n",
      "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\u001B[32m[2022-08-21 11:39:57 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 89)\u001B[0m: INFO SwinTransformerV2(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (layers): ModuleList(\n",
      "    (0): BasicLayer(\n",
      "      dim=128, input_resolution=(64, 64), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=128, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=128, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=4\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=4, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=128, out_features=384, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=128, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=8, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=128, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=4\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=4, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=128, out_features=384, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.022)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        input_resolution=(64, 64), dim=128\n",
      "        (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicLayer(\n",
      "      dim=256, input_resolution=(32, 32), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=256, input_resolution=(32, 32), num_heads=8, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=256, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=8\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=8, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.043)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=256, input_resolution=(32, 32), num_heads=8, window_size=16, shift_size=8, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=256, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=8\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=8, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.065)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        input_resolution=(32, 32), dim=256\n",
      "        (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (2): BasicLayer(\n",
      "      dim=512, input_resolution=(16, 16), depth=18\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.087)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.109)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.130)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.152)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.174)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.196)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.217)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.239)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.261)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.283)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.304)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.326)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (12): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.348)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (13): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.370)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (14): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.391)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (15): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.413)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (16): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.435)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (17): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.457)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        input_resolution=(16, 16), dim=512\n",
      "        (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (3): BasicLayer(\n",
      "      dim=1024, input_resolution=(8, 8), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=1024, input_resolution=(8, 8), num_heads=32, window_size=8, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=1024, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=32\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=32, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.478)\n",
      "          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=1024, input_resolution=(8, 8), num_heads=32, window_size=8, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=1024, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=32\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=32, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.500)\n",
      "          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (head): Linear(in_features=1024, out_features=1000, bias=True)\n",
      ")\n",
      "\u001B[32m[2022-08-21 11:39:57 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 92)\u001B[0m: INFO number of params: 87918816\n",
      "\u001B[32m[2022-08-21 11:39:57 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 95)\u001B[0m: INFO number of GFLOPs: 21.795610624\n",
      "All checkpoints founded in output/swinv2_base_patch4_window16_256/default: []\n",
      "\u001B[32m[2022-08-21 11:39:57 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 129)\u001B[0m: INFO no checkpoint found in output/swinv2_base_patch4_window16_256/default, ignoring auto resume\n",
      "\u001B[32m[2022-08-21 11:39:57 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(utils.py 15)\u001B[0m: INFO ==============> Resuming form swinv2_base_patch4_window16_256.pth....................\n",
      "\u001B[32m[2022-08-21 11:39:58 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(utils.py 22)\u001B[0m: INFO <All keys matched successfully>\n",
      "\u001B[32m[2022-08-21 11:40:00 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 266)\u001B[0m: INFO Test: [0/5]\tTime 2.439 (2.439)\tLoss 9.2969 (9.2969)\tAcc@1 0.000 (0.000)\tAcc@5 0.000 (0.000)\tMem 2093MB\n",
      "\u001B[32m[2022-08-21 11:40:22 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 272)\u001B[0m: INFO  * Acc@1 0.000 Acc@5 0.000\n",
      "\u001B[32m[2022-08-21 11:40:22 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 134)\u001B[0m: INFO Accuracy of the network on the 153 test images: 0.0%\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "train 실습"
   ],
   "metadata": {
    "id": "BclSmZt9NaX3",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!python -m torch.distributed.launch --nproc_per_node 1 --master_port 12345  main.py \\\n",
    "--cfg configs/swinv2/swinv2_base_patch4_window16_256.yaml --data-path /content/drive/MyDrive/AI-NN/datasets/hym_data/ --batch-size 16 \\\n",
    "--accumulation-steps 2 "
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HzlckEnbKvuK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661082218419,
     "user_tz": -540,
     "elapsed": 91076,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "outputId": "b10fd184-185b-42e7-b1e9-5c2e80c455ec",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use_env is set by default in torchrun.\n",
      "If your script expects `--local_rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  FutureWarning,\n",
      "[Warning] Fused window process have not been installed. Please refer to get_started.md for installation.\n",
      "Tutel has not been installed. To use Swin-MoE, please install Tutel; otherwise, just ignore this.\n",
      "To use FusedLAMB or FusedAdam, please install apex.\n",
      "=> merge config from configs/swinv2/swinv2_base_patch4_window16_256.yaml\n",
      "RANK and WORLD_SIZE in environ: 0/1\n",
      "\u001B[32m[2022-08-21 11:42:07 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 342)\u001B[0m: INFO Full config saved to output/swinv2_base_patch4_window16_256/default/config.json\n",
      "\u001B[32m[2022-08-21 11:42:07 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 345)\u001B[0m: INFO AMP_ENABLE: true\n",
      "AMP_OPT_LEVEL: ''\n",
      "AUG:\n",
      "  AUTO_AUGMENT: rand-m9-mstd0.5-inc1\n",
      "  COLOR_JITTER: 0.4\n",
      "  CUTMIX: 1.0\n",
      "  CUTMIX_MINMAX: null\n",
      "  MIXUP: 0.8\n",
      "  MIXUP_MODE: batch\n",
      "  MIXUP_PROB: 1.0\n",
      "  MIXUP_SWITCH_PROB: 0.5\n",
      "  RECOUNT: 1\n",
      "  REMODE: pixel\n",
      "  REPROB: 0.25\n",
      "BASE:\n",
      "- ''\n",
      "DATA:\n",
      "  BATCH_SIZE: 16\n",
      "  CACHE_MODE: part\n",
      "  DATASET: imagenet\n",
      "  DATA_PATH: /content/drive/MyDrive/AI-NN/datasets/hym_data/\n",
      "  IMG_SIZE: 256\n",
      "  INTERPOLATION: bicubic\n",
      "  NUM_WORKERS: 2\n",
      "  PIN_MEMORY: true\n",
      "  ZIP_MODE: false\n",
      "EVAL_MODE: false\n",
      "FUSED_LAYERNORM: false\n",
      "FUSED_WINDOW_PROCESS: false\n",
      "LOCAL_RANK: 0\n",
      "MODEL:\n",
      "  DROP_PATH_RATE: 0.5\n",
      "  DROP_RATE: 0.0\n",
      "  LABEL_SMOOTHING: 0.1\n",
      "  NAME: swinv2_base_patch4_window16_256\n",
      "  NUM_CLASSES: 2\n",
      "  PRETRAINED: ''\n",
      "  RESUME: ''\n",
      "  SWIN:\n",
      "    APE: false\n",
      "    DEPTHS:\n",
      "    - 2\n",
      "    - 2\n",
      "    - 6\n",
      "    - 2\n",
      "    EMBED_DIM: 96\n",
      "    IN_CHANS: 3\n",
      "    MLP_RATIO: 4.0\n",
      "    NUM_HEADS:\n",
      "    - 3\n",
      "    - 6\n",
      "    - 12\n",
      "    - 24\n",
      "    PATCH_NORM: true\n",
      "    PATCH_SIZE: 4\n",
      "    QKV_BIAS: true\n",
      "    QK_SCALE: null\n",
      "    WINDOW_SIZE: 7\n",
      "  SWINV2:\n",
      "    APE: false\n",
      "    DEPTHS:\n",
      "    - 2\n",
      "    - 2\n",
      "    - 18\n",
      "    - 2\n",
      "    EMBED_DIM: 128\n",
      "    IN_CHANS: 3\n",
      "    MLP_RATIO: 4.0\n",
      "    NUM_HEADS:\n",
      "    - 4\n",
      "    - 8\n",
      "    - 16\n",
      "    - 32\n",
      "    PATCH_NORM: true\n",
      "    PATCH_SIZE: 4\n",
      "    PRETRAINED_WINDOW_SIZES:\n",
      "    - 0\n",
      "    - 0\n",
      "    - 0\n",
      "    - 0\n",
      "    QKV_BIAS: true\n",
      "    WINDOW_SIZE: 16\n",
      "  SWIN_MLP:\n",
      "    APE: false\n",
      "    DEPTHS:\n",
      "    - 2\n",
      "    - 2\n",
      "    - 6\n",
      "    - 2\n",
      "    EMBED_DIM: 96\n",
      "    IN_CHANS: 3\n",
      "    MLP_RATIO: 4.0\n",
      "    NUM_HEADS:\n",
      "    - 3\n",
      "    - 6\n",
      "    - 12\n",
      "    - 24\n",
      "    PATCH_NORM: true\n",
      "    PATCH_SIZE: 4\n",
      "    WINDOW_SIZE: 7\n",
      "  SWIN_MOE:\n",
      "    APE: false\n",
      "    AUX_LOSS_WEIGHT: 0.01\n",
      "    CAPACITY_FACTOR: 1.25\n",
      "    COSINE_ROUTER: false\n",
      "    COSINE_ROUTER_DIM: 256\n",
      "    COSINE_ROUTER_INIT_T: 0.5\n",
      "    DEPTHS:\n",
      "    - 2\n",
      "    - 2\n",
      "    - 6\n",
      "    - 2\n",
      "    EMBED_DIM: 96\n",
      "    GATE_NOISE: 1.0\n",
      "    INIT_STD: 0.02\n",
      "    IN_CHANS: 3\n",
      "    IS_GSHARD_LOSS: false\n",
      "    MLP_FC2_BIAS: true\n",
      "    MLP_RATIO: 4.0\n",
      "    MOE_BLOCKS:\n",
      "    - - -1\n",
      "    - - -1\n",
      "    - - -1\n",
      "    - - -1\n",
      "    MOE_DROP: 0.0\n",
      "    NORMALIZE_GATE: false\n",
      "    NUM_HEADS:\n",
      "    - 3\n",
      "    - 6\n",
      "    - 12\n",
      "    - 24\n",
      "    NUM_LOCAL_EXPERTS: 1\n",
      "    PATCH_NORM: true\n",
      "    PATCH_SIZE: 4\n",
      "    PRETRAINED_WINDOW_SIZES:\n",
      "    - 0\n",
      "    - 0\n",
      "    - 0\n",
      "    - 0\n",
      "    QKV_BIAS: true\n",
      "    QK_SCALE: null\n",
      "    TOP_VALUE: 1\n",
      "    USE_BPR: true\n",
      "    WINDOW_SIZE: 7\n",
      "  TYPE: swinv2\n",
      "OUTPUT: output/swinv2_base_patch4_window16_256/default\n",
      "PRINT_FREQ: 10\n",
      "SAVE_FREQ: 1\n",
      "SEED: 0\n",
      "TAG: default\n",
      "TEST:\n",
      "  CROP: true\n",
      "  SEQUENTIAL: false\n",
      "  SHUFFLE: false\n",
      "THROUGHPUT_MODE: false\n",
      "TRAIN:\n",
      "  ACCUMULATION_STEPS: 2\n",
      "  AUTO_RESUME: true\n",
      "  BASE_LR: 3.125e-05\n",
      "  CLIP_GRAD: 5.0\n",
      "  EPOCHS: 10\n",
      "  LR_SCHEDULER:\n",
      "    DECAY_EPOCHS: 30\n",
      "    DECAY_RATE: 0.1\n",
      "    NAME: cosine\n",
      "  MIN_LR: 3.125e-07\n",
      "  MOE:\n",
      "    SAVE_MASTER: false\n",
      "  OPTIMIZER:\n",
      "    BETAS:\n",
      "    - 0.9\n",
      "    - 0.999\n",
      "    EPS: 1.0e-08\n",
      "    MOMENTUM: 0.9\n",
      "    NAME: adamw\n",
      "  START_EPOCH: 0\n",
      "  USE_CHECKPOINT: false\n",
      "  WARMUP_EPOCHS: 20\n",
      "  WARMUP_LR: 3.125e-08\n",
      "  WEIGHT_DECAY: 0.05\n",
      "\n",
      "\u001B[32m[2022-08-21 11:42:07 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 346)\u001B[0m: INFO {\"cfg\": \"configs/swinv2/swinv2_base_patch4_window16_256.yaml\", \"opts\": null, \"batch_size\": 16, \"data_path\": \"/content/drive/MyDrive/AI-NN/datasets/hym_data/\", \"zip\": false, \"cache_mode\": \"part\", \"pretrained\": null, \"resume\": null, \"accumulation_steps\": 2, \"use_checkpoint\": false, \"disable_amp\": false, \"amp_opt_level\": null, \"output\": \"output\", \"tag\": null, \"eval\": false, \"throughput\": false, \"local_rank\": 0, \"fused_window_process\": false, \"fused_layernorm\": false, \"optim\": null}\n",
      "local rank 0 / global rank 0 successfully build train dataset\n",
      "local rank 0 / global rank 0 successfully build val dataset\n",
      "\u001B[32m[2022-08-21 11:42:07 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 87)\u001B[0m: INFO Creating model:swinv2/swinv2_base_patch4_window16_256\n",
      "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\u001B[32m[2022-08-21 11:42:09 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 89)\u001B[0m: INFO SwinTransformerV2(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (layers): ModuleList(\n",
      "    (0): BasicLayer(\n",
      "      dim=128, input_resolution=(64, 64), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=128, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=128, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=4\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=4, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=128, out_features=384, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=128, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=8, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=128, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=4\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=4, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=128, out_features=384, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.022)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        input_resolution=(64, 64), dim=128\n",
      "        (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicLayer(\n",
      "      dim=256, input_resolution=(32, 32), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=256, input_resolution=(32, 32), num_heads=8, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=256, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=8\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=8, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.043)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=256, input_resolution=(32, 32), num_heads=8, window_size=16, shift_size=8, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=256, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=8\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=8, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.065)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        input_resolution=(32, 32), dim=256\n",
      "        (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (2): BasicLayer(\n",
      "      dim=512, input_resolution=(16, 16), depth=18\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.087)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.109)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.130)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.152)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.174)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.196)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.217)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.239)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.261)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.283)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.304)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.326)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (12): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.348)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (13): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.370)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (14): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.391)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (15): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.413)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (16): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.435)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (17): SwinTransformerBlock(\n",
      "          dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=512, window_size=(16, 16), pretrained_window_size=(0, 0), num_heads=16\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.457)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        input_resolution=(16, 16), dim=512\n",
      "        (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (3): BasicLayer(\n",
      "      dim=1024, input_resolution=(8, 8), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=1024, input_resolution=(8, 8), num_heads=32, window_size=8, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=1024, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=32\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=32, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.478)\n",
      "          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=1024, input_resolution=(8, 8), num_heads=32, window_size=8, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=1024, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=32\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=32, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.500)\n",
      "          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (head): Linear(in_features=1024, out_features=1000, bias=True)\n",
      ")\n",
      "\u001B[32m[2022-08-21 11:42:09 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 92)\u001B[0m: INFO number of params: 87918816\n",
      "\u001B[32m[2022-08-21 11:42:09 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 95)\u001B[0m: INFO number of GFLOPs: 21.795610624\n",
      "All checkpoints founded in output/swinv2_base_patch4_window16_256/default: []\n",
      "\u001B[32m[2022-08-21 11:42:09 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 129)\u001B[0m: INFO no checkpoint found in output/swinv2_base_patch4_window16_256/default, ignoring auto resume\n",
      "\u001B[32m[2022-08-21 11:42:09 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 147)\u001B[0m: INFO Start training\n",
      "\u001B[32m[2022-08-21 11:42:22 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 217)\u001B[0m: INFO Train: [0/10][0/15]\teta 0:03:16 lr 0.000000\t wd 0.0500\ttime 13.0672 (13.0672)\tloss 3.5105 (3.5105)\tgrad_norm 0.0000 (0.0000)\tloss_scale 65536.0000 (65536.0000)\tmem 7591MB\n",
      "\u001B[32m[2022-08-21 11:43:02 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 217)\u001B[0m: INFO Train: [0/10][10/15]\teta 0:00:24 lr 0.000001\t wd 0.0500\ttime 4.3033 (4.8257)\tloss 3.4270 (3.4264)\tgrad_norm 11.0725 (11.0878)\tloss_scale 65536.0000 (65536.0000)\tmem 8617MB\n",
      "\u001B[32m[2022-08-21 11:43:15 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 225)\u001B[0m: INFO EPOCH 0 training takes 0:01:05\n",
      "\u001B[32m[2022-08-21 11:43:15 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(utils.py 141)\u001B[0m: INFO output/swinv2_base_patch4_window16_256/default/ckpt_epoch_0.pth saving......\n",
      "\u001B[32m[2022-08-21 11:43:18 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(utils.py 143)\u001B[0m: INFO output/swinv2_base_patch4_window16_256/default/ckpt_epoch_0.pth saved !!!\n",
      "\u001B[32m[2022-08-21 11:43:19 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 266)\u001B[0m: INFO Test: [0/10]\tTime 0.563 (0.563)\tLoss 6.8398 (6.8398)\tAcc@1 0.000 (0.000)\tAcc@5 0.000 (0.000)\tMem 8617MB\n",
      "\u001B[32m[2022-08-21 11:43:21 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 272)\u001B[0m: INFO  * Acc@1 0.000 Acc@5 0.000\n",
      "\u001B[32m[2022-08-21 11:43:21 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 159)\u001B[0m: INFO Accuracy of the network on the 153 test images: 0.0%\n",
      "\u001B[32m[2022-08-21 11:43:21 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 161)\u001B[0m: INFO Max accuracy: 0.00%\n",
      "\u001B[32m[2022-08-21 11:43:22 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 217)\u001B[0m: INFO Train: [1/10][0/15]\teta 0:00:16 lr 0.000001\t wd 0.0500\ttime 1.1124 (1.1124)\tloss 3.4473 (3.4473)\tgrad_norm 0.0000 (0.0000)\tloss_scale 65536.0000 (65536.0000)\tmem 8617MB\n",
      "\u001B[32m[2022-08-21 11:43:29 swinv2_base_patch4_window16_256]\u001B[0m\u001B[33m(main.py 217)\u001B[0m: INFO Train: [1/10][10/15]\teta 0:00:03 lr 0.000003\t wd 0.0500\ttime 0.6574 (0.7298)\tloss 3.3595 (3.4113)\tgrad_norm 11.9185 (11.4695)\tloss_scale 65536.0000 (65536.0000)\tmem 8619MB\n",
      "WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers\n",
      "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1303 closing signal SIGINT\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 348, in <module>\n",
      "    main(config)\n",
      "  File \"main.py\", line 153, in main\n",
      "    loss_scaler)\n",
      "  File \"main.py\", line 200, in train_one_epoch\n",
      "    loss_scale_value = loss_scaler.state_dict()[\"scale\"]\n",
      "  File \"/content/drive/MyDrive/lecture/Swin-Transformer/utils.py\", line 218, in state_dict\n",
      "    return self._scaler.state_dict()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\", line 489, in state_dict\n",
      "    \"_growth_tracker\": self._get_growth_tracker()} if self._enabled else {}\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\", line 414, in get_scale\n",
      "    return self._init_scale if self._scale is None else self._get_scale_async().item()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 193, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 189, in main\n",
      "    launch(args)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 174, in launch\n",
      "    run(args)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/run.py\", line 755, in run\n",
      "    )(*cmd_args)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launcher/api.py\", line 236, in launch_agent\n",
      "    result = agent.run()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/metrics/api.py\", line 125, in wrapper\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 709, in run\n",
      "    result = self._invoke_run(role)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 850, in _invoke_run\n",
      "    time.sleep(monitor_interval)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 60, in _terminate_process_handler\n",
      "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
      "torch.distributed.elastic.multiprocessing.api.SignalException: Process 1291 got signal: 2\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from models.swin_transformer_v2 import SwinTransformerV2\n",
    "\n",
    "model = SwinTransformerV2()\n",
    "print(model)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nGbumVorNZoS",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661082335354,
     "user_tz": -540,
     "elapsed": 571,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "outputId": "a62c1ae8-66dc-47c8-8f6e-a2ca8618e5a2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 39,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SwinTransformerV2(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (layers): ModuleList(\n",
      "    (0): BasicLayer(\n",
      "      dim=96, input_resolution=(56, 56), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=96, input_resolution=(56, 56), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=96, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=3\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=3, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=96, input_resolution=(56, 56), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=96, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=3\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=3, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.009)\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        input_resolution=(56, 56), dim=96\n",
      "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
      "        (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicLayer(\n",
      "      dim=192, input_resolution=(28, 28), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=192, input_resolution=(28, 28), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=192, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=6\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=6, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.018)\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=192, input_resolution=(28, 28), num_heads=6, window_size=7, shift_size=3, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=192, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=6\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=6, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.027)\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        input_resolution=(28, 28), dim=192\n",
      "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (2): BasicLayer(\n",
      "      dim=384, input_resolution=(14, 14), depth=6\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=12\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.036)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=12\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.045)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=12\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.055)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=12\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.064)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=12\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.073)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=12\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.082)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        input_resolution=(14, 14), dim=384\n",
      "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (3): BasicLayer(\n",
      "      dim=768, input_resolution=(7, 7), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=768, input_resolution=(7, 7), num_heads=24, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=768, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=24\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=24, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.091)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=768, input_resolution=(7, 7), num_heads=24, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=768, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=24\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=24, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.100)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "학습"
   ],
   "metadata": {
    "id": "0Uh9kQ4bOWHh",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "pretrained_model = train(model, loss_func, optimizer, epochs=5)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "psSl4mB0NhfI",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661082805274,
     "user_tz": -540,
     "elapsed": 30331,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "outputId": "a67e9801-ef26-40ee-a0a5-20ae6d2175d2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 48,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch number 0/4\n",
      "====================\n",
      "train loss in this epoch: 2.506535517387703, accuracy in this epoch: 0.5204918032786886\n",
      "val loss in this epoch: 0.7856296409968457, accuracy in this epoch: 0.5032679738562091\n",
      "Epoch number 1/4\n",
      "====================\n",
      "train loss in this epoch: 0.7023707149458713, accuracy in this epoch: 0.5655737704918034\n",
      "val loss in this epoch: 0.6994537937095742, accuracy in this epoch: 0.49673202614379086\n",
      "Epoch number 2/4\n",
      "====================\n",
      "train loss in this epoch: 0.7139894317408078, accuracy in this epoch: 0.5614754098360656\n",
      "val loss in this epoch: 0.7107308553714379, accuracy in this epoch: 0.5294117647058824\n",
      "Epoch number 3/4\n",
      "====================\n",
      "train loss in this epoch: 0.6849609085770904, accuracy in this epoch: 0.6147540983606558\n",
      "val loss in this epoch: 0.7299181164479723, accuracy in this epoch: 0.5294117647058824\n",
      "Epoch number 4/4\n",
      "====================\n",
      "train loss in this epoch: 0.7111871350006979, accuracy in this epoch: 0.6024590163934427\n",
      "val loss in this epoch: 0.7213719325517517, accuracy in this epoch: 0.5490196078431373\n",
      "Training finished in 0.0mins 29.875112771987915secs\n",
      "Best validation set accuracy: 0.5490196078431373\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "test 실행"
   ],
   "metadata": {
    "id": "RSvwGm71QAk3",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "test(pretrained_model)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zMtq8e9UP_sp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661082835253,
     "user_tz": -540,
     "elapsed": 1417,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "outputId": "d3e78c3d-4cb7-42ab-af10-37e81f40677d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 49,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy for class: ants  is 75.7 %\n",
      "Accuracy for class: bees  is 37.3 %\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "visualize_predictions(pretrained_model)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "n-65LvCJQK7Y",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661082864040,
     "user_tz": -540,
     "elapsed": 1859,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "outputId": "8158e9ed-5921-4475-ce01-a1066ab92dc0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 50,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "train function"
   ],
   "metadata": {
    "id": "UDcA-MVeO-GV",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "import torch\n",
    "dvc = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train(model, loss_func, optimizer, epochs=10):\n",
    "   start = time.time()\n",
    "\n",
    "   model = model.to(dvc)\n",
    "\n",
    "   accuracy = 0.0\n",
    "\n",
    "   for e in range(epochs):\n",
    "        print(f'Epoch number {e}/{epochs - 1}')\n",
    "        print('=' * 20)\n",
    "\n",
    "        for dset in ['train', 'val']:\n",
    "            if dset == 'train':\n",
    "                model.train()  \n",
    "            else:\n",
    "                model.eval() \n",
    "\n",
    "            loss = 0.0\n",
    "            successes = 0\n",
    "\n",
    "            for imgs, tgts in dloaders[dset]:\n",
    "                imgs = imgs.to(dvc)\n",
    "                tgts = tgts.to(dvc)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(dset == 'train'):\n",
    "                    ops = model(imgs)\n",
    "                    #print(\"##\",ops)\n",
    "                    _, preds = torch.max(ops, 1)\n",
    "                    loss_curr = loss_func(ops, tgts)\n",
    "                    \n",
    "                    if dset == 'train':\n",
    "                        loss_curr.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                loss += loss_curr.item() * imgs.size(0)\n",
    "                successes += torch.sum(preds == tgts.data)\n",
    "          \n",
    "            loss_epoch = loss / dset_sizes[dset]\n",
    "            accuracy_epoch = successes.double() / dset_sizes[dset]\n",
    "\n",
    "            print(f'{dset} loss in this epoch: {loss_epoch}, accuracy in this epoch: {accuracy_epoch}')\n",
    "            if dset == 'val' and accuracy_epoch > accuracy:\n",
    "                accuracy = accuracy_epoch      \n",
    "\n",
    "   time_delta = time.time() - start\n",
    "   print(f'Training finished in {time_delta // 60}mins {time_delta % 60}secs')\n",
    "   print(f'Best validation set accuracy: {accuracy}')\n",
    "\n",
    "\n",
    "   return model"
   ],
   "metadata": {
    "id": "DLFLIO1YO2oR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661082657011,
     "user_tz": -540,
     "elapsed": 415,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "test function"
   ],
   "metadata": {
    "id": "2BWejkiRPBuT",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def test(model):\n",
    "  model = model.to(dvc)\n",
    "\n",
    "  correct_pred = {classname: 0 for classname in classes}\n",
    "  total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "\n",
    "  with torch.no_grad():\n",
    "      for images, labels in dloaders['val']:\n",
    "\n",
    "\n",
    "          images = images.to(dvc)\n",
    "          labels = labels.to(dvc)\n",
    "        \n",
    "          outputs = model(images)\n",
    "          _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "          for label, prediction in zip(labels, predictions):\n",
    "              if label == prediction:\n",
    "                  correct_pred[classes[label]] += 1\n",
    "              total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "\n",
    "  for classname, correct_count in correct_pred.items():\n",
    "      accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "      print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ],
   "metadata": {
    "id": "moE66B_0PBMg",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661082557150,
     "user_tz": -540,
     "elapsed": 453,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def visualize_predictions(pretrained_model, max_num_imgs=4):\n",
    "    torch.manual_seed(1)\n",
    "    was_model_training = pretrained_model.training\n",
    "    pretrained_model.eval()\n",
    "    imgs_counter = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (imgs, tgts) in enumerate(dloaders['val']):\n",
    "            imgs = imgs.to(dvc)\n",
    "            tgts = tgts.to(dvc)\n",
    "            ops = pretrained_model(imgs)\n",
    "            _, preds = torch.max(ops, 1)\n",
    "            \n",
    "            for j in range(imgs.size()[0]):\n",
    "                imgs_counter += 1\n",
    "                ax = plt.subplot(max_num_imgs//2, 2, imgs_counter)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'pred: {classes[preds[j]]} || target: {classes[tgts[j]]}')\n",
    "                imageshow(imgs.cpu().data[j])\n",
    "\n",
    "                if imgs_counter == max_num_imgs:\n",
    "                    pretrained_model.train(mode=was_model_training)\n",
    "                    return\n",
    "        pretrained_model.train(mode=was_model_training)"
   ],
   "metadata": {
    "id": "cWK4qBtVPFDJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661082581978,
     "user_tz": -540,
     "elapsed": 445,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def imageshow(img, text=None):\n",
    "  img = img.numpy().transpose((1,2,0))\n",
    "  avg = np.array([0.490, 0.449, 0.411])\n",
    "  stddev = np.array([0.231, 0.221, 0.230])\n",
    "  img = stddev * img + avg\n",
    "  img = np.clip(img, 0, 1)\n",
    "  plt.imshow(img)\n",
    "  if text is not None:\n",
    "    plt.title(text)"
   ],
   "metadata": {
    "id": "ctrF9hEOPHGY",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661082583429,
     "user_tz": -540,
     "elapsed": 1,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "DateSet"
   ],
   "metadata": {
    "id": "RzCrnL2cPXVK",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from torchvision import datasets, models, transforms"
   ],
   "metadata": {
    "id": "oH-eoSnoPLzw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661082639375,
     "user_tz": -540,
     "elapsed": 432,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ddir = '/content/drive/MyDrive/AI-NN/datasets/hym_data'\n",
    "\n",
    "batch_size = 8\n",
    "num_workers = 4\n",
    "\n",
    "data_transformers = {\n",
    "    'train': transforms.Compose(\n",
    "        [\n",
    "         transforms.RandomResizedCrop(224), \n",
    "         transforms.RandomHorizontalFlip(),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize([0.490, 0.449, 0.411], [0.231, 0.221, 0.230])\n",
    "        ]\n",
    "    ),\n",
    "    'val': transforms.Compose(\n",
    "        [\n",
    "         transforms.Resize(256),\n",
    "         transforms.CenterCrop(224),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize([0.490, 0.449, 0.411],[0.231, 0.221, 0.230])\n",
    "        ]\n",
    "    )\n",
    "}\n",
    "\n",
    "img_data = {\n",
    "    k: datasets.ImageFolder(os.path.join(ddir, k), data_transformers[k])\n",
    "    for k in ['train', 'val']\n",
    "}\n",
    "dloaders = {\n",
    "    k: torch.utils.data.DataLoader(\n",
    "        img_data[k], batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
    "    )\n",
    "    for k in ['train', 'val']\n",
    "}\n",
    "dset_sizes = {x: len(img_data[x]) for x in ['train', 'val']}\n",
    "classes = img_data['train'].classes\n",
    "\n",
    "dvc = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ],
   "metadata": {
    "id": "KCTg7Q9DPZaG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661082647839,
     "user_tz": -540,
     "elapsed": 449,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "코드 추출"
   ],
   "metadata": {
    "id": "Btz4RnRqQToU",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# --------------------------------------------------------\n",
    "# Swin Transformer V2\n",
    "# Copyright (c) 2022 Microsoft\n",
    "# Licensed under The MIT License [see LICENSE for details]\n",
    "# Written by Ze Liu\n",
    "# --------------------------------------------------------\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def window_partition(x, window_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: (B, H, W, C)\n",
    "        window_size (int): window size\n",
    "\n",
    "    Returns:\n",
    "        windows: (num_windows*B, window_size, window_size, C)\n",
    "    \"\"\"\n",
    "    B, H, W, C = x.shape\n",
    "    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n",
    "    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n",
    "    return windows\n",
    "\n",
    "\n",
    "def window_reverse(windows, window_size, H, W):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        windows: (num_windows*B, window_size, window_size, C)\n",
    "        window_size (int): Window size\n",
    "        H (int): Height of image\n",
    "        W (int): Width of image\n",
    "\n",
    "    Returns:\n",
    "        x: (B, H, W, C)\n",
    "    \"\"\"\n",
    "    B = int(windows.shape[0] / (H * W / window_size / window_size))\n",
    "    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1)\n",
    "    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)\n",
    "    return x\n",
    "\n",
    "\n",
    "class WindowAttention(nn.Module):\n",
    "    r\"\"\" Window based multi-head self attention (W-MSA) module with relative position bias.\n",
    "    It supports both of shifted and non-shifted window.\n",
    "\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        window_size (tuple[int]): The height and width of the window.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True\n",
    "        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0\n",
    "        proj_drop (float, optional): Dropout ratio of output. Default: 0.0\n",
    "        pretrained_window_size (tuple[int]): The height and width of the window in pre-training.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, attn_drop=0., proj_drop=0.,\n",
    "                 pretrained_window_size=[0, 0]):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size  # Wh, Ww\n",
    "        self.pretrained_window_size = pretrained_window_size\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.logit_scale = nn.Parameter(torch.log(10 * torch.ones((num_heads, 1, 1))), requires_grad=True)\n",
    "\n",
    "        # mlp to generate continuous relative position bias\n",
    "        self.cpb_mlp = nn.Sequential(nn.Linear(2, 512, bias=True),\n",
    "                                     nn.ReLU(inplace=True),\n",
    "                                     nn.Linear(512, num_heads, bias=False))\n",
    "\n",
    "        # get relative_coords_table\n",
    "        relative_coords_h = torch.arange(-(self.window_size[0] - 1), self.window_size[0], dtype=torch.float32)\n",
    "        relative_coords_w = torch.arange(-(self.window_size[1] - 1), self.window_size[1], dtype=torch.float32)\n",
    "        relative_coords_table = torch.stack(\n",
    "            torch.meshgrid([relative_coords_h,\n",
    "                            relative_coords_w])).permute(1, 2, 0).contiguous().unsqueeze(0)  # 1, 2*Wh-1, 2*Ww-1, 2\n",
    "        if pretrained_window_size[0] > 0:\n",
    "            relative_coords_table[:, :, :, 0] /= (pretrained_window_size[0] - 1)\n",
    "            relative_coords_table[:, :, :, 1] /= (pretrained_window_size[1] - 1)\n",
    "        else:\n",
    "            relative_coords_table[:, :, :, 0] /= (self.window_size[0] - 1)\n",
    "            relative_coords_table[:, :, :, 1] /= (self.window_size[1] - 1)\n",
    "        relative_coords_table *= 8  # normalize to -8, 8\n",
    "        relative_coords_table = torch.sign(relative_coords_table) * torch.log2(\n",
    "            torch.abs(relative_coords_table) + 1.0) / np.log2(8)\n",
    "\n",
    "        self.register_buffer(\"relative_coords_table\", relative_coords_table)\n",
    "\n",
    "        # get pair-wise relative position index for each token inside the window\n",
    "        coords_h = torch.arange(self.window_size[0])\n",
    "        coords_w = torch.arange(self.window_size[1])\n",
    "        coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  # 2, Wh, Ww\n",
    "        coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 2, Wh*Ww, Wh*Ww\n",
    "        relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww, Wh*Ww, 2\n",
    "        relative_coords[:, :, 0] += self.window_size[0] - 1  # shift to start from 0\n",
    "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
    "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
    "        relative_position_index = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n",
    "        self.register_buffer(\"relative_position_index\", relative_position_index)\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=False)\n",
    "        if qkv_bias:\n",
    "            self.q_bias = nn.Parameter(torch.zeros(dim))\n",
    "            self.v_bias = nn.Parameter(torch.zeros(dim))\n",
    "        else:\n",
    "            self.q_bias = None\n",
    "            self.v_bias = None\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: input features with shape of (num_windows*B, N, C)\n",
    "            mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None\n",
    "        \"\"\"\n",
    "        B_, N, C = x.shape\n",
    "        qkv_bias = None\n",
    "        if self.q_bias is not None:\n",
    "            qkv_bias = torch.cat((self.q_bias, torch.zeros_like(self.v_bias, requires_grad=False), self.v_bias))\n",
    "        qkv = F.linear(input=x, weight=self.qkv.weight, bias=qkv_bias)\n",
    "        qkv = qkv.reshape(B_, N, 3, self.num_heads, -1).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]  # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        # cosine attention\n",
    "        attn = (F.normalize(q, dim=-1) @ F.normalize(k, dim=-1).transpose(-2, -1))\n",
    "        logit_scale = torch.clamp(self.logit_scale, max=torch.log(torch.tensor(1. / 0.01).cuda())).exp()\n",
    "        attn = attn * logit_scale\n",
    "\n",
    "        relative_position_bias_table = self.cpb_mlp(self.relative_coords_table).view(-1, self.num_heads)\n",
    "        relative_position_bias = relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
    "            self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1], -1)  # Wh*Ww,Wh*Ww,nH\n",
    "        relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n",
    "        relative_position_bias = 16 * torch.sigmoid(relative_position_bias)\n",
    "        attn = attn + relative_position_bias.unsqueeze(0)\n",
    "\n",
    "        if mask is not None:\n",
    "            nW = mask.shape[0]\n",
    "            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0)\n",
    "            attn = attn.view(-1, self.num_heads, N, N)\n",
    "            attn = self.softmax(attn)\n",
    "        else:\n",
    "            attn = self.softmax(attn)\n",
    "\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f'dim={self.dim}, window_size={self.window_size}, ' \\\n",
    "               f'pretrained_window_size={self.pretrained_window_size}, num_heads={self.num_heads}'\n",
    "\n",
    "    def flops(self, N):\n",
    "        # calculate flops for 1 window with token length of N\n",
    "        flops = 0\n",
    "        # qkv = self.qkv(x)\n",
    "        flops += N * self.dim * 3 * self.dim\n",
    "        # attn = (q @ k.transpose(-2, -1))\n",
    "        flops += self.num_heads * N * (self.dim // self.num_heads) * N\n",
    "        #  x = (attn @ v)\n",
    "        flops += self.num_heads * N * N * (self.dim // self.num_heads)\n",
    "        # x = self.proj(x)\n",
    "        flops += N * self.dim * self.dim\n",
    "        return flops\n",
    "\n",
    "\n",
    "class SwinTransformerBlock(nn.Module):\n",
    "    r\"\"\" Swin Transformer Block.\n",
    "\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        input_resolution (tuple[int]): Input resulotion.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        window_size (int): Window size.\n",
    "        shift_size (int): Shift size for SW-MSA.\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
    "        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True\n",
    "        drop (float, optional): Dropout rate. Default: 0.0\n",
    "        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n",
    "        drop_path (float, optional): Stochastic depth rate. Default: 0.0\n",
    "        act_layer (nn.Module, optional): Activation layer. Default: nn.GELU\n",
    "        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n",
    "        pretrained_window_size (int): Window size in pre-training.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, input_resolution, num_heads, window_size=7, shift_size=0,\n",
    "                 mlp_ratio=4., qkv_bias=True, drop=0., attn_drop=0., drop_path=0.,\n",
    "                 act_layer=nn.GELU, norm_layer=nn.LayerNorm, pretrained_window_size=0):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "        self.shift_size = shift_size\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        if min(self.input_resolution) <= self.window_size:\n",
    "            # if window size is larger than input resolution, we don't partition windows\n",
    "            self.shift_size = 0\n",
    "            self.window_size = min(self.input_resolution)\n",
    "        assert 0 <= self.shift_size < self.window_size, \"shift_size must in 0-window_size\"\n",
    "\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = WindowAttention(\n",
    "            dim, window_size=to_2tuple(self.window_size), num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias, attn_drop=attn_drop, proj_drop=drop,\n",
    "            pretrained_window_size=to_2tuple(pretrained_window_size))\n",
    "\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "        if self.shift_size > 0:\n",
    "            # calculate attention mask for SW-MSA\n",
    "            H, W = self.input_resolution\n",
    "            img_mask = torch.zeros((1, H, W, 1))  # 1 H W 1\n",
    "            h_slices = (slice(0, -self.window_size),\n",
    "                        slice(-self.window_size, -self.shift_size),\n",
    "                        slice(-self.shift_size, None))\n",
    "            w_slices = (slice(0, -self.window_size),\n",
    "                        slice(-self.window_size, -self.shift_size),\n",
    "                        slice(-self.shift_size, None))\n",
    "            cnt = 0\n",
    "            for h in h_slices:\n",
    "                for w in w_slices:\n",
    "                    img_mask[:, h, w, :] = cnt\n",
    "                    cnt += 1\n",
    "\n",
    "            mask_windows = window_partition(img_mask, self.window_size)  # nW, window_size, window_size, 1\n",
    "            mask_windows = mask_windows.view(-1, self.window_size * self.window_size)\n",
    "            attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n",
    "            attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n",
    "        else:\n",
    "            attn_mask = None\n",
    "\n",
    "        self.register_buffer(\"attn_mask\", attn_mask)\n",
    "\n",
    "    def forward(self, x):\n",
    "        H, W = self.input_resolution\n",
    "        B, L, C = x.shape\n",
    "        assert L == H * W, \"input feature has wrong size\"\n",
    "\n",
    "        shortcut = x\n",
    "        x = x.view(B, H, W, C)\n",
    "\n",
    "        # cyclic shift\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))\n",
    "        else:\n",
    "            shifted_x = x\n",
    "\n",
    "        # partition windows\n",
    "        x_windows = window_partition(shifted_x, self.window_size)  # nW*B, window_size, window_size, C\n",
    "        x_windows = x_windows.view(-1, self.window_size * self.window_size, C)  # nW*B, window_size*window_size, C\n",
    "\n",
    "        # W-MSA/SW-MSA\n",
    "        attn_windows = self.attn(x_windows, mask=self.attn_mask)  # nW*B, window_size*window_size, C\n",
    "\n",
    "        # merge windows\n",
    "        attn_windows = attn_windows.view(-1, self.window_size, self.window_size, C)\n",
    "        shifted_x = window_reverse(attn_windows, self.window_size, H, W)  # B H' W' C\n",
    "\n",
    "        # reverse cyclic shift\n",
    "        if self.shift_size > 0:\n",
    "            x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(1, 2))\n",
    "        else:\n",
    "            x = shifted_x\n",
    "        x = x.view(B, H * W, C)\n",
    "        x = shortcut + self.drop_path(self.norm1(x))\n",
    "\n",
    "        # FFN\n",
    "        x = x + self.drop_path(self.norm2(self.mlp(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, \" \\\n",
    "               f\"window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}\"\n",
    "\n",
    "    def flops(self):\n",
    "        flops = 0\n",
    "        H, W = self.input_resolution\n",
    "        # norm1\n",
    "        flops += self.dim * H * W\n",
    "        # W-MSA/SW-MSA\n",
    "        nW = H * W / self.window_size / self.window_size\n",
    "        flops += nW * self.attn.flops(self.window_size * self.window_size)\n",
    "        # mlp\n",
    "        flops += 2 * H * W * self.dim * self.dim * self.mlp_ratio\n",
    "        # norm2\n",
    "        flops += self.dim * H * W\n",
    "        return flops\n",
    "\n",
    "\n",
    "class PatchMerging(nn.Module):\n",
    "    r\"\"\" Patch Merging Layer.\n",
    "\n",
    "    Args:\n",
    "        input_resolution (tuple[int]): Resolution of input feature.\n",
    "        dim (int): Number of input channels.\n",
    "        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_resolution, dim, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.input_resolution = input_resolution\n",
    "        self.dim = dim\n",
    "        self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)\n",
    "        self.norm = norm_layer(2 * dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: B, H*W, C\n",
    "        \"\"\"\n",
    "        H, W = self.input_resolution\n",
    "        B, L, C = x.shape\n",
    "        assert L == H * W, \"input feature has wrong size\"\n",
    "        assert H % 2 == 0 and W % 2 == 0, f\"x size ({H}*{W}) are not even.\"\n",
    "\n",
    "        x = x.view(B, H, W, C)\n",
    "\n",
    "        x0 = x[:, 0::2, 0::2, :]  # B H/2 W/2 C\n",
    "        x1 = x[:, 1::2, 0::2, :]  # B H/2 W/2 C\n",
    "        x2 = x[:, 0::2, 1::2, :]  # B H/2 W/2 C\n",
    "        x3 = x[:, 1::2, 1::2, :]  # B H/2 W/2 C\n",
    "        x = torch.cat([x0, x1, x2, x3], -1)  # B H/2 W/2 4*C\n",
    "        x = x.view(B, -1, 4 * C)  # B H/2*W/2 4*C\n",
    "\n",
    "        x = self.reduction(x)\n",
    "        x = self.norm(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"input_resolution={self.input_resolution}, dim={self.dim}\"\n",
    "\n",
    "    def flops(self):\n",
    "        H, W = self.input_resolution\n",
    "        flops = (H // 2) * (W // 2) * 4 * self.dim * 2 * self.dim\n",
    "        flops += H * W * self.dim // 2\n",
    "        return flops\n",
    "\n",
    "\n",
    "class BasicLayer(nn.Module):\n",
    "    \"\"\" A basic Swin Transformer layer for one stage.\n",
    "\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        input_resolution (tuple[int]): Input resolution.\n",
    "        depth (int): Number of blocks.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        window_size (int): Local window size.\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
    "        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True\n",
    "        drop (float, optional): Dropout rate. Default: 0.0\n",
    "        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n",
    "        drop_path (float | tuple[float], optional): Stochastic depth rate. Default: 0.0\n",
    "        norm_layer (nn.Module, optional): Normalization layer. Default: nn.LayerNorm\n",
    "        downsample (nn.Module | None, optional): Downsample layer at the end of the layer. Default: None\n",
    "        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False.\n",
    "        pretrained_window_size (int): Local window size in pre-training.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, input_resolution, depth, num_heads, window_size,\n",
    "                 mlp_ratio=4., qkv_bias=True, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., norm_layer=nn.LayerNorm, downsample=None, use_checkpoint=False,\n",
    "                 pretrained_window_size=0):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.depth = depth\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "\n",
    "        # build blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            SwinTransformerBlock(dim=dim, input_resolution=input_resolution,\n",
    "                                 num_heads=num_heads, window_size=window_size,\n",
    "                                 shift_size=0 if (i % 2 == 0) else window_size // 2,\n",
    "                                 mlp_ratio=mlp_ratio,\n",
    "                                 qkv_bias=qkv_bias,\n",
    "                                 drop=drop, attn_drop=attn_drop,\n",
    "                                 drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path,\n",
    "                                 norm_layer=norm_layer,\n",
    "                                 pretrained_window_size=pretrained_window_size)\n",
    "            for i in range(depth)])\n",
    "\n",
    "        # patch merging layer\n",
    "        if downsample is not None:\n",
    "            self.downsample = downsample(input_resolution, dim=dim, norm_layer=norm_layer)\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        for blk in self.blocks:\n",
    "            if self.use_checkpoint:\n",
    "                x = checkpoint.checkpoint(blk, x)\n",
    "            else:\n",
    "                x = blk(x)\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, depth={self.depth}\"\n",
    "\n",
    "    def flops(self):\n",
    "        flops = 0\n",
    "        for blk in self.blocks:\n",
    "            flops += blk.flops()\n",
    "        if self.downsample is not None:\n",
    "            flops += self.downsample.flops()\n",
    "        return flops\n",
    "\n",
    "    def _init_respostnorm(self):\n",
    "        for blk in self.blocks:\n",
    "            nn.init.constant_(blk.norm1.bias, 0)\n",
    "            nn.init.constant_(blk.norm1.weight, 0)\n",
    "            nn.init.constant_(blk.norm2.bias, 0)\n",
    "            nn.init.constant_(blk.norm2.weight, 0)\n",
    "\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    r\"\"\" Image to Patch Embedding\n",
    "\n",
    "    Args:\n",
    "        img_size (int): Image size.  Default: 224.\n",
    "        patch_size (int): Patch token size. Default: 4.\n",
    "        in_chans (int): Number of input image channels. Default: 3.\n",
    "        embed_dim (int): Number of linear projection output channels. Default: 96.\n",
    "        norm_layer (nn.Module, optional): Normalization layer. Default: None\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_size=224, patch_size=4, in_chans=3, embed_dim=96, norm_layer=None):\n",
    "        super().__init__()\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        patches_resolution = [img_size[0] // patch_size[0], img_size[1] // patch_size[1]]\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.patches_resolution = patches_resolution\n",
    "        self.num_patches = patches_resolution[0] * patches_resolution[1]\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        if norm_layer is not None:\n",
    "            self.norm = norm_layer(embed_dim)\n",
    "        else:\n",
    "            self.norm = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        # FIXME look at relaxing size constraints\n",
    "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
    "            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)  # B Ph*Pw C\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "    def flops(self):\n",
    "        Ho, Wo = self.patches_resolution\n",
    "        flops = Ho * Wo * self.embed_dim * self.in_chans * (self.patch_size[0] * self.patch_size[1])\n",
    "        if self.norm is not None:\n",
    "            flops += Ho * Wo * self.embed_dim\n",
    "        return flops\n",
    "\n",
    "\n",
    "class SwinTransformerV2(nn.Module):\n",
    "    r\"\"\" Swin Transformer\n",
    "        A PyTorch impl of : `Swin Transformer: Hierarchical Vision Transformer using Shifted Windows`  -\n",
    "          https://arxiv.org/pdf/2103.14030\n",
    "\n",
    "    Args:\n",
    "        img_size (int | tuple(int)): Input image size. Default 224\n",
    "        patch_size (int | tuple(int)): Patch size. Default: 4\n",
    "        in_chans (int): Number of input image channels. Default: 3\n",
    "        num_classes (int): Number of classes for classification head. Default: 1000\n",
    "        embed_dim (int): Patch embedding dimension. Default: 96\n",
    "        depths (tuple(int)): Depth of each Swin Transformer layer.\n",
    "        num_heads (tuple(int)): Number of attention heads in different layers.\n",
    "        window_size (int): Window size. Default: 7\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4\n",
    "        qkv_bias (bool): If True, add a learnable bias to query, key, value. Default: True\n",
    "        drop_rate (float): Dropout rate. Default: 0\n",
    "        attn_drop_rate (float): Attention dropout rate. Default: 0\n",
    "        drop_path_rate (float): Stochastic depth rate. Default: 0.1\n",
    "        norm_layer (nn.Module): Normalization layer. Default: nn.LayerNorm.\n",
    "        ape (bool): If True, add absolute position embedding to the patch embedding. Default: False\n",
    "        patch_norm (bool): If True, add normalization after patch embedding. Default: True\n",
    "        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False\n",
    "        pretrained_window_sizes (tuple(int)): Pretrained window sizes of each layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_size=224, patch_size=4, in_chans=3, num_classes=1000,\n",
    "                 embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24],\n",
    "                 window_size=7, mlp_ratio=4., qkv_bias=True,\n",
    "                 drop_rate=0., attn_drop_rate=0., drop_path_rate=0.1,\n",
    "                 norm_layer=nn.LayerNorm, ape=False, patch_norm=True,\n",
    "                 use_checkpoint=False, pretrained_window_sizes=[0, 0, 0, 0], **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = len(depths)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.ape = ape\n",
    "        self.patch_norm = patch_norm\n",
    "        self.num_features = int(embed_dim * 2 ** (self.num_layers - 1))\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "\n",
    "        # split image into non-overlapping patches\n",
    "        self.patch_embed = PatchEmbed(\n",
    "            img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim,\n",
    "            norm_layer=norm_layer if self.patch_norm else None)\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "        patches_resolution = self.patch_embed.patches_resolution\n",
    "        self.patches_resolution = patches_resolution\n",
    "\n",
    "        # absolute position embedding\n",
    "        if self.ape:\n",
    "            self.absolute_pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n",
    "            trunc_normal_(self.absolute_pos_embed, std=.02)\n",
    "\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        # stochastic depth\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]  # stochastic depth decay rule\n",
    "\n",
    "        # build layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i_layer in range(self.num_layers):\n",
    "            layer = BasicLayer(dim=int(embed_dim * 2 ** i_layer),\n",
    "                               input_resolution=(patches_resolution[0] // (2 ** i_layer),\n",
    "                                                 patches_resolution[1] // (2 ** i_layer)),\n",
    "                               depth=depths[i_layer],\n",
    "                               num_heads=num_heads[i_layer],\n",
    "                               window_size=window_size,\n",
    "                               mlp_ratio=self.mlp_ratio,\n",
    "                               qkv_bias=qkv_bias,\n",
    "                               drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                               drop_path=dpr[sum(depths[:i_layer]):sum(depths[:i_layer + 1])],\n",
    "                               norm_layer=norm_layer,\n",
    "                               downsample=PatchMerging if (i_layer < self.num_layers - 1) else None,\n",
    "                               use_checkpoint=use_checkpoint,\n",
    "                               pretrained_window_size=pretrained_window_sizes[i_layer])\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        self.norm = norm_layer(self.num_features)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.head = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        for bly in self.layers:\n",
    "            bly._init_respostnorm()\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {'absolute_pos_embed'}\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay_keywords(self):\n",
    "        return {\"cpb_mlp\", \"logit_scale\", 'relative_position_bias_table'}\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        if self.ape:\n",
    "            x = x + self.absolute_pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = self.norm(x)  # B L C\n",
    "        x = self.avgpool(x.transpose(1, 2))  # B C 1\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "    def flops(self):\n",
    "        flops = 0\n",
    "        flops += self.patch_embed.flops()\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            flops += layer.flops()\n",
    "        flops += self.num_features * self.patches_resolution[0] * self.patches_resolution[1] // (2 ** self.num_layers)\n",
    "        flops += self.num_features * self.num_classes\n",
    "        return flops\n"
   ],
   "metadata": {
    "id": "SBNxjQNKPbdp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661082908119,
     "user_tz": -540,
     "elapsed": 463,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instance 생성"
   ],
   "metadata": {
    "id": "qCusXSXUQhOk",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = SwinTransformerV2()\n",
    "print(model)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ny154URhQcmI",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661082949230,
     "user_tz": -540,
     "elapsed": 902,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "outputId": "f076b65a-af89-4250-9d2b-6fba1131e519",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 52,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SwinTransformerV2(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (layers): ModuleList(\n",
      "    (0): BasicLayer(\n",
      "      dim=96, input_resolution=(56, 56), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=96, input_resolution=(56, 56), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=96, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=3\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=3, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=96, input_resolution=(56, 56), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=96, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=3\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=3, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.009)\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        input_resolution=(56, 56), dim=96\n",
      "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
      "        (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicLayer(\n",
      "      dim=192, input_resolution=(28, 28), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=192, input_resolution=(28, 28), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=192, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=6\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=6, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.018)\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=192, input_resolution=(28, 28), num_heads=6, window_size=7, shift_size=3, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=192, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=6\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=6, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.027)\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        input_resolution=(28, 28), dim=192\n",
      "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (2): BasicLayer(\n",
      "      dim=384, input_resolution=(14, 14), depth=6\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=12\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.036)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=12\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.045)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=12\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.055)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=12\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.064)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=12\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.073)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=12\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.082)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        input_resolution=(14, 14), dim=384\n",
      "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (3): BasicLayer(\n",
      "      dim=768, input_resolution=(7, 7), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=768, input_resolution=(7, 7), num_heads=24, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=768, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=24\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=24, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.091)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=768, input_resolution=(7, 7), num_heads=24, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=768, window_size=(7, 7), pretrained_window_size=(0, 0), num_heads=24\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=512, out_features=24, bias=False)\n",
      "            )\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.100)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate=none)\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "pretrained_model = train(model, loss_func, optimizer, epochs=5)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ahOjq1DIQk8g",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661083062174,
     "user_tz": -540,
     "elapsed": 28639,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "outputId": "1ea1c28c-a325-458b-96b8-0f93a693fbc7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 54,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch number 0/4\n",
      "====================\n",
      "train loss in this epoch: 2.708508587274395, accuracy in this epoch: 0.4713114754098361\n",
      "val loss in this epoch: 0.7632695615681169, accuracy in this epoch: 0.48366013071895425\n",
      "Epoch number 1/4\n",
      "====================\n",
      "train loss in this epoch: 0.7245011994096099, accuracy in this epoch: 0.5163934426229508\n",
      "val loss in this epoch: 0.7539688568878797, accuracy in this epoch: 0.5228758169934641\n",
      "Epoch number 2/4\n",
      "====================\n",
      "train loss in this epoch: 0.6875847470564921, accuracy in this epoch: 0.5942622950819673\n",
      "val loss in this epoch: 0.8802225488463259, accuracy in this epoch: 0.5490196078431373\n",
      "Epoch number 3/4\n",
      "====================\n",
      "train loss in this epoch: 0.7035530551535184, accuracy in this epoch: 0.6024590163934427\n",
      "val loss in this epoch: 0.6864889051789552, accuracy in this epoch: 0.542483660130719\n",
      "Epoch number 4/4\n",
      "====================\n",
      "train loss in this epoch: 0.6646142601966858, accuracy in this epoch: 0.569672131147541\n",
      "val loss in this epoch: 0.7754169897316328, accuracy in this epoch: 0.4575163398692811\n",
      "Training finished in 0.0mins 28.22867441177368secs\n",
      "Best validation set accuracy: 0.5490196078431373\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test(pretrained_model)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7ecqL6NQvQv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1661083065810,
     "user_tz": -540,
     "elapsed": 1471,
     "user": {
      "displayName": "Hyunwoong Ahn",
      "userId": "15588558909775372294"
     }
    },
    "outputId": "1a1ebb62-188d-4b23-8d93-57fbbebc564d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 55,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy for class: ants  is 87.1 %\n",
      "Accuracy for class: bees  is 10.8 %\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "l19xkBLwRBQw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}