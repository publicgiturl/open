{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"part4-ch3-ConvNeXt.ipynb","provenance":[],"machine_shape":"hm","mount_file_id":"17j8KnHJ_82iqLtVopa29950W7tI9doMG","authorship_tag":"ABX9TyN2fA8zJbupBENvCKr4d0Ut"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["cd /content/drive/MyDrive/lecture"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ETRjIc6aIexx","executionInfo":{"status":"ok","timestamp":1661097663476,"user_tz":-540,"elapsed":938,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"45c4708d-1013-4915-8528-ca61e389723b"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/lecture\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/facebookresearch/ConvNeXt.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywkm55yxIs3w","executionInfo":{"status":"ok","timestamp":1661097683552,"user_tz":-540,"elapsed":914,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"13bc0067-4071-420b-916e-15a32b9e1efc"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ConvNeXt'...\n","remote: Enumerating objects: 252, done.\u001b[K\n","remote: Counting objects: 100% (90/90), done.\u001b[K\n","remote: Compressing objects: 100% (50/50), done.\u001b[K\n","remote: Total 252 (delta 58), reused 40 (delta 40), pack-reused 162\u001b[K\n","Receiving objects: 100% (252/252), 73.25 KiB | 3.33 MiB/s, done.\n","Resolving deltas: 100% (128/128), done.\n"]}]},{"cell_type":"code","source":["cd ConvNeXt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nhGpBPD9IyBQ","executionInfo":{"status":"ok","timestamp":1661097691391,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"b31d67e2-44a2-470b-9379-fcbb05f183ce"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/lecture/ConvNeXt\n"]}]},{"cell_type":"markdown","source":["lib install"],"metadata":{"id":"DjBUh8oOJIKV"}},{"cell_type":"code","source":["!pip install timm==0.4.12  #version 주의"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"duXasQ72I0Xg","executionInfo":{"status":"ok","timestamp":1661097757400,"user_tz":-540,"elapsed":2991,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"e2c992fa-8c15-4388-9c2d-ffbb86054a25"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: timm==0.4.12 in /usr/local/lib/python3.7/dist-packages (0.4.12)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm==0.4.12) (1.12.1+cu113)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm==0.4.12) (0.13.1+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm==0.4.12) (4.1.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.4.12) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.4.12) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.4.12) (1.21.6)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm==0.4.12) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm==0.4.12) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm==0.4.12) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm==0.4.12) (2.10)\n"]}]},{"cell_type":"code","source":["!pip install tensorboardX"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1_2K8O7VI_9n","executionInfo":{"status":"ok","timestamp":1661097766656,"user_tz":-540,"elapsed":2978,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"caa9e566-1f3f-41bf-faf1-2f3c5e09a910"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.5.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n","Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n"]}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vT_9-DnOMELv","executionInfo":{"status":"ok","timestamp":1661100023970,"user_tz":-540,"elapsed":474,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"811d2ef6-586f-4b2f-b98b-2b46b605259d"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["CODE_OF_CONDUCT.md            LICENSE            README.md\n","CONTRIBUTING.md               main.py            run_with_submitit.py\n","convnext_base_22k_1k_224.pth  \u001b[0m\u001b[01;34mmodels\u001b[0m/            \u001b[01;34msemantic_segmentation\u001b[0m/\n","datasets.py                   \u001b[01;34mobject_detection\u001b[0m/  TRAINING.md\n","engine.py                     optim_factory.py   utils.py\n","INSTALL.md                    \u001b[01;34m__pycache__\u001b[0m/\n"]}]},{"cell_type":"markdown","source":["test 실행"],"metadata":{"id":"0y7W0BmqSAeF"}},{"cell_type":"code","source":["!python main.py --model convnext_base --eval true \\\n","--resume convnext_base_22k_1k_224.pth \\\n","--input_size 224 --drop_path 0.2 \\\n","--data_path /content/drive/MyDrive/AI-NN/datasets/hym_data/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dlqL2PROJF8p","executionInfo":{"status":"ok","timestamp":1661100054533,"user_tz":-540,"elapsed":12020,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"6b928d4d-0159-4e04-e94c-691ec05670e5"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Not using distributed mode\n","Namespace(aa='rand-m9-mstd0.5-inc1', auto_resume=True, batch_size=64, clip_grad=None, color_jitter=0.4, crop_pct=None, cutmix=1.0, cutmix_minmax=None, data_path='/content/drive/MyDrive/AI-NN/datasets/hym_data/', data_set='IMNET', device='cuda', disable_eval=False, dist_eval=True, dist_on_itp=False, dist_url='env://', distributed=False, drop_path=0.2, enable_wandb=False, epochs=300, eval=True, eval_data_path=None, finetune='', head_init_scale=1.0, imagenet_default_mean_and_std=True, input_size=224, layer_decay=1.0, layer_scale_init_value=1e-06, local_rank=-1, log_dir=None, lr=0.004, min_lr=1e-06, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='convnext_base', model_ema=False, model_ema_decay=0.9999, model_ema_eval=False, model_ema_force_cpu=False, model_key='model|module', model_prefix='', momentum=0.9, nb_classes=1000, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='', pin_mem=True, project='convnext', recount=1, remode='pixel', reprob=0.25, resplit=False, resume='convnext_base_22k_1k_224.pth', save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, seed=0, smoothing=0.1, start_epoch=0, train_interpolation='bicubic', update_freq=1, use_amp=False, wandb_ckpt=False, warmup_epochs=20, warmup_steps=-1, weight_decay=0.05, weight_decay_end=None, world_size=1)\n","Transform = \n","RandomResizedCropAndInterpolation(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)\n","RandomHorizontalFlip(p=0.5)\n","<timm.data.auto_augment.RandAugment object at 0x7f759b29fb50>\n","ToTensor()\n","Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n","<timm.data.random_erasing.RandomErasing object at 0x7f759b2238d0>\n","---------------------------\n","reading from datapath /content/drive/MyDrive/AI-NN/datasets/hym_data/\n","Number of the class = 1000\n","Transform = \n","Resize(size=256, interpolation=bicubic, max_size=None, antialias=None)\n","CenterCrop(size=(224, 224))\n","ToTensor()\n","Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n","---------------------------\n","reading from datapath /content/drive/MyDrive/AI-NN/datasets/hym_data/\n","Number of the class = 1000\n","Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f759b29fd10>\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Mixup is activated!\n","Model = ConvNeXt(\n","  (downsample_layers): ModuleList(\n","    (0): Sequential(\n","      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n","      (1): LayerNorm()\n","    )\n","    (1): Sequential(\n","      (0): LayerNorm()\n","      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","    (2): Sequential(\n","      (0): LayerNorm()\n","      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","    (3): Sequential(\n","      (0): LayerNorm()\n","      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","  )\n","  (stages): ModuleList(\n","    (0): Sequential(\n","      (0): Block(\n","        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (1): Block(\n","        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (2): Block(\n","        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n","        (drop_path): DropPath()\n","      )\n","    )\n","    (1): Sequential(\n","      (0): Block(\n","        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (1): Block(\n","        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (2): Block(\n","        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n","        (drop_path): DropPath()\n","      )\n","    )\n","    (2): Sequential(\n","      (0): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (1): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (2): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (3): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (4): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (5): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (6): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (7): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (8): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (9): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (10): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (11): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (12): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (13): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (14): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (15): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (16): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (17): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (18): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (19): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (20): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (21): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (22): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (23): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (24): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (25): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (26): Block(\n","        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n","        (drop_path): DropPath()\n","      )\n","    )\n","    (3): Sequential(\n","      (0): Block(\n","        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (1): Block(\n","        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (2): Block(\n","        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)\n","        (drop_path): DropPath()\n","      )\n","    )\n","  )\n","  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n","  (head): Linear(in_features=1024, out_features=1000, bias=True)\n",")\n","number of params: 88591464\n","LR = 0.00400000\n","Batch size = 64\n","Update frequent = 1\n","Number of training examples = 244\n","Number of training training per epoch = 3\n","Param groups = {\n","  \"decay\": {\n","    \"weight_decay\": 0.05,\n","    \"params\": [\n","      \"downsample_layers.0.0.weight\",\n","      \"downsample_layers.1.1.weight\",\n","      \"downsample_layers.2.1.weight\",\n","      \"downsample_layers.3.1.weight\",\n","      \"stages.0.0.dwconv.weight\",\n","      \"stages.0.0.pwconv1.weight\",\n","      \"stages.0.0.pwconv2.weight\",\n","      \"stages.0.1.dwconv.weight\",\n","      \"stages.0.1.pwconv1.weight\",\n","      \"stages.0.1.pwconv2.weight\",\n","      \"stages.0.2.dwconv.weight\",\n","      \"stages.0.2.pwconv1.weight\",\n","      \"stages.0.2.pwconv2.weight\",\n","      \"stages.1.0.dwconv.weight\",\n","      \"stages.1.0.pwconv1.weight\",\n","      \"stages.1.0.pwconv2.weight\",\n","      \"stages.1.1.dwconv.weight\",\n","      \"stages.1.1.pwconv1.weight\",\n","      \"stages.1.1.pwconv2.weight\",\n","      \"stages.1.2.dwconv.weight\",\n","      \"stages.1.2.pwconv1.weight\",\n","      \"stages.1.2.pwconv2.weight\",\n","      \"stages.2.0.dwconv.weight\",\n","      \"stages.2.0.pwconv1.weight\",\n","      \"stages.2.0.pwconv2.weight\",\n","      \"stages.2.1.dwconv.weight\",\n","      \"stages.2.1.pwconv1.weight\",\n","      \"stages.2.1.pwconv2.weight\",\n","      \"stages.2.2.dwconv.weight\",\n","      \"stages.2.2.pwconv1.weight\",\n","      \"stages.2.2.pwconv2.weight\",\n","      \"stages.2.3.dwconv.weight\",\n","      \"stages.2.3.pwconv1.weight\",\n","      \"stages.2.3.pwconv2.weight\",\n","      \"stages.2.4.dwconv.weight\",\n","      \"stages.2.4.pwconv1.weight\",\n","      \"stages.2.4.pwconv2.weight\",\n","      \"stages.2.5.dwconv.weight\",\n","      \"stages.2.5.pwconv1.weight\",\n","      \"stages.2.5.pwconv2.weight\",\n","      \"stages.2.6.dwconv.weight\",\n","      \"stages.2.6.pwconv1.weight\",\n","      \"stages.2.6.pwconv2.weight\",\n","      \"stages.2.7.dwconv.weight\",\n","      \"stages.2.7.pwconv1.weight\",\n","      \"stages.2.7.pwconv2.weight\",\n","      \"stages.2.8.dwconv.weight\",\n","      \"stages.2.8.pwconv1.weight\",\n","      \"stages.2.8.pwconv2.weight\",\n","      \"stages.2.9.dwconv.weight\",\n","      \"stages.2.9.pwconv1.weight\",\n","      \"stages.2.9.pwconv2.weight\",\n","      \"stages.2.10.dwconv.weight\",\n","      \"stages.2.10.pwconv1.weight\",\n","      \"stages.2.10.pwconv2.weight\",\n","      \"stages.2.11.dwconv.weight\",\n","      \"stages.2.11.pwconv1.weight\",\n","      \"stages.2.11.pwconv2.weight\",\n","      \"stages.2.12.dwconv.weight\",\n","      \"stages.2.12.pwconv1.weight\",\n","      \"stages.2.12.pwconv2.weight\",\n","      \"stages.2.13.dwconv.weight\",\n","      \"stages.2.13.pwconv1.weight\",\n","      \"stages.2.13.pwconv2.weight\",\n","      \"stages.2.14.dwconv.weight\",\n","      \"stages.2.14.pwconv1.weight\",\n","      \"stages.2.14.pwconv2.weight\",\n","      \"stages.2.15.dwconv.weight\",\n","      \"stages.2.15.pwconv1.weight\",\n","      \"stages.2.15.pwconv2.weight\",\n","      \"stages.2.16.dwconv.weight\",\n","      \"stages.2.16.pwconv1.weight\",\n","      \"stages.2.16.pwconv2.weight\",\n","      \"stages.2.17.dwconv.weight\",\n","      \"stages.2.17.pwconv1.weight\",\n","      \"stages.2.17.pwconv2.weight\",\n","      \"stages.2.18.dwconv.weight\",\n","      \"stages.2.18.pwconv1.weight\",\n","      \"stages.2.18.pwconv2.weight\",\n","      \"stages.2.19.dwconv.weight\",\n","      \"stages.2.19.pwconv1.weight\",\n","      \"stages.2.19.pwconv2.weight\",\n","      \"stages.2.20.dwconv.weight\",\n","      \"stages.2.20.pwconv1.weight\",\n","      \"stages.2.20.pwconv2.weight\",\n","      \"stages.2.21.dwconv.weight\",\n","      \"stages.2.21.pwconv1.weight\",\n","      \"stages.2.21.pwconv2.weight\",\n","      \"stages.2.22.dwconv.weight\",\n","      \"stages.2.22.pwconv1.weight\",\n","      \"stages.2.22.pwconv2.weight\",\n","      \"stages.2.23.dwconv.weight\",\n","      \"stages.2.23.pwconv1.weight\",\n","      \"stages.2.23.pwconv2.weight\",\n","      \"stages.2.24.dwconv.weight\",\n","      \"stages.2.24.pwconv1.weight\",\n","      \"stages.2.24.pwconv2.weight\",\n","      \"stages.2.25.dwconv.weight\",\n","      \"stages.2.25.pwconv1.weight\",\n","      \"stages.2.25.pwconv2.weight\",\n","      \"stages.2.26.dwconv.weight\",\n","      \"stages.2.26.pwconv1.weight\",\n","      \"stages.2.26.pwconv2.weight\",\n","      \"stages.3.0.dwconv.weight\",\n","      \"stages.3.0.pwconv1.weight\",\n","      \"stages.3.0.pwconv2.weight\",\n","      \"stages.3.1.dwconv.weight\",\n","      \"stages.3.1.pwconv1.weight\",\n","      \"stages.3.1.pwconv2.weight\",\n","      \"stages.3.2.dwconv.weight\",\n","      \"stages.3.2.pwconv1.weight\",\n","      \"stages.3.2.pwconv2.weight\",\n","      \"head.weight\"\n","    ],\n","    \"lr_scale\": 1.0\n","  },\n","  \"no_decay\": {\n","    \"weight_decay\": 0.0,\n","    \"params\": [\n","      \"downsample_layers.0.0.bias\",\n","      \"downsample_layers.0.1.weight\",\n","      \"downsample_layers.0.1.bias\",\n","      \"downsample_layers.1.0.weight\",\n","      \"downsample_layers.1.0.bias\",\n","      \"downsample_layers.1.1.bias\",\n","      \"downsample_layers.2.0.weight\",\n","      \"downsample_layers.2.0.bias\",\n","      \"downsample_layers.2.1.bias\",\n","      \"downsample_layers.3.0.weight\",\n","      \"downsample_layers.3.0.bias\",\n","      \"downsample_layers.3.1.bias\",\n","      \"stages.0.0.gamma\",\n","      \"stages.0.0.dwconv.bias\",\n","      \"stages.0.0.norm.weight\",\n","      \"stages.0.0.norm.bias\",\n","      \"stages.0.0.pwconv1.bias\",\n","      \"stages.0.0.pwconv2.bias\",\n","      \"stages.0.1.gamma\",\n","      \"stages.0.1.dwconv.bias\",\n","      \"stages.0.1.norm.weight\",\n","      \"stages.0.1.norm.bias\",\n","      \"stages.0.1.pwconv1.bias\",\n","      \"stages.0.1.pwconv2.bias\",\n","      \"stages.0.2.gamma\",\n","      \"stages.0.2.dwconv.bias\",\n","      \"stages.0.2.norm.weight\",\n","      \"stages.0.2.norm.bias\",\n","      \"stages.0.2.pwconv1.bias\",\n","      \"stages.0.2.pwconv2.bias\",\n","      \"stages.1.0.gamma\",\n","      \"stages.1.0.dwconv.bias\",\n","      \"stages.1.0.norm.weight\",\n","      \"stages.1.0.norm.bias\",\n","      \"stages.1.0.pwconv1.bias\",\n","      \"stages.1.0.pwconv2.bias\",\n","      \"stages.1.1.gamma\",\n","      \"stages.1.1.dwconv.bias\",\n","      \"stages.1.1.norm.weight\",\n","      \"stages.1.1.norm.bias\",\n","      \"stages.1.1.pwconv1.bias\",\n","      \"stages.1.1.pwconv2.bias\",\n","      \"stages.1.2.gamma\",\n","      \"stages.1.2.dwconv.bias\",\n","      \"stages.1.2.norm.weight\",\n","      \"stages.1.2.norm.bias\",\n","      \"stages.1.2.pwconv1.bias\",\n","      \"stages.1.2.pwconv2.bias\",\n","      \"stages.2.0.gamma\",\n","      \"stages.2.0.dwconv.bias\",\n","      \"stages.2.0.norm.weight\",\n","      \"stages.2.0.norm.bias\",\n","      \"stages.2.0.pwconv1.bias\",\n","      \"stages.2.0.pwconv2.bias\",\n","      \"stages.2.1.gamma\",\n","      \"stages.2.1.dwconv.bias\",\n","      \"stages.2.1.norm.weight\",\n","      \"stages.2.1.norm.bias\",\n","      \"stages.2.1.pwconv1.bias\",\n","      \"stages.2.1.pwconv2.bias\",\n","      \"stages.2.2.gamma\",\n","      \"stages.2.2.dwconv.bias\",\n","      \"stages.2.2.norm.weight\",\n","      \"stages.2.2.norm.bias\",\n","      \"stages.2.2.pwconv1.bias\",\n","      \"stages.2.2.pwconv2.bias\",\n","      \"stages.2.3.gamma\",\n","      \"stages.2.3.dwconv.bias\",\n","      \"stages.2.3.norm.weight\",\n","      \"stages.2.3.norm.bias\",\n","      \"stages.2.3.pwconv1.bias\",\n","      \"stages.2.3.pwconv2.bias\",\n","      \"stages.2.4.gamma\",\n","      \"stages.2.4.dwconv.bias\",\n","      \"stages.2.4.norm.weight\",\n","      \"stages.2.4.norm.bias\",\n","      \"stages.2.4.pwconv1.bias\",\n","      \"stages.2.4.pwconv2.bias\",\n","      \"stages.2.5.gamma\",\n","      \"stages.2.5.dwconv.bias\",\n","      \"stages.2.5.norm.weight\",\n","      \"stages.2.5.norm.bias\",\n","      \"stages.2.5.pwconv1.bias\",\n","      \"stages.2.5.pwconv2.bias\",\n","      \"stages.2.6.gamma\",\n","      \"stages.2.6.dwconv.bias\",\n","      \"stages.2.6.norm.weight\",\n","      \"stages.2.6.norm.bias\",\n","      \"stages.2.6.pwconv1.bias\",\n","      \"stages.2.6.pwconv2.bias\",\n","      \"stages.2.7.gamma\",\n","      \"stages.2.7.dwconv.bias\",\n","      \"stages.2.7.norm.weight\",\n","      \"stages.2.7.norm.bias\",\n","      \"stages.2.7.pwconv1.bias\",\n","      \"stages.2.7.pwconv2.bias\",\n","      \"stages.2.8.gamma\",\n","      \"stages.2.8.dwconv.bias\",\n","      \"stages.2.8.norm.weight\",\n","      \"stages.2.8.norm.bias\",\n","      \"stages.2.8.pwconv1.bias\",\n","      \"stages.2.8.pwconv2.bias\",\n","      \"stages.2.9.gamma\",\n","      \"stages.2.9.dwconv.bias\",\n","      \"stages.2.9.norm.weight\",\n","      \"stages.2.9.norm.bias\",\n","      \"stages.2.9.pwconv1.bias\",\n","      \"stages.2.9.pwconv2.bias\",\n","      \"stages.2.10.gamma\",\n","      \"stages.2.10.dwconv.bias\",\n","      \"stages.2.10.norm.weight\",\n","      \"stages.2.10.norm.bias\",\n","      \"stages.2.10.pwconv1.bias\",\n","      \"stages.2.10.pwconv2.bias\",\n","      \"stages.2.11.gamma\",\n","      \"stages.2.11.dwconv.bias\",\n","      \"stages.2.11.norm.weight\",\n","      \"stages.2.11.norm.bias\",\n","      \"stages.2.11.pwconv1.bias\",\n","      \"stages.2.11.pwconv2.bias\",\n","      \"stages.2.12.gamma\",\n","      \"stages.2.12.dwconv.bias\",\n","      \"stages.2.12.norm.weight\",\n","      \"stages.2.12.norm.bias\",\n","      \"stages.2.12.pwconv1.bias\",\n","      \"stages.2.12.pwconv2.bias\",\n","      \"stages.2.13.gamma\",\n","      \"stages.2.13.dwconv.bias\",\n","      \"stages.2.13.norm.weight\",\n","      \"stages.2.13.norm.bias\",\n","      \"stages.2.13.pwconv1.bias\",\n","      \"stages.2.13.pwconv2.bias\",\n","      \"stages.2.14.gamma\",\n","      \"stages.2.14.dwconv.bias\",\n","      \"stages.2.14.norm.weight\",\n","      \"stages.2.14.norm.bias\",\n","      \"stages.2.14.pwconv1.bias\",\n","      \"stages.2.14.pwconv2.bias\",\n","      \"stages.2.15.gamma\",\n","      \"stages.2.15.dwconv.bias\",\n","      \"stages.2.15.norm.weight\",\n","      \"stages.2.15.norm.bias\",\n","      \"stages.2.15.pwconv1.bias\",\n","      \"stages.2.15.pwconv2.bias\",\n","      \"stages.2.16.gamma\",\n","      \"stages.2.16.dwconv.bias\",\n","      \"stages.2.16.norm.weight\",\n","      \"stages.2.16.norm.bias\",\n","      \"stages.2.16.pwconv1.bias\",\n","      \"stages.2.16.pwconv2.bias\",\n","      \"stages.2.17.gamma\",\n","      \"stages.2.17.dwconv.bias\",\n","      \"stages.2.17.norm.weight\",\n","      \"stages.2.17.norm.bias\",\n","      \"stages.2.17.pwconv1.bias\",\n","      \"stages.2.17.pwconv2.bias\",\n","      \"stages.2.18.gamma\",\n","      \"stages.2.18.dwconv.bias\",\n","      \"stages.2.18.norm.weight\",\n","      \"stages.2.18.norm.bias\",\n","      \"stages.2.18.pwconv1.bias\",\n","      \"stages.2.18.pwconv2.bias\",\n","      \"stages.2.19.gamma\",\n","      \"stages.2.19.dwconv.bias\",\n","      \"stages.2.19.norm.weight\",\n","      \"stages.2.19.norm.bias\",\n","      \"stages.2.19.pwconv1.bias\",\n","      \"stages.2.19.pwconv2.bias\",\n","      \"stages.2.20.gamma\",\n","      \"stages.2.20.dwconv.bias\",\n","      \"stages.2.20.norm.weight\",\n","      \"stages.2.20.norm.bias\",\n","      \"stages.2.20.pwconv1.bias\",\n","      \"stages.2.20.pwconv2.bias\",\n","      \"stages.2.21.gamma\",\n","      \"stages.2.21.dwconv.bias\",\n","      \"stages.2.21.norm.weight\",\n","      \"stages.2.21.norm.bias\",\n","      \"stages.2.21.pwconv1.bias\",\n","      \"stages.2.21.pwconv2.bias\",\n","      \"stages.2.22.gamma\",\n","      \"stages.2.22.dwconv.bias\",\n","      \"stages.2.22.norm.weight\",\n","      \"stages.2.22.norm.bias\",\n","      \"stages.2.22.pwconv1.bias\",\n","      \"stages.2.22.pwconv2.bias\",\n","      \"stages.2.23.gamma\",\n","      \"stages.2.23.dwconv.bias\",\n","      \"stages.2.23.norm.weight\",\n","      \"stages.2.23.norm.bias\",\n","      \"stages.2.23.pwconv1.bias\",\n","      \"stages.2.23.pwconv2.bias\",\n","      \"stages.2.24.gamma\",\n","      \"stages.2.24.dwconv.bias\",\n","      \"stages.2.24.norm.weight\",\n","      \"stages.2.24.norm.bias\",\n","      \"stages.2.24.pwconv1.bias\",\n","      \"stages.2.24.pwconv2.bias\",\n","      \"stages.2.25.gamma\",\n","      \"stages.2.25.dwconv.bias\",\n","      \"stages.2.25.norm.weight\",\n","      \"stages.2.25.norm.bias\",\n","      \"stages.2.25.pwconv1.bias\",\n","      \"stages.2.25.pwconv2.bias\",\n","      \"stages.2.26.gamma\",\n","      \"stages.2.26.dwconv.bias\",\n","      \"stages.2.26.norm.weight\",\n","      \"stages.2.26.norm.bias\",\n","      \"stages.2.26.pwconv1.bias\",\n","      \"stages.2.26.pwconv2.bias\",\n","      \"stages.3.0.gamma\",\n","      \"stages.3.0.dwconv.bias\",\n","      \"stages.3.0.norm.weight\",\n","      \"stages.3.0.norm.bias\",\n","      \"stages.3.0.pwconv1.bias\",\n","      \"stages.3.0.pwconv2.bias\",\n","      \"stages.3.1.gamma\",\n","      \"stages.3.1.dwconv.bias\",\n","      \"stages.3.1.norm.weight\",\n","      \"stages.3.1.norm.bias\",\n","      \"stages.3.1.pwconv1.bias\",\n","      \"stages.3.1.pwconv2.bias\",\n","      \"stages.3.2.gamma\",\n","      \"stages.3.2.dwconv.bias\",\n","      \"stages.3.2.norm.weight\",\n","      \"stages.3.2.norm.bias\",\n","      \"stages.3.2.pwconv1.bias\",\n","      \"stages.3.2.pwconv2.bias\",\n","      \"norm.weight\",\n","      \"norm.bias\",\n","      \"head.bias\"\n","    ],\n","    \"lr_scale\": 1.0\n","  }\n","}\n","Use Cosine LR scheduler\n","Set warmup steps = 60\n","Set warmup steps = 0\n","Max WD = 0.0500000, Min WD = 0.0500000\n","criterion = SoftTargetCrossEntropy()\n","Resume checkpoint convnext_base_22k_1k_224.pth\n","Eval only mode\n","Test:  [0/2]  eta: 0:00:08  loss: 10.1525 (10.1525)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 4.3833  data: 1.4431  max mem: 3275\n","Test:  [1/2]  eta: 0:00:02  loss: 9.9631 (10.0578)  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 2.5668  data: 0.7216  max mem: 3275\n","Test: Total time: 0:00:05 (2.6191 s / it)\n","* Acc@1 0.000 Acc@5 0.000 loss 10.058\n","Accuracy of the network on 153 test images: 0.00000%\n"]}]},{"cell_type":"code","source":["!mkdir save_results"],"metadata":{"id":"RV4ajOshJhz5","executionInfo":{"status":"ok","timestamp":1661100075995,"user_tz":-540,"elapsed":548,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":["학습 실행"],"metadata":{"id":"CrsZNsYpR8Tk"}},{"cell_type":"code","source":["!python -m torch.distributed.launch --nproc_per_node=1 main.py \\\n","--model convnext_tiny --drop_path 0.1 \\\n","--batch_size 32 --lr 4e-3 --update_freq 4 --epochs 20 \\\n","--model_ema true --model_ema_eval true \\\n","--data_path /content/drive/MyDrive/AI-NN/datasets/hym_data/ \\\n","--output_dir /content/drive/MyDrive/AI-NN/ConvNeXt/save_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AiAyKeqLJSmq","executionInfo":{"status":"ok","timestamp":1661100130501,"user_tz":-540,"elapsed":6343,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"0453f6a9-f95f-45b1-cedc-e45ab2a8cb94"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n","and will be removed in future. Use torchrun.\n","Note that --use_env is set by default in torchrun.\n","If your script expects `--local_rank` argument to be set, please\n","change it to read from `os.environ['LOCAL_RANK']` instead. See \n","https://pytorch.org/docs/stable/distributed.html#launch-utility for \n","further instructions\n","\n","  FutureWarning,\n","| distributed init (rank 0): env://, gpu 0\n","Namespace(aa='rand-m9-mstd0.5-inc1', auto_resume=True, batch_size=32, clip_grad=None, color_jitter=0.4, crop_pct=None, cutmix=1.0, cutmix_minmax=None, data_path='/content/drive/MyDrive/AI-NN/datasets/hym_data/', data_set='IMNET', device='cuda', disable_eval=False, dist_backend='nccl', dist_eval=True, dist_on_itp=False, dist_url='env://', distributed=True, drop_path=0.1, enable_wandb=False, epochs=20, eval=False, eval_data_path=None, finetune='', gpu=0, head_init_scale=1.0, imagenet_default_mean_and_std=True, input_size=224, layer_decay=1.0, layer_scale_init_value=1e-06, local_rank=0, log_dir=None, lr=0.004, min_lr=1e-06, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='convnext_tiny', model_ema=True, model_ema_decay=0.9999, model_ema_eval=True, model_ema_force_cpu=False, model_key='model|module', model_prefix='', momentum=0.9, nb_classes=1000, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='/content/drive/MyDrive/AI-NN/ConvNeXt/save_results', pin_mem=True, project='convnext', rank=0, recount=1, remode='pixel', reprob=0.25, resplit=False, resume='', save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, seed=0, smoothing=0.1, start_epoch=0, train_interpolation='bicubic', update_freq=4, use_amp=False, wandb_ckpt=False, warmup_epochs=20, warmup_steps=-1, weight_decay=0.05, weight_decay_end=None, world_size=1)\n","Transform = \n","RandomResizedCropAndInterpolation(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)\n","RandomHorizontalFlip(p=0.5)\n","<timm.data.auto_augment.RandAugment object at 0x7f07c87fd710>\n","ToTensor()\n","Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n","<timm.data.random_erasing.RandomErasing object at 0x7f07c87fd250>\n","---------------------------\n","reading from datapath /content/drive/MyDrive/AI-NN/datasets/hym_data/\n","Number of the class = 1000\n","Transform = \n","Resize(size=256, interpolation=bicubic, max_size=None, antialias=None)\n","CenterCrop(size=(224, 224))\n","ToTensor()\n","Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n","---------------------------\n","reading from datapath /content/drive/MyDrive/AI-NN/datasets/hym_data/\n","Number of the class = 1000\n","Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f07c887aad0>\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Mixup is activated!\n","Using EMA with decay = 0.99990000\n","Model = ConvNeXt(\n","  (downsample_layers): ModuleList(\n","    (0): Sequential(\n","      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n","      (1): LayerNorm()\n","    )\n","    (1): Sequential(\n","      (0): LayerNorm()\n","      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","    (2): Sequential(\n","      (0): LayerNorm()\n","      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","    (3): Sequential(\n","      (0): LayerNorm()\n","      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","  )\n","  (stages): ModuleList(\n","    (0): Sequential(\n","      (0): Block(\n","        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (1): Block(\n","        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (2): Block(\n","        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n","        (drop_path): DropPath()\n","      )\n","    )\n","    (1): Sequential(\n","      (0): Block(\n","        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (1): Block(\n","        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (2): Block(\n","        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n","        (drop_path): DropPath()\n","      )\n","    )\n","    (2): Sequential(\n","      (0): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (1): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (2): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (3): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (4): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (5): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (6): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (7): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (8): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): DropPath()\n","      )\n","    )\n","    (3): Sequential(\n","      (0): Block(\n","        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (1): Block(\n","        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop_path): DropPath()\n","      )\n","      (2): Block(\n","        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop_path): DropPath()\n","      )\n","    )\n","  )\n","  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","  (head): Linear(in_features=768, out_features=1000, bias=True)\n",")\n","number of params: 28589128\n","LR = 0.00400000\n","Batch size = 128\n","Update frequent = 4\n","Number of training examples = 244\n","Number of training training per epoch = 1\n","Param groups = {\n","  \"decay\": {\n","    \"weight_decay\": 0.05,\n","    \"params\": [\n","      \"downsample_layers.0.0.weight\",\n","      \"downsample_layers.1.1.weight\",\n","      \"downsample_layers.2.1.weight\",\n","      \"downsample_layers.3.1.weight\",\n","      \"stages.0.0.dwconv.weight\",\n","      \"stages.0.0.pwconv1.weight\",\n","      \"stages.0.0.pwconv2.weight\",\n","      \"stages.0.1.dwconv.weight\",\n","      \"stages.0.1.pwconv1.weight\",\n","      \"stages.0.1.pwconv2.weight\",\n","      \"stages.0.2.dwconv.weight\",\n","      \"stages.0.2.pwconv1.weight\",\n","      \"stages.0.2.pwconv2.weight\",\n","      \"stages.1.0.dwconv.weight\",\n","      \"stages.1.0.pwconv1.weight\",\n","      \"stages.1.0.pwconv2.weight\",\n","      \"stages.1.1.dwconv.weight\",\n","      \"stages.1.1.pwconv1.weight\",\n","      \"stages.1.1.pwconv2.weight\",\n","      \"stages.1.2.dwconv.weight\",\n","      \"stages.1.2.pwconv1.weight\",\n","      \"stages.1.2.pwconv2.weight\",\n","      \"stages.2.0.dwconv.weight\",\n","      \"stages.2.0.pwconv1.weight\",\n","      \"stages.2.0.pwconv2.weight\",\n","      \"stages.2.1.dwconv.weight\",\n","      \"stages.2.1.pwconv1.weight\",\n","      \"stages.2.1.pwconv2.weight\",\n","      \"stages.2.2.dwconv.weight\",\n","      \"stages.2.2.pwconv1.weight\",\n","      \"stages.2.2.pwconv2.weight\",\n","      \"stages.2.3.dwconv.weight\",\n","      \"stages.2.3.pwconv1.weight\",\n","      \"stages.2.3.pwconv2.weight\",\n","      \"stages.2.4.dwconv.weight\",\n","      \"stages.2.4.pwconv1.weight\",\n","      \"stages.2.4.pwconv2.weight\",\n","      \"stages.2.5.dwconv.weight\",\n","      \"stages.2.5.pwconv1.weight\",\n","      \"stages.2.5.pwconv2.weight\",\n","      \"stages.2.6.dwconv.weight\",\n","      \"stages.2.6.pwconv1.weight\",\n","      \"stages.2.6.pwconv2.weight\",\n","      \"stages.2.7.dwconv.weight\",\n","      \"stages.2.7.pwconv1.weight\",\n","      \"stages.2.7.pwconv2.weight\",\n","      \"stages.2.8.dwconv.weight\",\n","      \"stages.2.8.pwconv1.weight\",\n","      \"stages.2.8.pwconv2.weight\",\n","      \"stages.3.0.dwconv.weight\",\n","      \"stages.3.0.pwconv1.weight\",\n","      \"stages.3.0.pwconv2.weight\",\n","      \"stages.3.1.dwconv.weight\",\n","      \"stages.3.1.pwconv1.weight\",\n","      \"stages.3.1.pwconv2.weight\",\n","      \"stages.3.2.dwconv.weight\",\n","      \"stages.3.2.pwconv1.weight\",\n","      \"stages.3.2.pwconv2.weight\",\n","      \"head.weight\"\n","    ],\n","    \"lr_scale\": 1.0\n","  },\n","  \"no_decay\": {\n","    \"weight_decay\": 0.0,\n","    \"params\": [\n","      \"downsample_layers.0.0.bias\",\n","      \"downsample_layers.0.1.weight\",\n","      \"downsample_layers.0.1.bias\",\n","      \"downsample_layers.1.0.weight\",\n","      \"downsample_layers.1.0.bias\",\n","      \"downsample_layers.1.1.bias\",\n","      \"downsample_layers.2.0.weight\",\n","      \"downsample_layers.2.0.bias\",\n","      \"downsample_layers.2.1.bias\",\n","      \"downsample_layers.3.0.weight\",\n","      \"downsample_layers.3.0.bias\",\n","      \"downsample_layers.3.1.bias\",\n","      \"stages.0.0.gamma\",\n","      \"stages.0.0.dwconv.bias\",\n","      \"stages.0.0.norm.weight\",\n","      \"stages.0.0.norm.bias\",\n","      \"stages.0.0.pwconv1.bias\",\n","      \"stages.0.0.pwconv2.bias\",\n","      \"stages.0.1.gamma\",\n","      \"stages.0.1.dwconv.bias\",\n","      \"stages.0.1.norm.weight\",\n","      \"stages.0.1.norm.bias\",\n","      \"stages.0.1.pwconv1.bias\",\n","      \"stages.0.1.pwconv2.bias\",\n","      \"stages.0.2.gamma\",\n","      \"stages.0.2.dwconv.bias\",\n","      \"stages.0.2.norm.weight\",\n","      \"stages.0.2.norm.bias\",\n","      \"stages.0.2.pwconv1.bias\",\n","      \"stages.0.2.pwconv2.bias\",\n","      \"stages.1.0.gamma\",\n","      \"stages.1.0.dwconv.bias\",\n","      \"stages.1.0.norm.weight\",\n","      \"stages.1.0.norm.bias\",\n","      \"stages.1.0.pwconv1.bias\",\n","      \"stages.1.0.pwconv2.bias\",\n","      \"stages.1.1.gamma\",\n","      \"stages.1.1.dwconv.bias\",\n","      \"stages.1.1.norm.weight\",\n","      \"stages.1.1.norm.bias\",\n","      \"stages.1.1.pwconv1.bias\",\n","      \"stages.1.1.pwconv2.bias\",\n","      \"stages.1.2.gamma\",\n","      \"stages.1.2.dwconv.bias\",\n","      \"stages.1.2.norm.weight\",\n","      \"stages.1.2.norm.bias\",\n","      \"stages.1.2.pwconv1.bias\",\n","      \"stages.1.2.pwconv2.bias\",\n","      \"stages.2.0.gamma\",\n","      \"stages.2.0.dwconv.bias\",\n","      \"stages.2.0.norm.weight\",\n","      \"stages.2.0.norm.bias\",\n","      \"stages.2.0.pwconv1.bias\",\n","      \"stages.2.0.pwconv2.bias\",\n","      \"stages.2.1.gamma\",\n","      \"stages.2.1.dwconv.bias\",\n","      \"stages.2.1.norm.weight\",\n","      \"stages.2.1.norm.bias\",\n","      \"stages.2.1.pwconv1.bias\",\n","      \"stages.2.1.pwconv2.bias\",\n","      \"stages.2.2.gamma\",\n","      \"stages.2.2.dwconv.bias\",\n","      \"stages.2.2.norm.weight\",\n","      \"stages.2.2.norm.bias\",\n","      \"stages.2.2.pwconv1.bias\",\n","      \"stages.2.2.pwconv2.bias\",\n","      \"stages.2.3.gamma\",\n","      \"stages.2.3.dwconv.bias\",\n","      \"stages.2.3.norm.weight\",\n","      \"stages.2.3.norm.bias\",\n","      \"stages.2.3.pwconv1.bias\",\n","      \"stages.2.3.pwconv2.bias\",\n","      \"stages.2.4.gamma\",\n","      \"stages.2.4.dwconv.bias\",\n","      \"stages.2.4.norm.weight\",\n","      \"stages.2.4.norm.bias\",\n","      \"stages.2.4.pwconv1.bias\",\n","      \"stages.2.4.pwconv2.bias\",\n","      \"stages.2.5.gamma\",\n","      \"stages.2.5.dwconv.bias\",\n","      \"stages.2.5.norm.weight\",\n","      \"stages.2.5.norm.bias\",\n","      \"stages.2.5.pwconv1.bias\",\n","      \"stages.2.5.pwconv2.bias\",\n","      \"stages.2.6.gamma\",\n","      \"stages.2.6.dwconv.bias\",\n","      \"stages.2.6.norm.weight\",\n","      \"stages.2.6.norm.bias\",\n","      \"stages.2.6.pwconv1.bias\",\n","      \"stages.2.6.pwconv2.bias\",\n","      \"stages.2.7.gamma\",\n","      \"stages.2.7.dwconv.bias\",\n","      \"stages.2.7.norm.weight\",\n","      \"stages.2.7.norm.bias\",\n","      \"stages.2.7.pwconv1.bias\",\n","      \"stages.2.7.pwconv2.bias\",\n","      \"stages.2.8.gamma\",\n","      \"stages.2.8.dwconv.bias\",\n","      \"stages.2.8.norm.weight\",\n","      \"stages.2.8.norm.bias\",\n","      \"stages.2.8.pwconv1.bias\",\n","      \"stages.2.8.pwconv2.bias\",\n","      \"stages.3.0.gamma\",\n","      \"stages.3.0.dwconv.bias\",\n","      \"stages.3.0.norm.weight\",\n","      \"stages.3.0.norm.bias\",\n","      \"stages.3.0.pwconv1.bias\",\n","      \"stages.3.0.pwconv2.bias\",\n","      \"stages.3.1.gamma\",\n","      \"stages.3.1.dwconv.bias\",\n","      \"stages.3.1.norm.weight\",\n","      \"stages.3.1.norm.bias\",\n","      \"stages.3.1.pwconv1.bias\",\n","      \"stages.3.1.pwconv2.bias\",\n","      \"stages.3.2.gamma\",\n","      \"stages.3.2.dwconv.bias\",\n","      \"stages.3.2.norm.weight\",\n","      \"stages.3.2.norm.bias\",\n","      \"stages.3.2.pwconv1.bias\",\n","      \"stages.3.2.pwconv2.bias\",\n","      \"norm.weight\",\n","      \"norm.bias\",\n","      \"head.bias\"\n","    ],\n","    \"lr_scale\": 1.0\n","  }\n","}\n","Use Cosine LR scheduler\n","Set warmup steps = 20\n","Set warmup steps = 0\n","Max WD = 0.0500000, Min WD = 0.0500000\n","criterion = SoftTargetCrossEntropy()\n","Auto resume checkpoint: /content/drive/MyDrive/AI-NN/ConvNeXt/save_results/checkpoint-19.pth\n","Resume checkpoint /content/drive/MyDrive/AI-NN/ConvNeXt/save_results/checkpoint-19.pth\n","With optim & sched!\n","Start training for 20 epochs\n","Training time 0:00:00\n"]}]},{"cell_type":"code","source":["from models.convnext import ConvNeXt\n","\n","model = ConvNeXt(num_classes=2)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rCwACNzdSGVt","executionInfo":{"status":"ok","timestamp":1661100226394,"user_tz":-540,"elapsed":2207,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"6f88eae8-b3f8-47c7-98e9-73c781c89d93"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["ConvNeXt(\n","  (downsample_layers): ModuleList(\n","    (0): Sequential(\n","      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n","      (1): LayerNorm()\n","    )\n","    (1): Sequential(\n","      (0): LayerNorm()\n","      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","    (2): Sequential(\n","      (0): LayerNorm()\n","      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","    (3): Sequential(\n","      (0): LayerNorm()\n","      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","  )\n","  (stages): ModuleList(\n","    (0): Sequential(\n","      (0): Block(\n","        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (1): Block(\n","        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (2): Block(\n","        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n","        (drop_path): Identity()\n","      )\n","    )\n","    (1): Sequential(\n","      (0): Block(\n","        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (1): Block(\n","        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (2): Block(\n","        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n","        (drop_path): Identity()\n","      )\n","    )\n","    (2): Sequential(\n","      (0): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (1): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (2): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (3): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (4): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (5): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (6): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (7): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (8): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","    )\n","    (3): Sequential(\n","      (0): Block(\n","        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (1): Block(\n","        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (2): Block(\n","        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop_path): Identity()\n","      )\n","    )\n","  )\n","  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","  (head): Linear(in_features=768, out_features=2, bias=True)\n",")\n"]}]},{"cell_type":"markdown","source":["학습"],"metadata":{"id":"A-YtuZQ4Shcy"}},{"cell_type":"code","source":["import torch.optim as optim\n","\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","\n","pretrained_model = train(model, loss_func, optimizer, epochs=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bBNkMYwwSeWM","executionInfo":{"status":"ok","timestamp":1661100401733,"user_tz":-540,"elapsed":73919,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"0440f823-ad09-4878-9e1c-7fdcb04319d3"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch number 0/4\n","====================\n","train loss in this epoch: 0.974306378208223, accuracy in this epoch: 0.5409836065573771\n","val loss in this epoch: 0.8424636172313317, accuracy in this epoch: 0.43790849673202614\n","Epoch number 1/4\n","====================\n","train loss in this epoch: 0.7183880805969238, accuracy in this epoch: 0.5614754098360656\n","val loss in this epoch: 0.7005290011175318, accuracy in this epoch: 0.5555555555555556\n","Epoch number 2/4\n","====================\n","train loss in this epoch: 0.6944325322010478, accuracy in this epoch: 0.6188524590163935\n","val loss in this epoch: 0.8019828644453311, accuracy in this epoch: 0.5555555555555556\n","Epoch number 3/4\n","====================\n","train loss in this epoch: 0.7345120887287327, accuracy in this epoch: 0.5286885245901639\n","val loss in this epoch: 0.7167823567889096, accuracy in this epoch: 0.542483660130719\n","Epoch number 4/4\n","====================\n","train loss in this epoch: 0.7090222757370745, accuracy in this epoch: 0.5860655737704918\n","val loss in this epoch: 0.6909552200946932, accuracy in this epoch: 0.6013071895424836\n","Training finished in 1.0mins 13.678797006607056secs\n","Best validation set accuracy: 0.6013071895424836\n"]}]},{"cell_type":"code","source":["test(pretrained_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-PA570YMS3kM","executionInfo":{"status":"ok","timestamp":1661100409350,"user_tz":-540,"elapsed":1801,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"36977111-a88c-43ea-d57c-809aacff2b24"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy for class: ants  is 47.1 %\n","Accuracy for class: bees  is 71.1 %\n"]}]},{"cell_type":"markdown","source":["train function"],"metadata":{"id":"LxgxmnKnSlgo"}},{"cell_type":"code","source":["import torch\n","import time\n","dvc = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","def train(model, loss_func, optimizer, epochs=10):\n","   start = time.time()\n","\n","   model = model.to(dvc)\n","\n","   accuracy = 0.0\n","\n","   for e in range(epochs):\n","        print(f'Epoch number {e}/{epochs - 1}')\n","        print('=' * 20)\n","\n","        for dset in ['train', 'val']:\n","            if dset == 'train':\n","                model.train()  \n","            else:\n","                model.eval() \n","\n","            loss = 0.0\n","            successes = 0\n","\n","            for imgs, tgts in dloaders[dset]:\n","                imgs = imgs.to(dvc)\n","                tgts = tgts.to(dvc)\n","                optimizer.zero_grad()\n","                \n","                with torch.set_grad_enabled(dset == 'train'):\n","                    ops = model(imgs)\n","                    #print(\"##\",ops)\n","                    _, preds = torch.max(ops, 1)\n","                    loss_curr = loss_func(ops, tgts)\n","                    \n","                    if dset == 'train':\n","                        loss_curr.backward()\n","                        optimizer.step()\n","\n","                loss += loss_curr.item() * imgs.size(0)\n","                successes += torch.sum(preds == tgts.data)\n","          \n","            loss_epoch = loss / dset_sizes[dset]\n","            accuracy_epoch = successes.double() / dset_sizes[dset]\n","\n","            print(f'{dset} loss in this epoch: {loss_epoch}, accuracy in this epoch: {accuracy_epoch}')\n","            if dset == 'val' and accuracy_epoch > accuracy:\n","                accuracy = accuracy_epoch      \n","\n","   time_delta = time.time() - start\n","   print(f'Training finished in {time_delta // 60}mins {time_delta % 60}secs')\n","   print(f'Best validation set accuracy: {accuracy}')\n","\n","\n","   return model"],"metadata":{"id":"u4Asr5ibSocM","executionInfo":{"status":"ok","timestamp":1661100274106,"user_tz":-540,"elapsed":550,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":["test function"],"metadata":{"id":"M5GOh8_iSsMM"}},{"cell_type":"code","source":["def test(model):\n","  model = model.to(dvc)\n","\n","  correct_pred = {classname: 0 for classname in classes}\n","  total_pred = {classname: 0 for classname in classes}\n","\n","\n","  with torch.no_grad():\n","      for images, labels in dloaders['val']:\n","\n","\n","          images = images.to(dvc)\n","          labels = labels.to(dvc)\n","        \n","          outputs = model(images)\n","          _, predictions = torch.max(outputs, 1)\n","\n","          for label, prediction in zip(labels, predictions):\n","              if label == prediction:\n","                  correct_pred[classes[label]] += 1\n","              total_pred[classes[label]] += 1\n","\n","\n","\n","  for classname, correct_count in correct_pred.items():\n","      accuracy = 100 * float(correct_count) / total_pred[classname]\n","      print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"],"metadata":{"id":"w1vTKMzySoo8","executionInfo":{"status":"ok","timestamp":1661100294229,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":["dataset"],"metadata":{"id":"turDvKXySwub"}},{"cell_type":"code","source":["import os\n","import time\n","import copy\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","\n","import torch.nn as nn\n","\n","\n","from torchvision import datasets, models, transforms"],"metadata":{"id":"dfHmO1iJSvrc","executionInfo":{"status":"ok","timestamp":1661100309943,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["ddir = '/content/drive/MyDrive/AI-NN/datasets/hym_data'\n","\n","batch_size = 8\n","num_workers = 4\n","\n","data_transformers = {\n","    'train': transforms.Compose(\n","        [\n","         transforms.RandomResizedCrop(224), \n","         transforms.RandomHorizontalFlip(),\n","         transforms.ToTensor(),\n","         transforms.Normalize([0.490, 0.449, 0.411], [0.231, 0.221, 0.230])\n","        ]\n","    ),\n","    'val': transforms.Compose(\n","        [\n","         transforms.Resize(256),\n","         transforms.CenterCrop(224),\n","         transforms.ToTensor(),\n","         transforms.Normalize([0.490, 0.449, 0.411],[0.231, 0.221, 0.230])\n","        ]\n","    )\n","}\n","\n","img_data = {\n","    k: datasets.ImageFolder(os.path.join(ddir, k), data_transformers[k])\n","    for k in ['train', 'val']\n","}\n","dloaders = {\n","    k: torch.utils.data.DataLoader(\n","        img_data[k], batch_size=batch_size, shuffle=True, num_workers=num_workers\n","    )\n","    for k in ['train', 'val']\n","}\n","dset_sizes = {x: len(img_data[x]) for x in ['train', 'val']}\n","classes = img_data['train'].classes\n","\n","dvc = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"],"metadata":{"id":"7Yd2JktySzi0","executionInfo":{"status":"ok","timestamp":1661100318118,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":["class 추출"],"metadata":{"id":"9-oGh36ITPY2"}},{"cell_type":"code","source":["# Copyright (c) Meta Platforms, Inc. and affiliates.\n","\n","# All rights reserved.\n","\n","# This source code is licensed under the license found in the\n","# LICENSE file in the root directory of this source tree.\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from timm.models.layers import trunc_normal_, DropPath\n","from timm.models.registry import register_model\n","\n","class Block(nn.Module):\n","    r\"\"\" ConvNeXt Block. There are two equivalent implementations:\n","    (1) DwConv -> LayerNorm (channels_first) -> 1x1 Conv -> GELU -> 1x1 Conv; all in (N, C, H, W)\n","    (2) DwConv -> Permute to (N, H, W, C); LayerNorm (channels_last) -> Linear -> GELU -> Linear; Permute back\n","    We use (2) as we find it slightly faster in PyTorch\n","    \n","    Args:\n","        dim (int): Number of input channels.\n","        drop_path (float): Stochastic depth rate. Default: 0.0\n","        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\n","    \"\"\"\n","    def __init__(self, dim, drop_path=0., layer_scale_init_value=1e-6):\n","        super().__init__()\n","        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim) # depthwise conv\n","        self.norm = LayerNorm(dim, eps=1e-6)\n","        self.pwconv1 = nn.Linear(dim, 4 * dim) # pointwise/1x1 convs, implemented with linear layers\n","        self.act = nn.GELU()\n","        self.pwconv2 = nn.Linear(4 * dim, dim)\n","        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), \n","                                    requires_grad=True) if layer_scale_init_value > 0 else None\n","        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n","\n","    def forward(self, x):\n","        input = x\n","        x = self.dwconv(x)\n","        x = x.permute(0, 2, 3, 1) # (N, C, H, W) -> (N, H, W, C)\n","        x = self.norm(x)\n","        x = self.pwconv1(x)\n","        x = self.act(x)\n","        x = self.pwconv2(x)\n","        if self.gamma is not None:\n","            x = self.gamma * x\n","        x = x.permute(0, 3, 1, 2) # (N, H, W, C) -> (N, C, H, W)\n","\n","        x = input + self.drop_path(x)\n","        return x\n","\n","class ConvNeXt(nn.Module):\n","    r\"\"\" ConvNeXt\n","        A PyTorch impl of : `A ConvNet for the 2020s`  -\n","          https://arxiv.org/pdf/2201.03545.pdf\n","\n","    Args:\n","        in_chans (int): Number of input image channels. Default: 3\n","        num_classes (int): Number of classes for classification head. Default: 1000\n","        depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]\n","        dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]\n","        drop_path_rate (float): Stochastic depth rate. Default: 0.\n","        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\n","        head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.\n","    \"\"\"\n","    def __init__(self, in_chans=3, num_classes=1000, \n","                 depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], drop_path_rate=0., \n","                 layer_scale_init_value=1e-6, head_init_scale=1.,\n","                 ):\n","        super().__init__()\n","\n","        self.downsample_layers = nn.ModuleList() # stem and 3 intermediate downsampling conv layers\n","        stem = nn.Sequential(\n","            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),\n","            LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\")\n","        )\n","        self.downsample_layers.append(stem)\n","        for i in range(3):\n","            downsample_layer = nn.Sequential(\n","                    LayerNorm(dims[i], eps=1e-6, data_format=\"channels_first\"),\n","                    nn.Conv2d(dims[i], dims[i+1], kernel_size=2, stride=2),\n","            )\n","            self.downsample_layers.append(downsample_layer)\n","\n","        self.stages = nn.ModuleList() # 4 feature resolution stages, each consisting of multiple residual blocks\n","        dp_rates=[x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))] \n","        cur = 0\n","        for i in range(4):\n","            stage = nn.Sequential(\n","                *[Block(dim=dims[i], drop_path=dp_rates[cur + j], \n","                layer_scale_init_value=layer_scale_init_value) for j in range(depths[i])]\n","            )\n","            self.stages.append(stage)\n","            cur += depths[i]\n","\n","        self.norm = nn.LayerNorm(dims[-1], eps=1e-6) # final norm layer\n","        self.head = nn.Linear(dims[-1], num_classes)\n","\n","        self.apply(self._init_weights)\n","        self.head.weight.data.mul_(head_init_scale)\n","        self.head.bias.data.mul_(head_init_scale)\n","\n","    def _init_weights(self, m):\n","        if isinstance(m, (nn.Conv2d, nn.Linear)):\n","            trunc_normal_(m.weight, std=.02)\n","            nn.init.constant_(m.bias, 0)\n","\n","    def forward_features(self, x):\n","        for i in range(4):\n","            x = self.downsample_layers[i](x)\n","            x = self.stages[i](x)\n","        return self.norm(x.mean([-2, -1])) # global average pooling, (N, C, H, W) -> (N, C)\n","\n","    def forward(self, x):\n","        x = self.forward_features(x)\n","        x = self.head(x)\n","        return x\n","\n","class LayerNorm(nn.Module):\n","    r\"\"\" LayerNorm that supports two data formats: channels_last (default) or channels_first. \n","    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with \n","    shape (batch_size, height, width, channels) while channels_first corresponds to inputs \n","    with shape (batch_size, channels, height, width).\n","    \"\"\"\n","    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n","        super().__init__()\n","        self.weight = nn.Parameter(torch.ones(normalized_shape))\n","        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n","        self.eps = eps\n","        self.data_format = data_format\n","        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n","            raise NotImplementedError \n","        self.normalized_shape = (normalized_shape, )\n","    \n","    def forward(self, x):\n","        if self.data_format == \"channels_last\":\n","            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n","        elif self.data_format == \"channels_first\":\n","            u = x.mean(1, keepdim=True)\n","            s = (x - u).pow(2).mean(1, keepdim=True)\n","            x = (x - u) / torch.sqrt(s + self.eps)\n","            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n","            return x\n","\n","\n","model_urls = {\n","    \"convnext_tiny_1k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth\",\n","    \"convnext_small_1k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_small_1k_224_ema.pth\",\n","    \"convnext_base_1k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_224_ema.pth\",\n","    \"convnext_large_1k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_large_1k_224_ema.pth\",\n","    \"convnext_tiny_22k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_tiny_22k_224.pth\",\n","    \"convnext_small_22k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_small_22k_224.pth\",\n","    \"convnext_base_22k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_224.pth\",\n","    \"convnext_large_22k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_224.pth\",\n","    \"convnext_xlarge_22k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_224.pth\",\n","}\n","\n","@register_model\n","def convnext_tiny(pretrained=False,in_22k=False, **kwargs):\n","    model = ConvNeXt(depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], **kwargs)\n","    if pretrained:\n","        url = model_urls['convnext_tiny_22k'] if in_22k else model_urls['convnext_tiny_1k']\n","        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location=\"cpu\", check_hash=True)\n","        model.load_state_dict(checkpoint[\"model\"])\n","    return model\n","\n","@register_model\n","def convnext_small(pretrained=False,in_22k=False, **kwargs):\n","    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[96, 192, 384, 768], **kwargs)\n","    if pretrained:\n","        url = model_urls['convnext_small_22k'] if in_22k else model_urls['convnext_small_1k']\n","        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location=\"cpu\")\n","        model.load_state_dict(checkpoint[\"model\"])\n","    return model\n","\n","@register_model\n","def convnext_base(pretrained=False, in_22k=False, **kwargs):\n","    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024], **kwargs)\n","    if pretrained:\n","        url = model_urls['convnext_base_22k'] if in_22k else model_urls['convnext_base_1k']\n","        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location=\"cpu\")\n","        model.load_state_dict(checkpoint[\"model\"])\n","    return model\n","\n","@register_model\n","def convnext_large(pretrained=False, in_22k=False, **kwargs):\n","    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[192, 384, 768, 1536], **kwargs)\n","    if pretrained:\n","        url = model_urls['convnext_large_22k'] if in_22k else model_urls['convnext_large_1k']\n","        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location=\"cpu\")\n","        model.load_state_dict(checkpoint[\"model\"])\n","    return model\n","\n","@register_model\n","def convnext_xlarge(pretrained=False, in_22k=False, **kwargs):\n","    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[256, 512, 1024, 2048], **kwargs)\n","    if pretrained:\n","        assert in_22k, \"only ImageNet-22K pre-trained ConvNeXt-XL is available; please set in_22k=True\"\n","        url = model_urls['convnext_xlarge_22k']\n","        checkpoint = torch.hub.load_state_dict_from_url(url=url, map_location=\"cpu\")\n","        model.load_state_dict(checkpoint[\"model\"])\n","    return model\n"],"metadata":{"id":"1XljUSXAS1gl","executionInfo":{"status":"ok","timestamp":1661100450242,"user_tz":-540,"elapsed":909,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["model = ConvNeXt(num_classes=2)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q-EIBGVcTVld","executionInfo":{"status":"ok","timestamp":1661100483535,"user_tz":-540,"elapsed":904,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"39830942-f264-458a-e897-b7d4ded12a4c"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["ConvNeXt(\n","  (downsample_layers): ModuleList(\n","    (0): Sequential(\n","      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n","      (1): LayerNorm()\n","    )\n","    (1): Sequential(\n","      (0): LayerNorm()\n","      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","    (2): Sequential(\n","      (0): LayerNorm()\n","      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","    (3): Sequential(\n","      (0): LayerNorm()\n","      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","  )\n","  (stages): ModuleList(\n","    (0): Sequential(\n","      (0): Block(\n","        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (1): Block(\n","        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (2): Block(\n","        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n","        (drop_path): Identity()\n","      )\n","    )\n","    (1): Sequential(\n","      (0): Block(\n","        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (1): Block(\n","        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (2): Block(\n","        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n","        (drop_path): Identity()\n","      )\n","    )\n","    (2): Sequential(\n","      (0): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (1): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (2): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (3): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (4): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (5): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (6): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (7): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (8): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","    )\n","    (3): Sequential(\n","      (0): Block(\n","        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (1): Block(\n","        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (2): Block(\n","        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU(approximate=none)\n","        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop_path): Identity()\n","      )\n","    )\n","  )\n","  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","  (head): Linear(in_features=768, out_features=2, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","\n","pretrained_model = train(model, loss_func, optimizer, epochs=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3zYIxY7oTdqs","executionInfo":{"status":"ok","timestamp":1661100540500,"user_tz":-540,"elapsed":26944,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"2fee7c0c-f6c6-44d6-9fed-de63e601b4f3"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch number 0/4\n","====================\n","train loss in this epoch: 0.9215529971435422, accuracy in this epoch: 0.5163934426229508\n","val loss in this epoch: 0.7296074040574965, accuracy in this epoch: 0.5098039215686274\n","Epoch number 1/4\n","====================\n","train loss in this epoch: 0.7305795843483972, accuracy in this epoch: 0.569672131147541\n","val loss in this epoch: 0.7329814930756887, accuracy in this epoch: 0.5882352941176471\n","Epoch number 2/4\n","====================\n","train loss in this epoch: 0.7339847078088855, accuracy in this epoch: 0.5491803278688525\n","val loss in this epoch: 0.7231879047319001, accuracy in this epoch: 0.5816993464052288\n","Epoch number 3/4\n","====================\n","train loss in this epoch: 0.7154395814801826, accuracy in this epoch: 0.5860655737704918\n","val loss in this epoch: 0.7200927578545864, accuracy in this epoch: 0.5751633986928105\n","Epoch number 4/4\n","====================\n","train loss in this epoch: 0.7248942685908959, accuracy in this epoch: 0.5901639344262295\n","val loss in this epoch: 0.725503539143045, accuracy in this epoch: 0.5032679738562091\n","Training finished in 0.0mins 27.213762760162354secs\n","Best validation set accuracy: 0.5882352941176471\n"]}]},{"cell_type":"code","source":["test(pretrained_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ihjy3tWwTlUc","executionInfo":{"status":"ok","timestamp":1661100548286,"user_tz":-540,"elapsed":1537,"user":{"displayName":"Hyunwoong Ahn","userId":"15588558909775372294"}},"outputId":"61601dbb-d797-4fbc-c761-c6cf142157ea"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy for class: ants  is 75.7 %\n","Accuracy for class: bees  is 28.9 %\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"jS51zVSaTtVc"},"execution_count":null,"outputs":[]}]}