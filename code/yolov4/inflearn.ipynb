{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import colorsys\n",
    "from operator import itemgetter\n",
    "\n",
    "def draw_bounding_box_and_label_info(frame, x_min, y_min, x_max, y_max, label, confidence, color):\n",
    "  draw_bounding_box(frame, x_min, y_min, x_max, y_max, color)\n",
    "  draw_label_info(frame, x_min, y_min, label, confidence, color)\n",
    "\n",
    "\n",
    "def draw_bounding_box(frame, x_min, y_min, x_max, y_max, color):\n",
    "  cv2.rectangle(\n",
    "    frame,\n",
    "    (x_min, y_min),\n",
    "    (x_max, y_max),\n",
    "    color, 3)\n",
    "\n",
    "\n",
    "def draw_label_info(frame, x_min, y_min, label, confidence, color):\n",
    "  text = label + ' ' + str('%.3f' % confidence)\n",
    "  bottomLeftCornerOfText = (x_min, y_min)\n",
    "  font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "  fontScale = 0.8\n",
    "  fontColor = color\n",
    "  lineType = 2\n",
    "\n",
    "  cv2.putText(frame, text,\n",
    "              bottomLeftCornerOfText,\n",
    "              font,\n",
    "              fontScale,\n",
    "              fontColor,\n",
    "              lineType)\n",
    "\n",
    "def find_max_confidence_bounding_box(bounding_box_info_list):\n",
    "  bounding_box_info_list_sorted = sorted(bounding_box_info_list,\n",
    "                                                   key=itemgetter('confidence'),\n",
    "                                                   reverse=True)\n",
    "  max_confidence_bounding_box = bounding_box_info_list_sorted[0]\n",
    "\n",
    "  return max_confidence_bounding_box\n",
    "\n",
    "\n",
    "def yolo_format_to_bounding_box_dict(xcenter, ycenter, box_w, box_h, class_name, confidence):\n",
    "  bounding_box_info = {}\n",
    "  bounding_box_info['left'] = int(xcenter - (box_w / 2))\n",
    "  bounding_box_info['top'] = int(ycenter - (box_h / 2))\n",
    "  bounding_box_info['right'] = int(xcenter + (box_w / 2))\n",
    "  bounding_box_info['bottom'] = int(ycenter + (box_h / 2))\n",
    "  bounding_box_info['class_name'] = class_name\n",
    "  bounding_box_info['confidence'] = confidence\n",
    "\n",
    "  return bounding_box_info\n",
    "\n",
    "\n",
    "def iou(yolo_pred_boxes, ground_truth_boxes):\n",
    "  # Reference : https://github.com/nilboy/tensorflow-yolo/blob/python2.7/yolo/net/yolo_tiny_net.py#L105\n",
    "  \"\"\"calculate ious\n",
    "  Args:\n",
    "    yolo_pred_boxes: 4-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  ====> (x_center, y_center, w, h)\n",
    "    ground_truth_boxes: 1-D tensor [4] ===> (x_center, y_center, w, h)\n",
    "  Return:\n",
    "    iou: 3-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "  \"\"\"\n",
    "  boxes1 = yolo_pred_boxes\n",
    "  boxes2 = ground_truth_boxes\n",
    "\n",
    "  boxes1 = tf.stack([boxes1[:, :, :, 0] - boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] - boxes1[:, :, :, 3] / 2,\n",
    "                     boxes1[:, :, :, 0] + boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] + boxes1[:, :, :, 3] / 2])\n",
    "  boxes1 = tf.transpose(boxes1, [1, 2, 3, 0])\n",
    "  boxes2 = tf.stack([boxes2[0] - boxes2[2] / 2, boxes2[1] - boxes2[3] / 2,\n",
    "                     boxes2[0] + boxes2[2] / 2, boxes2[1] + boxes2[3] / 2])\n",
    "  boxes2 = tf.cast(boxes2, tf.float32)\n",
    "\n",
    "  # calculate the left up point\n",
    "  lu = tf.maximum(boxes1[:, :, :, 0:2], boxes2[0:2])\n",
    "  rd = tf.minimum(boxes1[:, :, :, 2:], boxes2[2:])\n",
    "\n",
    "  # intersection\n",
    "  intersection = rd - lu\n",
    "\n",
    "  inter_square = intersection[:, :, :, 0] * intersection[:, :, :, 1]\n",
    "\n",
    "  mask = tf.cast(intersection[:, :, :, 0] > 0, tf.float32) * tf.cast(intersection[:, :, :, 1] > 0, tf.float32)\n",
    "\n",
    "  inter_square = mask * inter_square\n",
    "\n",
    "  # calculate the boxs1 square and boxs2 square\n",
    "  square1 = (boxes1[:, :, :, 2] - boxes1[:, :, :, 0]) * (boxes1[:, :, :, 3] - boxes1[:, :, :, 1])\n",
    "  square2 = (boxes2[2] - boxes2[0]) * (boxes2[3] - boxes2[1])\n",
    "\n",
    "  return inter_square / (square1 + square2 - inter_square + 1e-6)\n",
    "\n",
    "\n",
    "def generate_color(num_classes):\n",
    "  # Reference : https://github.com/qqwweee/keras-yolo3/blob/e6598d13c703029b2686bc2eb8d5c09badf42992/yolo.py#L82\n",
    "  # Generate colors for drawing bounding boxes.\n",
    "  hsv_tuples = [(x / num_classes, 1., 1.)\n",
    "                for x in range(num_classes)]\n",
    "  colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "  colors = list(\n",
    "    map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "        colors))\n",
    "  np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "  np.random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "  np.random.seed(None)  # Reset seed to default.\n",
    "\n",
    "  return colors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Reference : https://stackoverflow.com/questions/54567986/python-numpy-remove-empty-zeroes-border-of-3d-array\n",
    "def bounds_per_dimension(ndarray):\n",
    "  return map(\n",
    "    lambda e: range(e.min(), e.max() + 1),\n",
    "    np.where(ndarray != 0)\n",
    "  )\n",
    "\n",
    "\n",
    "def zero_trim_ndarray(ndarray):\n",
    "  return ndarray[np.ix_(*bounds_per_dimension(ndarray))]\n",
    "\n",
    "\n",
    "# process ground-truth data for YOLO format\n",
    "def process_each_ground_truth(original_image,\n",
    "                              bbox,\n",
    "                              class_labels,\n",
    "                              input_width,\n",
    "                              input_height\n",
    "                              ):\n",
    "  \"\"\"\n",
    "  Reference:\n",
    "    https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/object_detection/voc.py#L115\n",
    "    bbox return : (ymin / height, xmin / width, ymax / height, xmax / width)\n",
    "  Args:\n",
    "    original_image : (original_height, orignal_width, channel) image tensor\n",
    "    bbox : (max_object_num_in_batch, 4) = (ymin / height, xmin / width, ymax / height, xmax / width)\n",
    "    class_labels : (max_object_num_in_batch) = class labels without one-hot-encoding\n",
    "    input_width : yolo input width\n",
    "    input_height : yolo input height\n",
    "  Returns:\n",
    "    image: (resized_height, resized_width, channel) image ndarray\n",
    "    labels: 2-D list [object_num, 5] (xcenter (Absolute Coordinate), ycenter (Absolute Coordinate), w (Absolute Coordinate), h (Absolute Coordinate), class_num)\n",
    "    object_num: total object number in image\n",
    "  \"\"\"\n",
    "  image = original_image.numpy()\n",
    "  image = zero_trim_ndarray(image)\n",
    "\n",
    "  # set original width height\n",
    "  original_h = image.shape[0]\n",
    "  original_w = image.shape[1]\n",
    "\n",
    "  width_rate = input_width * 1.0 / original_w\n",
    "  height_rate = input_height * 1.0 / original_h\n",
    "\n",
    "  image = tf.image.resize(image, [input_height, input_width])\n",
    "\n",
    "  object_num = np.count_nonzero(bbox, axis=0)[0]\n",
    "  labels = [[0, 0, 0, 0, 0]] * object_num\n",
    "  for i in range(object_num):\n",
    "    xmin = bbox[i][1] * original_w\n",
    "    ymin = bbox[i][0] * original_h\n",
    "    xmax = bbox[i][3] * original_w\n",
    "    ymax = bbox[i][2] * original_h\n",
    "\n",
    "    class_num = class_labels[i]\n",
    "\n",
    "    xcenter = (xmin + xmax) * 1.0 / 2 * width_rate\n",
    "    ycenter = (ymin + ymax) * 1.0 / 2 * height_rate\n",
    "\n",
    "    box_w = (xmax - xmin) * width_rate\n",
    "    box_h = (ymax - ymin) * height_rate\n",
    "\n",
    "    labels[i] = [xcenter, ycenter, box_w, box_h, class_num]\n",
    "\n",
    "  return [image.numpy(), labels, object_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def yolo_loss(predict,\n",
    "              labels,\n",
    "              each_object_num,\n",
    "              num_classes,\n",
    "              boxes_per_cell,\n",
    "              cell_size,\n",
    "              input_width,\n",
    "              input_height,\n",
    "              coord_scale,\n",
    "              object_scale,\n",
    "              noobject_scale,\n",
    "              class_scale\n",
    "              ):\n",
    "  '''\n",
    "  Args:\n",
    "    predict: 3 - D tensor [cell_size, cell_size, num_classes + 5 * boxes_per_cell]\n",
    "    labels: 2-D list [object_num, 5] (xcenter (Absolute coordinate), ycenter (Absolute coordinate), w (Absolute coordinate), h (Absolute coordinate), class_num)\n",
    "    each_object_num: each_object number in image\n",
    "    num_classes: number of classes\n",
    "    boxes_per_cell: number of prediction boxes per each cell\n",
    "    cell_size: each cell size\n",
    "    input_width : input width of original image\n",
    "    input_height : input_height of original image\n",
    "    coord_scale : coefficient for coordinate loss\n",
    "    object_scale : coefficient for object loss\n",
    "    noobject_scale : coefficient for noobject loss\n",
    "    class_scale : coefficient for class loss\n",
    "  Returns:\n",
    "    total_loss: coord_loss  + object_loss + noobject_loss + class_loss\n",
    "    coord_loss\n",
    "    object_loss\n",
    "    noobject_loss\n",
    "    class_loss\n",
    "  '''\n",
    "\n",
    "  # parse only coordinate vector\n",
    "  predict_boxes = predict[:, :, num_classes + boxes_per_cell:]\n",
    "  predict_boxes = tf.reshape(predict_boxes, [cell_size, cell_size, boxes_per_cell, 4])\n",
    "\n",
    "  # prediction : absolute coordinate\n",
    "  pred_xcenter = predict_boxes[:, :, :, 0]\n",
    "  pred_ycenter = predict_boxes[:, :, :, 1]\n",
    "  pred_sqrt_w = tf.sqrt(tf.minimum(input_width * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 2])))\n",
    "  pred_sqrt_h = tf.sqrt(tf.minimum(input_height * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 3])))\n",
    "  pred_sqrt_w = tf.cast(pred_sqrt_w, tf.float32)\n",
    "  pred_sqrt_h = tf.cast(pred_sqrt_h, tf.float32)\n",
    "\n",
    "  # parse label\n",
    "  labels = np.array(labels)\n",
    "  labels = labels.astype('float32')\n",
    "  label = labels[each_object_num, :]\n",
    "  xcenter = label[0]\n",
    "  ycenter = label[1]\n",
    "  sqrt_w = tf.sqrt(label[2])\n",
    "  sqrt_h = tf.sqrt(label[3])\n",
    "\n",
    "  # calulate iou between ground-truth and predictions\n",
    "  iou_predict_truth = iou(predict_boxes, label[0:4])\n",
    "\n",
    "  # find best box mask\n",
    "  I = iou_predict_truth\n",
    "  max_I = tf.reduce_max(I, 2, keepdims=True)\n",
    "  best_box_mask = tf.cast((I >= max_I), tf.float32)\n",
    "\n",
    "  # set object_loss information\n",
    "  C = iou_predict_truth\n",
    "  pred_C = predict[:, :, num_classes:num_classes + boxes_per_cell]\n",
    "\n",
    "  # set class_loss information\n",
    "  P = tf.one_hot(tf.cast(label[4], tf.int32), num_classes, dtype=tf.float32)\n",
    "  pred_P = predict[:, :, 0:num_classes]\n",
    "\n",
    "  # find object exists cell mask\n",
    "  object_exists_cell = np.zeros([cell_size, cell_size, 1])\n",
    "  object_exists_cell_i, object_exists_cell_j = int(cell_size * ycenter / input_height), int(cell_size * xcenter / input_width)\n",
    "  object_exists_cell[object_exists_cell_i][object_exists_cell_j] = 1\n",
    "\n",
    "  # set coord_loss\n",
    "  coord_loss = (tf.nn.l2_loss(object_exists_cell * best_box_mask * (pred_xcenter - xcenter) / (input_width / cell_size)) +\n",
    "                tf.nn.l2_loss(object_exists_cell * best_box_mask * (pred_ycenter - ycenter) / (input_height / cell_size)) +\n",
    "                tf.nn.l2_loss(object_exists_cell * best_box_mask * (pred_sqrt_w - sqrt_w)) / input_width +\n",
    "                tf.nn.l2_loss(object_exists_cell * best_box_mask * (pred_sqrt_h - sqrt_h)) / input_height ) \\\n",
    "               * coord_scale\n",
    "\n",
    "  # object_loss\n",
    "  object_loss = tf.nn.l2_loss(object_exists_cell * best_box_mask * (pred_C - C)) * object_scale\n",
    "\n",
    "  # noobject_loss\n",
    "  noobject_loss = tf.nn.l2_loss((1 - object_exists_cell) * (pred_C)) * noobject_scale\n",
    "\n",
    "  # class loss\n",
    "  class_loss = tf.nn.l2_loss(object_exists_cell * (pred_P - P)) * class_scale\n",
    "\n",
    "  # sum every loss\n",
    "  total_loss = coord_loss + object_loss + noobject_loss + class_loss\n",
    "\n",
    "  return total_loss, coord_loss, object_loss, noobject_loss, class_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Implementation using tf.keras.applications (https://www.tensorflow.org/api_docs/python/tf/keras/applications)\n",
    "# & Keras Functional API (https://www.tensorflow.org/guide/keras/functional)\n",
    "class YOLOv1(tf.keras.Model):\n",
    "  def __init__(self, input_height, input_width, cell_size, boxes_per_cell, num_classes):\n",
    "    super(YOLOv1, self).__init__()\n",
    "    base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet', input_shape=(input_height, input_width, 3))\n",
    "    base_model.trainable = True\n",
    "    x = base_model.output\n",
    "\n",
    "    # Global Average Pooling\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    output = tf.keras.layers.Dense(cell_size * cell_size * (num_classes + (boxes_per_cell*5)), activation=None)(x)\n",
    "    model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
    "    self.model = model\n",
    "    # print model structure\n",
    "    self.model.summary()\n",
    "\n",
    "  def call(self, x):\n",
    "    return self.model(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yolo_loss'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-12-c576b84852d3>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;31m# from dataset import process_each_ground_truth\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;31m# from utils import draw_bounding_box_and_label_info, generate_color, find_max_confidence_bounding_box, yolo_format_to_bounding_box_dict\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0myolo_loss\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     15\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mYOLOv1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mprocess_each_ground_truth\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'yolo_loss'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "from absl import flags\n",
    "from absl import app\n",
    "\n",
    "# from loss import yolo_loss\n",
    "# from model import YOLOv1\n",
    "# from dataset import process_each_ground_truth\n",
    "# from utils import draw_bounding_box_and_label_info, generate_color, find_max_confidence_bounding_box, yolo_format_to_bounding_box_dict\n",
    "import yolo_loss\n",
    "import YOLOv1\n",
    "import process_each_ground_truth\n",
    "import draw_bounding_box_and_label_info, generate_color, find_max_confidence_bounding_box, yolo_format_to_bounding_box_dict\n",
    "\n",
    "\n",
    "\n",
    "# set cat label dictionary\n",
    "cat_label_dict = {\n",
    "  0: \"cat\"\n",
    "}\n",
    "cat_class_to_label_dict = {v: k for k, v in cat_label_dict.items()}\n",
    "\n",
    "flags.DEFINE_string('checkpoint_path', default='saved_model', help='path to a directory to save model checkpoints during training')\n",
    "flags.DEFINE_integer('save_checkpoint_steps', default=50, help='period at which checkpoints are saved (defaults to every 50 steps)')\n",
    "flags.DEFINE_string('tensorboard_log_path', default='tensorboard_log', help='path to a directory to save tensorboard log')\n",
    "flags.DEFINE_integer('validation_steps', default=50, help='period at which test prediction result and save image')\n",
    "flags.DEFINE_integer('num_epochs', default=135, help='training epochs') # original paper : 135 epoch\n",
    "flags.DEFINE_float('init_learning_rate', default=0.0001, help='initial learning rate') # original paper : 0.001 (1epoch) -> 0.01 (75epoch) -> 0.001 (30epoch) -> 0.0001 (30epoch)\n",
    "flags.DEFINE_float('lr_decay_rate', default=0.5, help='decay rate for the learning rate')\n",
    "flags.DEFINE_integer('lr_decay_steps', default=2000, help='number of steps after which the learning rate is decayed by decay rate')\n",
    "flags.DEFINE_integer('num_visualize_image', default=8, help='number of visualize image for validation')\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# set configuration value\n",
    "batch_size = 24 # original paper : 64\n",
    "input_width = 224 # original paper : 448\n",
    "input_height = 224 # original paper : 448\n",
    "cell_size = 7\n",
    "num_classes = 1 # original paper : 20\n",
    "boxes_per_cell = 2\n",
    "\n",
    "# set color_list for drawing\n",
    "color_list = generate_color(num_classes)\n",
    "\n",
    "# set loss function coefficients\n",
    "coord_scale = 10 # original paper : 5\n",
    "class_scale = 0.1  # original paper : 1\n",
    "object_scale = 1\n",
    "noobject_scale = 0.5\n",
    "\n",
    "# load pascal voc2007/voc2012 dataset using tfds\n",
    "# notice : voc2007 train data(=2,501 images) for test & voc2007 test data(=4,952 images) for training\n",
    "voc2007_test_split_data = tfds.load(\"voc/2007\", split=tfds.Split.TEST, batch_size=1)\n",
    "voc2012_train_split_data = tfds.load(\"voc/2012\", split=tfds.Split.TRAIN, batch_size=1)\n",
    "voc2012_validation_split_data = tfds.load(\"voc/2012\", split=tfds.Split.VALIDATION, batch_size=1)\n",
    "train_data = voc2007_test_split_data.concatenate(voc2012_train_split_data).concatenate(voc2012_validation_split_data)\n",
    "\n",
    "# set validation data\n",
    "voc2007_validation_split_data = tfds.load(\"voc/2007\", split=tfds.Split.VALIDATION, batch_size=1)\n",
    "validation_data = voc2007_validation_split_data\n",
    "\n",
    "# label 7 : cat\n",
    "# Reference : https://stackoverflow.com/questions/55731774/filter-dataset-to-get-just-images-from-specific-class\n",
    "def predicate(x, allowed_labels=tf.constant([7.0])):\n",
    "  label = x['objects']['label']\n",
    "  isallowed = tf.equal(allowed_labels, tf.cast(label, tf.float32))\n",
    "  reduced = tf.reduce_sum(tf.cast(isallowed, tf.float32))\n",
    "\n",
    "  return tf.greater(reduced, tf.constant(0.))\n",
    "\n",
    "train_data = train_data.filter(predicate)\n",
    "train_data = train_data.padded_batch(batch_size)\n",
    "\n",
    "validation_data = validation_data.filter(predicate)\n",
    "validation_data = validation_data.padded_batch(batch_size)\n",
    "\n",
    "\n",
    "def reshape_yolo_preds(preds):\n",
    "  # flatten vector -> cell_size x cell_size x (num_classes + 5 * boxes_per_cell)\n",
    "  return tf.reshape(preds, [tf.shape(preds)[0], cell_size, cell_size, num_classes + 5 * boxes_per_cell])\n",
    "\n",
    "\n",
    "def calculate_loss(model, batch_image, batch_bbox, batch_labels):\n",
    "  total_loss = 0.0\n",
    "  coord_loss = 0.0\n",
    "  object_loss = 0.0\n",
    "  noobject_loss = 0.0\n",
    "  class_loss = 0.0\n",
    "  for batch_index in range(batch_image.shape[0]):\n",
    "    image, labels, object_num = process_each_ground_truth(batch_image[batch_index], batch_bbox[batch_index], batch_labels[batch_index], input_width, input_height)\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "\n",
    "    predict = model(image)\n",
    "    predict = reshape_yolo_preds(predict)\n",
    "\n",
    "    for object_num_index in range(object_num):\n",
    "      each_object_total_loss, each_object_coord_loss, each_object_object_loss, each_object_noobject_loss, each_object_class_loss = yolo_loss(predict[0],\n",
    "                                   labels,\n",
    "                                   object_num_index,\n",
    "                                   num_classes,\n",
    "                                   boxes_per_cell,\n",
    "                                   cell_size,\n",
    "                                   input_width,\n",
    "                                   input_height,\n",
    "                                   coord_scale,\n",
    "                                   object_scale,\n",
    "                                   noobject_scale,\n",
    "                                   class_scale\n",
    "                                   )\n",
    "\n",
    "      total_loss = total_loss + each_object_total_loss\n",
    "      coord_loss = coord_loss + each_object_coord_loss\n",
    "      object_loss = object_loss + each_object_object_loss\n",
    "      noobject_loss = noobject_loss + each_object_noobject_loss\n",
    "      class_loss = class_loss + each_object_class_loss\n",
    "\n",
    "  return total_loss, coord_loss, object_loss, noobject_loss, class_loss\n",
    "\n",
    "\n",
    "def train_step(optimizer, model, batch_image, batch_bbox, batch_labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    total_loss, coord_loss, object_loss, noobject_loss, class_loss = calculate_loss(model, batch_image, batch_bbox, batch_labels)\n",
    "  gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  return total_loss, coord_loss, object_loss, noobject_loss, class_loss\n",
    "\n",
    "\n",
    "def save_validation_result(model, ckpt, validation_summary_writer, num_visualize_image):\n",
    "  total_validation_total_loss = 0.0\n",
    "  total_validation_coord_loss = 0.0\n",
    "  total_validation_object_loss = 0.0\n",
    "  total_validation_noobject_loss = 0.0\n",
    "  total_validation_class_loss = 0.0\n",
    "  for iter, features in enumerate(validation_data):\n",
    "    batch_validation_image = features['image']\n",
    "    batch_validation_bbox = features['objects']['bbox']\n",
    "    batch_validation_labels = features['objects']['label']\n",
    "\n",
    "    batch_validation_image = tf.squeeze(batch_validation_image, axis=1)\n",
    "    batch_validation_bbox = tf.squeeze(batch_validation_bbox, axis=1)\n",
    "    batch_validation_labels = tf.squeeze(batch_validation_labels, axis=1)\n",
    "\n",
    "    validation_total_loss, validation_coord_loss, validation_object_loss, validation_noobject_loss, validation_class_loss = calculate_loss(model, batch_validation_image, batch_validation_bbox, batch_validation_labels)\n",
    "\n",
    "    total_validation_total_loss = total_validation_total_loss + validation_total_loss\n",
    "    total_validation_coord_loss = total_validation_coord_loss + validation_coord_loss\n",
    "    total_validation_object_loss = total_validation_object_loss + validation_object_loss\n",
    "    total_validation_noobject_loss = total_validation_noobject_loss + validation_noobject_loss\n",
    "    total_validation_class_loss = total_validation_class_loss + validation_class_loss\n",
    "\n",
    "  # save validation tensorboard log\n",
    "  with validation_summary_writer.as_default():\n",
    "    tf.summary.scalar('total_validation_total_loss', total_validation_total_loss, step=int(ckpt.step))\n",
    "    tf.summary.scalar('total_validation_coord_loss', total_validation_coord_loss, step=int(ckpt.step))\n",
    "    tf.summary.scalar('total_validation_object_loss ', total_validation_object_loss, step=int(ckpt.step))\n",
    "    tf.summary.scalar('total_validation_noobject_loss ', total_validation_noobject_loss, step=int(ckpt.step))\n",
    "    tf.summary.scalar('total_validation_class_loss ', total_validation_class_loss, step=int(ckpt.step))\n",
    "\n",
    "  # save validation test image\n",
    "  for validation_image_index in range(num_visualize_image):\n",
    "    random_idx = random.randint(0, batch_validation_image.shape[0] - 1)\n",
    "    image, labels, object_num = process_each_ground_truth(batch_validation_image[random_idx], batch_validation_bbox[random_idx],\n",
    "                                                          batch_validation_labels[random_idx], input_width, input_height)\n",
    "\n",
    "    drawing_image = image\n",
    "\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    predict = model(image)\n",
    "    predict = reshape_yolo_preds(predict)\n",
    "\n",
    "    # parse prediction\n",
    "    predict_boxes = predict[0, :, :, num_classes + boxes_per_cell:]\n",
    "    predict_boxes = tf.reshape(predict_boxes, [cell_size, cell_size, boxes_per_cell, 4])\n",
    "\n",
    "    confidence_boxes = predict[0, :, :, num_classes:num_classes + boxes_per_cell]\n",
    "    confidence_boxes = tf.reshape(confidence_boxes, [cell_size, cell_size, boxes_per_cell, 1])\n",
    "\n",
    "    class_prediction = predict[0, :, :, 0:num_classes]\n",
    "    class_prediction = tf.argmax(class_prediction, axis=2)\n",
    "\n",
    "    # make prediction bounding box list\n",
    "    bounding_box_info_list = []\n",
    "    for i in range(cell_size):\n",
    "      for j in range(cell_size):\n",
    "        for k in range(boxes_per_cell):\n",
    "          pred_xcenter = predict_boxes[i][j][k][0]\n",
    "          pred_ycenter = predict_boxes[i][j][k][1]\n",
    "          pred_box_w = tf.minimum(input_width * 1.0, tf.maximum(0.0, predict_boxes[i][j][k][2]))\n",
    "          pred_box_h = tf.minimum(input_height * 1.0, tf.maximum(0.0, predict_boxes[i][j][k][3]))\n",
    "\n",
    "          pred_class_name = cat_label_dict[class_prediction[i][j].numpy()]\n",
    "          pred_confidence = confidence_boxes[i][j][k].numpy()[0]\n",
    "\n",
    "          # add bounding box dict list\n",
    "          bounding_box_info_list.append(yolo_format_to_bounding_box_dict(pred_xcenter, pred_ycenter, pred_box_w, pred_box_h, pred_class_name, pred_confidence))\n",
    "\n",
    "    # make ground truth bounding box list\n",
    "    ground_truth_bounding_box_info_list = []\n",
    "    for each_object_num in range(object_num):\n",
    "      labels = np.array(labels)\n",
    "      labels = labels.astype('float32')\n",
    "      label = labels[each_object_num, :]\n",
    "      xcenter = label[0]\n",
    "      ycenter = label[1]\n",
    "      box_w = label[2]\n",
    "      box_h = label[3]\n",
    "      class_label = label[4]\n",
    "\n",
    "      # label 7 : cat\n",
    "      # add ground-turth bounding box dict list\n",
    "      if class_label == 7:\n",
    "        ground_truth_bounding_box_info_list.append(\n",
    "          yolo_format_to_bounding_box_dict(xcenter, ycenter, box_w, box_h, 'cat', 1.0))\n",
    "\n",
    "    ground_truth_drawing_image = drawing_image.copy()\n",
    "    # draw ground-truth image\n",
    "    for ground_truth_bounding_box_info in ground_truth_bounding_box_info_list:\n",
    "      draw_bounding_box_and_label_info(\n",
    "        ground_truth_drawing_image,\n",
    "        ground_truth_bounding_box_info['left'],\n",
    "        ground_truth_bounding_box_info['top'],\n",
    "        ground_truth_bounding_box_info['right'],\n",
    "        ground_truth_bounding_box_info['bottom'],\n",
    "        ground_truth_bounding_box_info['class_name'],\n",
    "        ground_truth_bounding_box_info['confidence'],\n",
    "        color_list[cat_class_to_label_dict[ground_truth_bounding_box_info['class_name']]]\n",
    "      )\n",
    "\n",
    "    # find one max confidence bounding box\n",
    "    max_confidence_bounding_box = find_max_confidence_bounding_box(bounding_box_info_list)\n",
    "\n",
    "    # draw prediction\n",
    "    draw_bounding_box_and_label_info(\n",
    "      drawing_image,\n",
    "      max_confidence_bounding_box['left'],\n",
    "      max_confidence_bounding_box['top'],\n",
    "      max_confidence_bounding_box['right'],\n",
    "      max_confidence_bounding_box['bottom'],\n",
    "      max_confidence_bounding_box['class_name'],\n",
    "      max_confidence_bounding_box['confidence'],\n",
    "      color_list[cat_class_to_label_dict[max_confidence_bounding_box['class_name']]]\n",
    "    )\n",
    "\n",
    "    # left : ground-truth, right : prediction\n",
    "    drawing_image = np.concatenate((ground_truth_drawing_image, drawing_image), axis=1)\n",
    "    drawing_image = drawing_image / 255\n",
    "    drawing_image = tf.expand_dims(drawing_image, axis=0)\n",
    "\n",
    "    # save tensorboard log\n",
    "    with validation_summary_writer.as_default():\n",
    "      tf.summary.image('validation_image_'+str(validation_image_index), drawing_image, step=int(ckpt.step))\n",
    "\n",
    "def main(_):\n",
    "  # set learning rate decay\n",
    "  lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    FLAGS.init_learning_rate,\n",
    "    decay_steps=FLAGS.lr_decay_steps,\n",
    "    decay_rate=FLAGS.lr_decay_rate,\n",
    "    staircase=True)\n",
    "\n",
    "  # set optimizer\n",
    "  optimizer = tf.optimizers.Adam(lr_schedule)  # original paper : SGD with momentum 0.9, decay 0.0005\n",
    "\n",
    "  # check if checkpoint path exists\n",
    "  if not os.path.exists(FLAGS.checkpoint_path):\n",
    "    os.mkdir(FLAGS.checkpoint_path)\n",
    "\n",
    "  # create YOLO model\n",
    "  YOLOv1_model = YOLOv1(input_height, input_width, cell_size, boxes_per_cell, num_classes)\n",
    "\n",
    "  # set checkpoint manager\n",
    "  ckpt = tf.train.Checkpoint(step=tf.Variable(0), model=YOLOv1_model)\n",
    "  ckpt_manager = tf.train.CheckpointManager(ckpt,\n",
    "                                            directory=FLAGS.checkpoint_path,\n",
    "                                            max_to_keep=None)\n",
    "  latest_ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_path)\n",
    "\n",
    "  # restore latest checkpoint\n",
    "  if latest_ckpt:\n",
    "    ckpt.restore(latest_ckpt)\n",
    "    print('global_step : {}, checkpoint is restored!'.format(int(ckpt.step)))\n",
    "\n",
    "  # set tensorboard log\n",
    "  train_summary_writer = tf.summary.create_file_writer(FLAGS.tensorboard_log_path +  '/train')\n",
    "  validation_summary_writer = tf.summary.create_file_writer(FLAGS.tensorboard_log_path +  '/validation')\n",
    "\n",
    "  for epoch in range(FLAGS.num_epochs):\n",
    "    num_batch = len(list(train_data))\n",
    "    for iter, features in enumerate(train_data):\n",
    "      batch_image = features['image']\n",
    "      batch_bbox = features['objects']['bbox']\n",
    "      batch_labels = features['objects']['label']\n",
    "\n",
    "      batch_image = tf.squeeze(batch_image, axis=1)\n",
    "      batch_bbox = tf.squeeze(batch_bbox, axis=1)\n",
    "      batch_labels = tf.squeeze(batch_labels, axis=1)\n",
    "\n",
    "      # run optimization and calculate loss\n",
    "      total_loss, coord_loss, object_loss, noobject_loss, class_loss = train_step(optimizer, YOLOv1_model, batch_image, batch_bbox, batch_labels)\n",
    "\n",
    "      # print log\n",
    "      print(\"Epoch: %d, Iter: %d/%d, Loss: %f\" % ((epoch+1), (iter+1), num_batch, total_loss.numpy()))\n",
    "\n",
    "      # save tensorboard log\n",
    "      with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('learning_rate ', optimizer.lr(ckpt.step).numpy(), step=int(ckpt.step))\n",
    "        tf.summary.scalar('total_loss', total_loss, step=int(ckpt.step))\n",
    "        tf.summary.scalar('coord_loss', coord_loss, step=int(ckpt.step))\n",
    "        tf.summary.scalar('object_loss ', object_loss, step=int(ckpt.step))\n",
    "        tf.summary.scalar('noobject_loss ', noobject_loss, step=int(ckpt.step))\n",
    "        tf.summary.scalar('class_loss ', class_loss, step=int(ckpt.step))\n",
    "\n",
    "      # save checkpoint\n",
    "      if ckpt.step % FLAGS.save_checkpoint_steps == 0:\n",
    "        # save checkpoint\n",
    "        ckpt_manager.save(checkpoint_number=ckpt.step)\n",
    "        print('global_step : {}, checkpoint is saved!'.format(int(ckpt.step)))\n",
    "\n",
    "      ckpt.step.assign_add(1)\n",
    "\n",
    "      # occasionally check validation data and save tensorboard log\n",
    "      if iter % FLAGS.validation_steps == 0:\n",
    "        save_validation_result(YOLOv1_model, ckpt, validation_summary_writer, FLAGS.num_visualize_image)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  app.run(main)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-13-0cda661092d8>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mabsl\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mapp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mmodel\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mYOLOv1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mdataset\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mprocess_each_ground_truth\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mutils\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdraw_bounding_box_and_label_info\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgenerate_color\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfind_max_confidence_bounding_box\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0myolo_format_to_bounding_box_dict\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from absl import flags\n",
    "from absl import app\n",
    "\n",
    "from model import YOLOv1\n",
    "from dataset import process_each_ground_truth\n",
    "from utils import draw_bounding_box_and_label_info, generate_color, find_max_confidence_bounding_box, yolo_format_to_bounding_box_dict\n",
    "\n",
    "# set voc label dictionary\n",
    "cat_label_to_class_dict = {\n",
    "  0:\"cat\"\n",
    "}\n",
    "cat_class_to_label_dict = {v: k for k, v in cat_label_to_class_dict.items()}\n",
    "\n",
    "flags.DEFINE_string('checkpoint_path', default='saved_model', help='path to a directory to restore checkpoint file')\n",
    "flags.DEFINE_string('test_dir', default='test_result', help='directory which test prediction result saved')\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# set configuration value\n",
    "batch_size = 1\n",
    "input_width = 224 # original paper : 448\n",
    "input_height = 224 # original paper : 448\n",
    "cell_size = 7\n",
    "num_classes = 1 # original paper : 20\n",
    "boxes_per_cell = 2\n",
    "\n",
    "# set color_list for drawing\n",
    "color_list = generate_color(num_classes)\n",
    "\n",
    "# load pascal voc 2007 dataset using tfds\n",
    "# notice : voc2007 train data(=2,501 images) for test & voc2007 test data(=4,952 images) for training\n",
    "voc2007_train_split_data = tfds.load(\"voc/2007\", split=tfds.Split.TRAIN, batch_size=1)\n",
    "test_data = voc2007_train_split_data\n",
    "\n",
    "# label 7 : cat\n",
    "def predicate(x, allowed_labels=tf.constant([7.0])):\n",
    "  label = x['objects']['label']\n",
    "  isallowed = tf.equal(allowed_labels, tf.cast(label, tf.float32))\n",
    "  reduced = tf.reduce_sum(tf.cast(isallowed, tf.float32))\n",
    "\n",
    "  return tf.greater(reduced, tf.constant(0.))\n",
    "\n",
    "test_data = test_data.filter(predicate)\n",
    "test_data = test_data.padded_batch(batch_size)\n",
    "\n",
    "\n",
    "def reshape_yolo_preds(preds):\n",
    "  # 7x7x(20+5*2) = 1470 -> 7x7x30\n",
    "  return tf.reshape(preds, [tf.shape(preds)[0], cell_size, cell_size, num_classes + 5 * boxes_per_cell])\n",
    "\n",
    "\n",
    "def main(_):\n",
    "  # check if checkpoint path exists\n",
    "  if not os.path.exists(FLAGS.checkpoint_path):\n",
    "    print('checkpoint file is not exists!')\n",
    "    exit()\n",
    "\n",
    "  # create YOLO model\n",
    "  YOLOv1_model = YOLOv1(input_height, input_width, cell_size, boxes_per_cell, num_classes)\n",
    "\n",
    "  # set checkpoint manager\n",
    "  ckpt = tf.train.Checkpoint(step=tf.Variable(0), model=YOLOv1_model)\n",
    "  latest_ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_path)\n",
    "\n",
    "  # restore latest checkpoint\n",
    "  if latest_ckpt:\n",
    "    ckpt.restore(latest_ckpt)\n",
    "    print('global_step : {}, checkpoint is restored!'.format(int(ckpt.step)))\n",
    "\n",
    "  num_images = len(list(test_data))  # batch_size = 1\n",
    "  print('total test image :', num_images)\n",
    "  for image_num, features in enumerate(test_data):\n",
    "    batch_image = features['image']\n",
    "    batch_bbox = features['objects']['bbox']\n",
    "    batch_labels = features['objects']['label']\n",
    "\n",
    "    batch_image = tf.squeeze(batch_image, axis=1)\n",
    "    batch_bbox = tf.squeeze(batch_bbox, axis=1)\n",
    "    batch_labels = tf.squeeze(batch_labels, axis=1)\n",
    "\n",
    "    image, labels, object_num = process_each_ground_truth(batch_image[0], batch_bbox[0], batch_labels[0], input_width, input_height)\n",
    "\n",
    "    drawing_image = image\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "\n",
    "    predict = YOLOv1_model(image)\n",
    "    predict = reshape_yolo_preds(predict)\n",
    "\n",
    "    predict_boxes = predict[0, :, :, num_classes + boxes_per_cell:]\n",
    "    predict_boxes = tf.reshape(predict_boxes, [cell_size, cell_size, boxes_per_cell, 4])\n",
    "\n",
    "    confidence_boxes = predict[0, :, :, num_classes:num_classes + boxes_per_cell]\n",
    "    confidence_boxes = tf.reshape(confidence_boxes, [cell_size, cell_size, boxes_per_cell, 1])\n",
    "\n",
    "    class_prediction = predict[0, :, :, 0:num_classes]\n",
    "    class_prediction = tf.argmax(class_prediction, axis=2)\n",
    "\n",
    "    bounding_box_info_list = []\n",
    "    for i in range(cell_size):\n",
    "      for j in range(cell_size):\n",
    "        for k in range(boxes_per_cell):\n",
    "          pred_xcenter = predict_boxes[i][j][k][0]\n",
    "          pred_ycenter = predict_boxes[i][j][k][1]\n",
    "          pred_box_w = tf.minimum(input_width * 1.0, tf.maximum(0.0, predict_boxes[i][j][k][2]))\n",
    "          pred_box_h = tf.minimum(input_height * 1.0, tf.maximum(0.0, predict_boxes[i][j][k][3]))\n",
    "\n",
    "          pred_class_name = cat_label_to_class_dict[class_prediction[i][j].numpy()]\n",
    "          pred_confidence = confidence_boxes[i][j][k].numpy()\n",
    "\n",
    "          # add bounding box dict list\n",
    "          bounding_box_info_list.append(yolo_format_to_bounding_box_dict(pred_xcenter, pred_ycenter, pred_box_w, pred_box_h, pred_class_name, pred_confidence))\n",
    "\n",
    "    # make ground truth bounding box list\n",
    "    ground_truth_bounding_box_info_list = []\n",
    "    for each_object_num in range(object_num):\n",
    "      labels = np.array(labels)\n",
    "      labels = labels.astype('float32')\n",
    "      label = labels[each_object_num, :]\n",
    "      xcenter = label[0]\n",
    "      ycenter = label[1]\n",
    "      box_w = label[2]\n",
    "      box_h = label[3]\n",
    "      class_label = label[4]\n",
    "\n",
    "      # label 7 : cat\n",
    "      # add ground-turth bounding box dict list\n",
    "      if class_label == 7:\n",
    "        ground_truth_bounding_box_info_list.append(\n",
    "          yolo_format_to_bounding_box_dict(xcenter, ycenter, box_w, box_h, 'cat', 1.0))\n",
    "\n",
    "    ground_truth_drawing_image = drawing_image.copy()\n",
    "    # draw ground-truth image\n",
    "    for ground_truth_bounding_box_info in ground_truth_bounding_box_info_list:\n",
    "      draw_bounding_box_and_label_info(\n",
    "        ground_truth_drawing_image,\n",
    "        ground_truth_bounding_box_info['left'],\n",
    "        ground_truth_bounding_box_info['top'],\n",
    "        ground_truth_bounding_box_info['right'],\n",
    "        ground_truth_bounding_box_info['bottom'],\n",
    "        ground_truth_bounding_box_info['class_name'],\n",
    "        ground_truth_bounding_box_info['confidence'],\n",
    "        color_list[cat_class_to_label_dict[ground_truth_bounding_box_info['class_name']]]\n",
    "      )\n",
    "\n",
    "    # find one max confidence bounding box\n",
    "    max_confidence_bounding_box = find_max_confidence_bounding_box(bounding_box_info_list)\n",
    "\n",
    "    # draw prediction\n",
    "    draw_bounding_box_and_label_info(\n",
    "      drawing_image,\n",
    "      max_confidence_bounding_box['left'],\n",
    "      max_confidence_bounding_box['top'],\n",
    "      max_confidence_bounding_box['right'],\n",
    "      max_confidence_bounding_box['bottom'],\n",
    "      max_confidence_bounding_box['class_name'],\n",
    "      max_confidence_bounding_box['confidence'],\n",
    "      color_list[cat_class_to_label_dict[max_confidence_bounding_box['class_name']]]\n",
    "    )\n",
    "\n",
    "    # left : ground-truth, right : prediction\n",
    "    drawing_image = np.concatenate((ground_truth_drawing_image, drawing_image), axis=1)\n",
    "\n",
    "    # save test prediction result to png file\n",
    "    if not os.path.exists(os.path.join(os.getcwd(), FLAGS.test_dir)):\n",
    "      os.mkdir(os.path.join(os.getcwd(), FLAGS.test_dir))\n",
    "    output_image_name = os.path.join(os.getcwd(), FLAGS.test_dir, str(int(image_num)) +'_result.png')\n",
    "    cv2.imwrite(output_image_name, cv2.cvtColor(drawing_image, cv2.COLOR_BGR2RGB))\n",
    "    print(output_image_name + ' saved!')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  app.run(main)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-feb1f727",
   "language": "python",
   "display_name": "PyCharm (code)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}