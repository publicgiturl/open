{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4378504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ede988c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow==2.4.0 tensorflow-gpu==2.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b05f17",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1177f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'F:/Dacon/data/'\n",
    "train_csv = pd.read_csv('F:/Dacon/data/train.csv')\n",
    "test_csv = pd.read_csv('F:/Dacon/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87015347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     img_id              input_img              label_img\n0     10000  train_input_10000.png  train_label_10000.png\n1     10001  train_input_10001.png  train_label_10001.png\n2     10002  train_input_10002.png  train_label_10002.png\n3     10003  train_input_10003.png  train_label_10003.png\n4     10004  train_input_10004.png  train_label_10004.png\n..      ...                    ...                    ...\n617   10617  train_input_10617.png  train_label_10617.png\n618   10618  train_input_10618.png  train_label_10618.png\n619   10619  train_input_10619.png  train_label_10619.png\n620   10620  train_input_10620.png  train_label_10620.png\n621   10621  train_input_10621.png  train_label_10621.png\n\n[622 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>img_id</th>\n      <th>input_img</th>\n      <th>label_img</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10000</td>\n      <td>train_input_10000.png</td>\n      <td>train_label_10000.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10001</td>\n      <td>train_input_10001.png</td>\n      <td>train_label_10001.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10002</td>\n      <td>train_input_10002.png</td>\n      <td>train_label_10002.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10003</td>\n      <td>train_input_10003.png</td>\n      <td>train_label_10003.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10004</td>\n      <td>train_input_10004.png</td>\n      <td>train_label_10004.png</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>617</th>\n      <td>10617</td>\n      <td>train_input_10617.png</td>\n      <td>train_label_10617.png</td>\n    </tr>\n    <tr>\n      <th>618</th>\n      <td>10618</td>\n      <td>train_input_10618.png</td>\n      <td>train_label_10618.png</td>\n    </tr>\n    <tr>\n      <th>619</th>\n      <td>10619</td>\n      <td>train_input_10619.png</td>\n      <td>train_label_10619.png</td>\n    </tr>\n    <tr>\n      <th>620</th>\n      <td>10620</td>\n      <td>train_input_10620.png</td>\n      <td>train_label_10620.png</td>\n    </tr>\n    <tr>\n      <th>621</th>\n      <td>10621</td>\n      <td>train_input_10621.png</td>\n      <td>train_label_10621.png</td>\n    </tr>\n  </tbody>\n</table>\n<p>622 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "    img_id             input_img submission_name\n0    20000  test_input_20000.png  test_20000.png\n1    20001  test_input_20001.png  test_20001.png\n2    20002  test_input_20002.png  test_20002.png\n3    20003  test_input_20003.png  test_20003.png\n4    20004  test_input_20004.png  test_20004.png\n5    20005  test_input_20005.png  test_20005.png\n6    20006  test_input_20006.png  test_20006.png\n7    20007  test_input_20007.png  test_20007.png\n8    20008  test_input_20008.png  test_20008.png\n9    20009  test_input_20009.png  test_20009.png\n10   20010  test_input_20010.png  test_20010.png\n11   20011  test_input_20011.png  test_20011.png\n12   20012  test_input_20012.png  test_20012.png\n13   20013  test_input_20013.png  test_20013.png\n14   20014  test_input_20014.png  test_20014.png\n15   20015  test_input_20015.png  test_20015.png\n16   20016  test_input_20016.png  test_20016.png\n17   20017  test_input_20017.png  test_20017.png\n18   20018  test_input_20018.png  test_20018.png\n19   20019  test_input_20019.png  test_20019.png",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>img_id</th>\n      <th>input_img</th>\n      <th>submission_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20000</td>\n      <td>test_input_20000.png</td>\n      <td>test_20000.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20001</td>\n      <td>test_input_20001.png</td>\n      <td>test_20001.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20002</td>\n      <td>test_input_20002.png</td>\n      <td>test_20002.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20003</td>\n      <td>test_input_20003.png</td>\n      <td>test_20003.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20004</td>\n      <td>test_input_20004.png</td>\n      <td>test_20004.png</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>20005</td>\n      <td>test_input_20005.png</td>\n      <td>test_20005.png</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>20006</td>\n      <td>test_input_20006.png</td>\n      <td>test_20006.png</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>20007</td>\n      <td>test_input_20007.png</td>\n      <td>test_20007.png</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>20008</td>\n      <td>test_input_20008.png</td>\n      <td>test_20008.png</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>20009</td>\n      <td>test_input_20009.png</td>\n      <td>test_20009.png</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>20010</td>\n      <td>test_input_20010.png</td>\n      <td>test_20010.png</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>20011</td>\n      <td>test_input_20011.png</td>\n      <td>test_20011.png</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>20012</td>\n      <td>test_input_20012.png</td>\n      <td>test_20012.png</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>20013</td>\n      <td>test_input_20013.png</td>\n      <td>test_20013.png</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>20014</td>\n      <td>test_input_20014.png</td>\n      <td>test_20014.png</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>20015</td>\n      <td>test_input_20015.png</td>\n      <td>test_20015.png</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>20016</td>\n      <td>test_input_20016.png</td>\n      <td>test_20016.png</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>20017</td>\n      <td>test_input_20017.png</td>\n      <td>test_20017.png</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>20018</td>\n      <td>test_input_20018.png</td>\n      <td>test_20018.png</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>20019</td>\n      <td>test_input_20019.png</td>\n      <td>test_20019.png</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_csv)\n",
    "display(test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eec61154",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = path+'train_input_img/'+train_csv['input_img'], path+'train_label_img/'+train_csv['label_img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a2fb6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "((622,), (622,))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e5e3c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a27b57e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "((435,), (435,), (187,), (187,))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6521cbf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "con_train_x = train_x.to_numpy()\n",
    "con_test_x = test_x.to_numpy()\n",
    "con_train_y = train_y.to_numpy()\n",
    "con_test_y = test_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "566a11b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'con_train_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-6-e91d94a3fc42>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfor\u001B[0m \u001B[0minput_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabel_path\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcon_train_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcon_train_y\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m     \u001B[0minp_img\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m     \u001B[0mtarg_img\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabel_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfigure\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfigsize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m15\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0minp_img\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcvtColor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minp_img\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mCOLOR_BGR2RGB\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'con_train_x' is not defined"
     ]
    }
   ],
   "source": [
    "for input_path, label_path in zip(con_train_x, con_train_y):\n",
    "    inp_img = cv2.imread(input_path)\n",
    "    targ_img = cv2.imread(label_path)\n",
    "    plt.figure(figsize=(15,10))\n",
    "    inp_img = cv2.cvtColor(inp_img, cv2.COLOR_BGR2RGB)\n",
    "    targ_img = cv2.cvtColor(targ_img, cv2.COLOR_BGR2RGB)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(inp_img)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(targ_img)\n",
    "    plt.show()\n",
    "    print(input_path, label_path, '\\n')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7074cd2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### HyperParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4184c4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "img_size = 256\n",
    "#weights = None\n",
    "weights = 'imagenet'\n",
    "learning_rate = 1e-5\n",
    "EPOCHS = 5\n",
    "dropout_rate = 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34827cee",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def cut_img(img_path_list, save_path, stride):\n",
    "    os.makedirs(f'{save_path}{img_size}', exist_ok=True)\n",
    "    num = 0\n",
    "    for path in tqdm(img_path_list):\n",
    "        img = cv2.imread(path)\n",
    "        for top in range(0, img.shape[0], stride):\n",
    "            for left in range(0, img.shape[1], stride):\n",
    "                piece = np.zeros([img_size, img_size, 3], np.uint8)\n",
    "                temp = img[top:top+img_size, left:left+img_size, :]\n",
    "                piece[:temp.shape[0], :temp.shape[1], :] = temp\n",
    "                np.save(f'{save_path}{img_size}/{num}.npy', piece)\n",
    "                num+=1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 435/435 [02:14<00:00,  3.23it/s]\n",
      "100%|██████████| 187/187 [00:52<00:00,  3.59it/s]\n",
      "100%|██████████| 435/435 [02:25<00:00,  3.00it/s]\n",
      "100%|██████████| 187/187 [00:48<00:00,  3.87it/s]\n"
     ]
    }
   ],
   "source": [
    "cut_img(train_x, path+'train_input_img/', 128)\n",
    "cut_img(test_x, path+'train_input_img/', 128)\n",
    "cut_img(train_y, path+'train_label_img/', 128)\n",
    "cut_img(test_y, path+'train_label_img/', 128)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_inp_files = glob(path+f'train_input_img/{img_size}/*.npy')\n",
    "train_targ_files = glob(path+f'train_label_img/{img_size}/*.npy')\n",
    "\n",
    "val_inp_files = glob(path+f'train_input_img/{img_size}/*.npy')\n",
    "val_targ_files = glob(path+f'train_label_img/{img_size}/*.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_inp_files, train_targ_files = shuffle(train_inp_files, train_targ_files, random_state=42)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(127920, 127920, 127920, 127920)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_inp_files), len(val_inp_files), len(train_targ_files), len(val_targ_files)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data_Set\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def train_map_func(inp_path, targ_path):\n",
    "    inp = np.load(inp_path)\n",
    "    inp = inp.astype(np.float32)/255\n",
    "    targ = np.load(targ_path)\n",
    "    targ = targ.astype(np.float32)/255\n",
    "    inp, targ = augmentation(inp, targ)\n",
    "\n",
    "    return inp, targ\n",
    "\n",
    "def val_map_func(inp_path, targ_path):\n",
    "    inp = np.load(inp_path)\n",
    "    inp = inp.astype(np.float32)/255\n",
    "    targ = np.load(targ_path)\n",
    "    targ = targ.astype(np.float32)/255\n",
    "    return inp, targ\n",
    "\n",
    "def augmentation(inp, targ):\n",
    "    inp, targ = random_rot(inp, targ)\n",
    "    inp, targ = random_flip(inp, targ)\n",
    "\n",
    "    return inp, targ\n",
    "\n",
    "def random_rot(inp, targ):\n",
    "    k = np.random.randint(4)\n",
    "    inp = np.rot90(inp, k)\n",
    "    targ = np.rot90(targ, k)\n",
    "\n",
    "    return inp, targ\n",
    "\n",
    "def random_flip(inp, targ):\n",
    "    f = np.random.randint(2)\n",
    "    if f == 0:\n",
    "        inp = np.fliplr(inp)\n",
    "        targ = np.fliplr(targ)\n",
    "\n",
    "    return inp, targ\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_inp_files, train_targ_files))\n",
    "train_dataset = train_dataset.map(lambda item1, item2: tf.numpy_function(train_map_func, [item1, item2], [tf.float32, tf.float32]), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_inp_files, val_targ_files))\n",
    "val_dataset = val_dataset.map(lambda item1, item2: tf.numpy_function(val_map_func, [item1, item2], [tf.float32, tf.float32]), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(TensorShape([8, 256, 256, 3]),\n TensorShape([8, 256, 256, 3]),\n TensorShape([8, 256, 256, 3]),\n TensorShape([8, 256, 256, 3]))"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))[0].shape, next(iter(train_dataset))[1].shape, next(iter(val_dataset))[0].shape, next(iter(val_dataset))[1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = tf.keras.layers.Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    if activation == True:\n",
    "        x = tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(blockInput, num_filters=16):\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.1)(blockInput)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    blockInput = tf.keras.layers.BatchNormalization()(blockInput)\n",
    "    x = convolution_block(x, num_filters, (3,3) )\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    x = tf.keras.layers.Add()([x, blockInput])\n",
    "    return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def ResUNet101V2(input_shape=(None, None, 3), dropout_rate=0.1, start_neurons = 16):\n",
    "    backbone = tf.keras.applications.ResNet101V2(weights=weights, include_top=False, input_shape=input_shape)\n",
    "    input_layer = backbone.input\n",
    "\n",
    "    conv4 = backbone.layers[122].output\n",
    "    conv4 = tf.keras.layers.LeakyReLU(alpha=0.1)(conv4)\n",
    "    pool4 = tf.keras.layers.MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = tf.keras.layers.Dropout(dropout_rate)(pool4)\n",
    "\n",
    "    convm = tf.keras.layers.Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n",
    "    convm = residual_block(convm,start_neurons * 32)\n",
    "    convm = residual_block(convm,start_neurons * 32)\n",
    "    convm = tf.keras.layers.LeakyReLU(alpha=0.1)(convm)\n",
    "\n",
    "    deconv4 = tf.keras.layers.Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = tf.keras.layers.concatenate([deconv4, conv4])\n",
    "    uconv4 = tf.keras.layers.Dropout(dropout_rate)(uconv4)\n",
    "\n",
    "    uconv4 = tf.keras.layers.Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 16)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 16)\n",
    "    uconv4 = tf.keras.layers.LeakyReLU(alpha=0.1)(uconv4)\n",
    "\n",
    "    deconv3 = tf.keras.layers.Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    conv3 = backbone.layers[76].output\n",
    "    uconv3 = tf.keras.layers.concatenate([deconv3, conv3])\n",
    "    uconv3 = tf.keras.layers.Dropout(dropout_rate)(uconv3)\n",
    "\n",
    "    uconv3 = tf.keras.layers.Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 8)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 8)\n",
    "    uconv3 = tf.keras.layers.LeakyReLU(alpha=0.1)(uconv3)\n",
    "\n",
    "    deconv2 = tf.keras.layers.Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    conv2 = backbone.layers[30].output\n",
    "    uconv2 = tf.keras.layers.concatenate([deconv2, conv2])\n",
    "\n",
    "    uconv2 = tf.keras.layers.Dropout(0.1)(uconv2)\n",
    "    uconv2 = tf.keras.layers.Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 4)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 4)\n",
    "    uconv2 = tf.keras.layers.LeakyReLU(alpha=0.1)(uconv2)\n",
    "\n",
    "    deconv1 = tf.keras.layers.Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    conv1 = backbone.layers[2].output\n",
    "    uconv1 = tf.keras.layers.concatenate([deconv1, conv1])\n",
    "\n",
    "    uconv1 = tf.keras.layers.Dropout(0.1)(uconv1)\n",
    "    uconv1 = tf.keras.layers.Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 2)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 2)\n",
    "    uconv1 = tf.keras.layers.LeakyReLU(alpha=0.1)(uconv1)\n",
    "\n",
    "    uconv0 = tf.keras.layers.Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)\n",
    "    uconv0 = tf.keras.layers.Dropout(0.1)(uconv0)\n",
    "    uconv0 = tf.keras.layers.Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n",
    "    uconv0 = residual_block(uconv0,start_neurons * 1)\n",
    "    uconv0 = residual_block(uconv0,start_neurons * 1)\n",
    "    uconv0 = tf.keras.layers.LeakyReLU(alpha=0.1)(uconv0)\n",
    "\n",
    "    uconv0 = tf.keras.layers.Dropout(dropout_rate/2)(uconv0)\n",
    "    output_layer = tf.keras.layers.Conv2D(3, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv0)\n",
    "\n",
    "    model = tf.keras.models.Model(input_layer, output_layer)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Optimize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Optimize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-35-9e9f29d390b3>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mOptimize\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'Optimize' is not defined"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "model = ResUNet101V2(input_shape=(img_size, img_size, 3),dropout_rate=dropout_rate)\n",
    "model.compile(loss='mae', optimizer=optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Callback"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath = 'models/baseline_model.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True\n",
    "    )\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = model.fit(train_dataset, epochs=EPOCHS, validation_data=val_dataset, callbacks=callbacks_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Result\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-6b1c271e6ba6>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhist\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"loss\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'train_loss'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhist\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"val_loss\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'val_loss'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtitle\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'loss_plot'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlegend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(hist.history[\"loss\"], label='train_loss')\n",
    "plt.plot(hist.history[\"val_loss\"], label='val_loss')\n",
    "plt.title('loss_plot')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Instance Segmentation\n",
    "\n",
    "### HR-Net_OCR_V2\n",
    "\n",
    "- Instance Segmentation에서 SOTA를 달성\n",
    "- ㅁㅈ얌쟝ㅈㅁ\n",
    "- ㅇㅁ쟈ㅓ얌ㅈ\n",
    "    - ㅁㅈ애ㅓㅁㅈ애\n",
    "    - 얌저얒ㅁ\n",
    "\n",
    "---\n",
    "* Requeriment\n",
    "    - Python >= 3.8\n",
    "    - conda >= 4.10.5\n",
    "    - torch >=1.8.1\n",
    "\n",
    "* 추가설치\n",
    "    - 암ㅈ아\n",
    "        - ㅇㅈ\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RuntimeError: CUDA error: an illegal memory access was\n",
    "encountered CUDA kernel errors might be asynchronously\n",
    "reported at some other API call,so the stacktrace below might be\n",
    "incorrect. For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
    "\n",
    "- 한글설명(번역)\n",
    "- 한글설명(왜 발생했는지)\n",
    "- 어떻게 해결하면 되는지\n",
    "\n",
    "### Solution\n",
    "### 해결방안\n",
    "- CUDA Drviver\n",
    "    - 현재 cuda-drvier version -> 10.1\n",
    "    - nvidia-driver -> 450.61.92\n",
    "    - cudnn ->\n",
    "- 조치방안\n",
    "    - mmsegmentation -> version : mmcv, mmdet\n",
    "    - CUda -> 11.1\n",
    "    - nvidia-driver -> 465.61.59\n",
    "    - cudnn ->\n",
    "모델 테스트"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'detect.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "from yolov4 import *\n",
    "\n",
    "!python detect.py --verioan"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-feb1f727",
   "language": "python",
   "display_name": "PyCharm (code)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}