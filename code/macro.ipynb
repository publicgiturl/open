{
 "cells": [
  {
   "source": [
    "### 이미지좌우반전"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import json, os, glob, re\n",
    "\n",
    "main_path = 'F:/20201120_S2-N1207M02566' # 파일위치\n",
    "jpg_list = glob.glob('{}/*.jpg'.format(main_path))\n",
    "\n",
    "for jpg_name in jpg_list:\n",
    "    row_jpg = jpg_name.split('\\\\')[-1]\n",
    "    number = re.findall('\\d{5}',row_jpg)\n",
    "    new_number= int(''.join(number)) + 100000\n",
    "    json_name = re.sub('.jpg', '.json', jpg_name)\n",
    "    new_jpg = re.sub('\\d{5}', str(new_number), row_jpg)   # 반전된 jpg이름\n",
    "    new_json = new_jpg.replace('.jpg', '.json')   # 반전된 json이름\n",
    "    re_path = jpg_name.split('\\\\')[0]+'_re'\n",
    "    \n",
    "    image1 = Image.open(jpg_name)   #이미지 불러오기\n",
    "    FlipImage = image1.transpose(Image.FLIP_LEFT_RIGHT)   #이미지 좌우대칭\n",
    "    \n",
    "    if not (os.path.isdir(re_path)):   # _re폴더 생성\n",
    "        os.makedirs(re_path)    \n",
    "    FlipImage.save(os.path.join(re_path, new_jpg))\n",
    "\n",
    "    try:\n",
    "        with open(json_name, encoding='utf-8') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            json_data['image']['filename'] = new_jpg\n",
    "            annotation = json_data['annotations']\n",
    "            \n",
    "            for i in range(len(annotation)):\n",
    "                annotation[i]['box'][0] = 1920-annotation[i]['box'][0]\n",
    "                annotation[i]['box'][2] = 1920-annotation[i]['box'][2]\n",
    "               \n",
    "        with open(os.path.join(re_path, new_json), 'w', encoding='utf-8') as json_change:\n",
    "            json.dump(json_data, json_change, indent=2, ensure_ascii = False)\n",
    "                            \n",
    "    finally:\n",
    "        json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "source": [
    "### 폴더 내 파일 개수 확인"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "\n",
    "class Getallfiles:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def getFiles(self,dir):\n",
    "        x = 0\n",
    "        for pack in os.walk(dir):\n",
    "            for f in pack[2]:\n",
    "                if f.endswith('.json'):\n",
    "                    x+=1\n",
    "        print(('Dir: %s, 전체 파일수 : %s')%(dir,str(x)))\n",
    "if __name__ =='__main__':\n",
    "    f= Getallfiles()\n",
    "    f.getFiles('Z:/학습데이터')"
   ]
  },
  {
   "source": [
    "### 파일크기 확인"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2283208826775\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def get_dir_size(path='.'):\n",
    "    total = 0\n",
    "    with os.scandir(path) as it:\n",
    "        for entry in it:\n",
    "            if entry.is_file():\n",
    "                total += entry.stat().st_size\n",
    "            elif entry.is_dir():\n",
    "                total += get_dir_size(entry.path)\n",
    "    return total\n",
    "print(get_dir_size('Z:/origin_image'))"
   ]
  },
  {
   "source": [
    "### 랜덤 파일 추출"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['S2-N2105M49075.json', 'S2-N2105M49097.json', 'S2-N2105M49077.json', 'S2-N2105M49092.json', 'S2-N2105M49085.json', 'S2-N2105M49100.json']\n"
     ]
    }
   ],
   "source": [
    "import random, os, shutil\n",
    "\n",
    "file_list = os.listdir('C:/Users/S2_SVR/Desktop/새 폴더/새 폴더 (3)/middle classification_02')\n",
    "\n",
    "sampleList = random.sample(file_list, 6)\n",
    "print(sampleList)\n",
    "for i in sampleList:\n",
    "    if i.endswith('.json'):\n",
    "        src = os.path.join('C:/Users/S2_SVR/Desktop/새 폴더/새 폴더 (3)/middle classification_02', i)\n",
    "        dst = os.path.join('C:/Users/S2_SVR/Desktop/새 폴더/새 폴더 (3)/새 폴더 (2)', i)\n",
    "        \n",
    "        shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil,os\n",
    "\n",
    "for path, dir, files in os.walk('C:/Users/S2_SVR/Desktop/새 폴더/새 폴더/20201028_S1-N0103M00001/.dat'):\n",
    "    for file_name in files:\n",
    "        for path, dir, files in os.walk('C:/Users/S2_SVR/Desktop/새 폴더/새 폴더/20201028_S1-N0103M00001'):\n",
    "            for file_name2 in files:\n",
    "                if file_name.split('.json')[0] == file_name2.split('.jpg')[0]:\n",
    "                    src = os.path.join(path, file_name2)\n",
    "                    dst = os.path.join('C:/Users/S2_SVR/Desktop/새 폴더',file_name2)\n",
    "                    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import os\n",
    "## 수정 파일 리스트 들고 오기\n",
    "aa = pd.read_excel('Z:/공사/0204_오프라인툴/0204.xlsx', header=None)\n",
    "filelist = list(aa[0])\n",
    "# filelist = os.listdir('Z:/origin_image/20201120')\n",
    "for file_name in filelist:\n",
    "# Connect DB\n",
    "    conn = pymysql.connect(host = '172.16.0.20', user = 'humanf', password = '1234', port = 3307, database = 'unidentify')\n",
    "    # conn = pymysql.connect(host = '172.16.0.5', user = 'uniden', password = 'uniden2020!@', port = 3306, database = 'indentify')  ### 5서버 DB접속\n",
    "    curs = conn.cursor()\n",
    "# Select Query\n",
    "    sql = \"UPDATE imagetbl SET Work_Yn = %s, Coordinates = %s WHERE Img_Name= %s;\"\n",
    "    curs.execute(sql, ('N','NULL', file_name))\n",
    "    # commit 필수\n",
    "    conn.commit()    \n",
    "    conn.close()\n",
    "    \n",
    "print('완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## "
   ]
  },
  {
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "# Connect DB\n",
    "conn = pymysql.connect(host = '192.168.0.222', user = 'media', password = '1234', port = 3306, database = 'media')\n",
    "curs = conn.cursor()\n",
    "\n",
    "# Select Query\n",
    "sql = \"select filename FROM s1 where class17 <> 0;\"\n",
    "\n",
    "curs.execute(sql)\n",
    "rows = curs.fetchall()\n",
    "\n",
    "conn.commit()    \n",
    "conn.close()\n",
    "\n",
    "daily_work = pd.DataFrame(rows, columns=['filename'])\n",
    "daily_work.to_excel('D:/새 폴더/class17.xlsx', header=True, encoding='utf-8')"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 폴더 복사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "file_list = ['[162-1][키포인트]20.12.07 47.비계 위에서 안전고리 미결착, 떨어짐']\n",
    "\n",
    "for i in file_list:\n",
    "    shutil.copytree('Z:/학습데이터/20201207/{}'.format(i),'F:/새 폴더/{}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F:/새 폴더/[162-1][키포인트]20.12.07 47.비계 위에서 안전고리 미결착, 떨어짐완료\n"
     ]
    }
   ],
   "source": [
    "import ftplib\n",
    "ftp = ftplib.FTP()\n",
    "ftp.connect(host = '172.16.0.5', port = 21)\n",
    "ftp.login(user='isafe', passwd='ftp2020')\n",
    "\n",
    "ftp.cwd(\"/work_complete\")\n",
    "for path, dir, files in os.walk('/work_complete'):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith('.jpg'):\n",
    "            fd = open(\"./\" + file_name,'wb')\n",
    "            ftp.retrbinary(\"RETR \"+ file_name, fd.write)\n",
    "            fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['20200611', '20200612', '20200613', '20200626', '20200709', '20200715', '20200728', '20200907', '20200910', '20200911', '20200912', '20200913', '20200916', '20200921', '20200924', '20200928', '20201005', '20201006', '20201007', '20201008', '20201009', '20201012', '20201013', '20201014', '20201015', '20201016', '20201019', '20201020', '20201021', '20201022', '20201023', '20201024', '20201026']\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "from openpyxl import Workbook\n",
    "\n",
    "\n",
    "main_path = 'F:/새 폴더/[162-1][키포인트]20.12.07 47.비계 위에서 안전고리 미결착, 떨어짐'\n",
    "dir_path = main_path.replace(main_path.split('/')[-1], '')\n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    " \n",
    "createFolder(dir_path+'카운트')\n",
    "\n",
    "for (path, dir, files) in os.walk(main_path):\n",
    "        error_json = {}\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.json'):\n",
    "                try:\n",
    "                    with open(os.path.join(path, file_name), encoding='utf-8') as json_file:\n",
    "                        error_json[os.path.join(path, file_name)] = ''\n",
    "                        json_data = json.load(json_file)\n",
    "                        annotation = json_data['annotations']\n",
    "                        com_count = 0\n",
    "\n",
    "                        if json_data['image']['copyrighter'] != '미디어그룹사람과숲(컨)':\n",
    "                            error_json[os.path.join(path, file_name)] = error_json[os.path.join(path, file_name)] + 'Copyrighter 에러'\n",
    "                            com_count += 1\n",
    "                        if len(json_data['image']['date']) != 8:\n",
    "                            if com_count != 0:\n",
    "                                error_json[os.path.join(path, file_name)] = error_json[os.path.join(path, file_name)] + ', ' + 'date 에러'\n",
    "                            else:\n",
    "                                error_json[os.path.join(path, file_name)] = error_json[os.path.join(path, file_name)] + 'date 에러'\n",
    "                                com_count += 1\n",
    "                        if json_data['image']['path'] == 'NULL':\n",
    "                            if com_count != 0:\n",
    "                                error_json[os.path.join(path, file_name)] = error_json[os.path.join(path, file_name)] + ', ' + 'path 에러'\n",
    "                            else:\n",
    "                                error_json[os.path.join(path, file_name)] = error_json[os.path.join(path, file_name)] + 'path 에러'\n",
    "                                com_count += 1\n",
    "                        if json_data['image']['filename'][0] != 'S' or json_data['image']['filename'][3] != 'O' and json_data['image']['filename'][3] != 'N':\n",
    "                            if com_count != 0:\n",
    "                                error_json[os.path.join(path, file_name)] = error_json[os.path.join(path, file_name)] + ', ' + 'filename 에러'\n",
    "                            else:\n",
    "                                error_json[os.path.join(path, file_name)] = error_json[os.path.join(path, file_name)] + 'filename 에러'\n",
    "                                com_count += 1\n",
    "                        if len(annotation) == 0:\n",
    "                            if com_count != 0:\n",
    "                                error_json[os.path.join(path, file_name)] = error_json[os.path.join(path, file_name)] + ', ' + 'annotation 누락'\n",
    "                            else:\n",
    "                                error_json[os.path.join(path, file_name)] = error_json[os.path.join(path, file_name)] + 'annotation 누락'\n",
    "                                com_count += 1\n",
    "                        else:\n",
    "                            for i in range(len(annotation)):\n",
    "                                if 'data ID' not in annotation[i] or 'middle classification' not in annotation[i] or 'flags' not in annotation[i] or 'class' not in annotation[i]:\n",
    "                                    if com_count != 0:\n",
    "                                        error_json[os.path.join(path, file_name)] = error_json[os.path.join(path, file_name)] + ', ' + 'annotation 에러'\n",
    "                                        break\n",
    "                                    else:\n",
    "                                        error_json[os.path.join(path, file_name)] = error_json[os.path.join(path, file_name)] + 'annotation 에러'\n",
    "                                        com_count += 1\n",
    "                                        break\n",
    "                                else:\n",
    "                                    if len(annotation[i]['data ID']) != 2:\n",
    "                                        if com_count != 0:\n",
    "                                            error_json[os.path.join(path, file_name)] = error_json[os.path.join(path, file_name)] + ', ' + 'annotation 에러'\n",
    "                                            break\n",
    "                                        else:\n",
    "                                            error_json[os.path.join(path, file_name)] = error_json[os.path.join(path, file_name)] + 'annotation 에러'\n",
    "                                            com_count += 1\n",
    "                                            break\n",
    "                                    if 'box' in annotation[i]:\n",
    "                                        if len(annotation[i]['box']) != 4:\n",
    "                                            if com_count != 0:\n",
    "                                                error_json[os.path.join(path, file_name)] = error_json[os.path.join(path, file_name)] + ', ' + 'annotation 에러'\n",
    "                                                break\n",
    "                                            else:\n",
    "                                                error_json[os.path.join(path, file_name)] = error_json[os.path.join(path, file_name)] + 'annotation 에러'\n",
    "                                                com_count += 1\n",
    "                                                break\n",
    "                                    elif 'polygon' in annotation[i]:\n",
    "                                        pass\n",
    "                                    elif 'keypoints' in annotation[i]:\n",
    "                                        pass\n",
    "                                    else:\n",
    "                                        if com_count != 0:\n",
    "                                            error_json[os.path.join(path, file_name)] = error_json[os.path.join(path, file_name)] + ', ' + 'annotation 에러'\n",
    "                                            break\n",
    "                                        else:\n",
    "                                            error_json[os.path.join(path, file_name)] = error_json[os.path.join(path, file_name)] + 'annotation 에러'\n",
    "                                            com_count += 1\n",
    "                                            break\n",
    "\n",
    "                                    if annotation[i]['flags'] != {}:\n",
    "                                        if len(annotation[i]['flags'].split(',')) < 2:\n",
    "                                            if com_count != 0:\n",
    "                                                error_json[os.path.join(path, file_name)] = error_json[os.path.join(path, file_name)] + ', ' + 'annotation 에러'\n",
    "                                                break\n",
    "                                            else:\n",
    "                                                error_json[os.path.join(path, file_name)] = error_json[os.path.join(path, file_name)] + 'annotation 에러'\n",
    "                                                com_count += 1\n",
    "                                                break\n",
    "                                    else:\n",
    "                                        if com_count != 0:\n",
    "                                            error_json[os.path.join(path, file_name)] = error_json[os.path.join(path, file_name)] + ', ' + 'annotation 에러'\n",
    "                                            break\n",
    "                                        else:\n",
    "                                            error_json[os.path.join(path, file_name)] = error_json[os.path.join(path, file_name)] + 'annotation 에러'\n",
    "                                            com_count += 1\n",
    "                                            break\n",
    "                except:\n",
    "                    error_json[os.path.join(path, file_name)] = 'json 형식 에러'\n",
    "                finally:\n",
    "                    json_file.close()\n",
    "\n",
    "        try:\n",
    "            e = open(os.path.join(path, 'annotation_error.csv'), mode='wt', encoding='utf-8-sig')\n",
    "            for key, value in error_json.items():\n",
    "                if value != '':\n",
    "                    e.write(str(key) + ' : ' + str(value) + '\\n')\n",
    "        finally:\n",
    "            e.close()\n",
    "\n",
    "\n",
    "remove_list = []\n",
    "\n",
    "# annotation누락 찾기\n",
    "with open(main_path+'/annotation_error.csv', 'r', encoding='utf-8') as f:\n",
    "    Ann_list = [i for i in f]\n",
    "\n",
    "for ann in Ann_list:\n",
    "    if ' annotation 누락' in ann:\n",
    "        remove_list.append(ann.split('\\\\')[-1].split(' :')[0])\n",
    "\n",
    "for i in remove_list:\n",
    "    os.remove('./'+i)\n",
    "\n",
    "write_xl = Workbook()\n",
    "write_ws = write_xl.active\n",
    "write_ws.append(['폴더명', 'JSON', 'class', 'class_count', 'box', 'polygon', 'point'])\n",
    "for (path, dir, files) in os.walk(main_path):\n",
    "    firstRow = True\n",
    "    for fileName in files:\n",
    "        if fileName.endswith('.json'):\n",
    "            firstJson = True\n",
    "            with open(os.path.join(path, fileName), encoding='utf-8') as json_file:\n",
    "                try:\n",
    "                    jsonData = json.load(json_file)\n",
    "                    annotations = jsonData['annotations']\n",
    "                    classType = []\n",
    "                    classTypeList = ['box', 'polygon', 'point']\n",
    "                    classCountDict = {}\n",
    "                    classTypeCountDict = {}\n",
    "\n",
    "                    for i in range(len(annotations)):\n",
    "                        classType.append(annotations[i]['class'])\n",
    "\n",
    "                    for key in classType:\n",
    "                        classCountDict[key] = classType.count(key)\n",
    "                        classTypeCountDict[key] = {'box': 0, 'polygon': 0, 'point': 0}\n",
    "\n",
    "                    for key in classCountDict:\n",
    "                        for i in range(len(annotations)):\n",
    "                            if annotations[i]['class'] == key:\n",
    "                                for item in classTypeList:\n",
    "                                    if item in annotations[i]:\n",
    "                                        classTypeCountDict[key][item] += 1\n",
    "\n",
    "                    for key in classCountDict:\n",
    "                        if firstRow and firstJson:\n",
    "                            write_ws.append([path, fileName, key, classCountDict[key],\n",
    "                                                classTypeCountDict[key][classTypeList[0]],\n",
    "                                                classTypeCountDict[key][classTypeList[1]],\n",
    "                                                classTypeCountDict[key][classTypeList[2]]])\n",
    "                            firstRow = False\n",
    "                            firstJson = False\n",
    "                        elif firstJson:\n",
    "                            write_ws.append([\"\", fileName, key, classCountDict[key],\n",
    "                                                classTypeCountDict[key][classTypeList[0]],\n",
    "                                                classTypeCountDict[key][classTypeList[1]],\n",
    "                                                classTypeCountDict[key][classTypeList[2]]])\n",
    "                            firstJson = False\n",
    "                        else:\n",
    "                            write_ws.append([\"\", \"\", key, classCountDict[key],\n",
    "                                                classTypeCountDict[key][classTypeList[0]],\n",
    "                                                classTypeCountDict[key][classTypeList[1]],\n",
    "                                                classTypeCountDict[key][classTypeList[2]]])\n",
    "                except Exception as ex:\n",
    "                    print(ex)\n",
    "                    pass\n",
    "\n",
    "write_xl.save(os.path.join(main_path, '../카운트/{}.xlsx'.format(main_path.split('/')[-1])))\n",
    "\n",
    "\n",
    "jpg  = []\n",
    "json = []\n",
    "NG = []\n",
    "no_jpg = []\n",
    "# json파일 이름명 추출\n",
    "### 주소만 변경 ###\n",
    "\n",
    "# os.chdir(main_path)\n",
    "for file in glob.glob(\"*.json\"):\n",
    "    json.append(file.split('.')[0])\n",
    "\n",
    "# jpg파일 이름명 추출    \n",
    "for file in glob.glob(\"*.jpg\"):\n",
    "    jpg.append(file.split('.')[0])\n",
    "\n",
    "# Json은 있지만 이미지가 없는 파일 걸러내기\n",
    "for v in jpg:\n",
    "    if v not in json:\n",
    "        NG.append(v+'.jpg')\n",
    "\n",
    "# 이미지가 없는데 Json이 있는 파일 걸러내기\n",
    "for v in json:\n",
    "    if v not in jpg:\n",
    "        no_jpg.append(v+'.json')\n",
    "\n",
    "# # 매치 되지않은 jpg리스트 저장\n",
    "with open('./omission_jpg.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(NG)\n",
    "\n",
    "# 매치 되지않은 json리스트 저장\n",
    "with open('./omission_json.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(no_jpg)\n",
    "\n",
    "# 매치되지 않은 jpg 삭제\n",
    "for i in NG:\n",
    "    os.remove(i)\n",
    "\n",
    "# 매치되지 않은 json 삭제\n",
    "for i in no_jpg:\n",
    "    os.remove(i)\n",
    "print(main_path + '완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "aa = os.listdir('Z:/origin_image')\n",
    "print(aa[:33])\n",
    "# for path, dir, files in os.walk('D:/Safety_DB_A/1.Training/Visualization'):\n",
    "#     for file_name in files:\n",
    "#         # if file_name in aa:\n",
    "#         src = os.path.join(path, file_name)\n",
    "#         dst = os.path.join('Z:/aa/새 폴더', file_name)\n",
    "#         shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "move_path = 'D:/Safety_DB_A/2.Validation/JPEGImages'\n",
    "aa = os.listdir(move_path)\n",
    "\n",
    "for path, dir, files in os.walk('Z:/origin_image'):\n",
    "    for file_name in files:\n",
    "        if file_name in aa:\n",
    "            src = os.path.join(path, file_name)\n",
    "            dst = os.path.join(move_path, file_name)\n",
    "            shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "move_path = 'D:/Safety_DB_A/3.Test/JPEGImages'\n",
    "aa = os.listdir(move_path)\n",
    "\n",
    "for path, dir, files in os.walk('Z:/origin_image'):\n",
    "    for file_name in files:\n",
    "        if file_name in aa:\n",
    "            src = os.path.join(path, file_name)\n",
    "            dst = os.path.join(move_path, file_name)\n",
    "            shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "완료\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "move_path = 'D:/Safety_DB_A/4.Sample'\n",
    "aa = os.listdir(move_path)\n",
    "\n",
    "for path, dir, files in os.walk('Z:/origin_image'):\n",
    "    for file_name in files:\n",
    "        if file_name in aa:\n",
    "            src = os.path.join(path, file_name)\n",
    "            dst = os.path.join(move_path, file_name)\n",
    "            shutil.copyfile(src, dst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "cc89b33f806db6ff0b6ad492e0b63dc98f065d4134c88bbc5cc2afaf80f26bf9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}