{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'4.4.0'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "from yolov4.tf import YOLOv4\r\n",
    "os.chdir('D:/aaa')\r\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The first argument to `Layer.call` must always be passed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-fad8791ecc1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0myolo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0myolo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0myolo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"yolov4.weights\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"yolo\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0myolo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"yolo\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    914\u001b[0m     \u001b[1;31m#   not to any other argument.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m     \u001b[1;31m# - setting the SavedModel saving spec.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 916\u001b[1;33m     \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_split_out_first_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    917\u001b[0m     \u001b[0minput_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\maskrcnn\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_split_out_first_arg\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2978\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m       raise ValueError(\n\u001b[1;32m-> 2980\u001b[1;33m           'The first argument to `Layer.call` must always be passed.')\n\u001b[0m\u001b[0;32m   2981\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The first argument to `Layer.call` must always be passed."
     ]
    }
   ],
   "source": [
    "yolo = YOLOv4()\r\n",
    "\r\n",
    "yolo.config.parse_names(\"coco.names\")\r\n",
    "yolo.config.parse_cfg(\"yolov4.cfg\")\r\n",
    "\r\n",
    "yolo.make_model()\r\n",
    "yolo.model(gpu=1)\r\n",
    "yolo.load_weights(\"yolov4.weights\", weights_type=\"yolo\")\r\n",
    "yolo.summary(summary_type=\"yolo\", gpu=1)\r\n",
    "yolo.summary()\r\n",
    "\r\n",
    "yolo.inference(media_path=\"dog.jpg\")\r\n",
    "\r\n",
    "# yolo.inference(media_path=\"test2.mp4\", is_image=False)\r\n",
    "\r\n",
    "yolo.inference(\r\n",
    "    \"/dev/video0\",\r\n",
    "    is_image=False,\r\n",
    "    cv_apiPreference=cv2.CAP_V4L2,\r\n",
    "    cv_frame_size=(418, 418),\r\n",
    "    cv_fourcc=\"YUYV\",\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_model',\n '_predict',\n 'compile',\n 'config',\n 'draw_bboxes',\n 'fit',\n 'fit_to_original',\n 'get_yolo_detections',\n 'inference',\n 'load_weights',\n 'make_model',\n 'model',\n 'predict',\n 'resize_image',\n 'save_weights',\n 'summary']"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(yolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\maskrcnn\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\ProgramData\\Anaconda3\\envs\\maskrcnn\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\ProgramData\\Anaconda3\\envs\\maskrcnn\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'core'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-50142049785c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphysical_devices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mabsl\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myolov4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfilter_boxes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtag_constants\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'core'"
     ]
    }
   ],
   "source": [
    "\r\n",
    "import tensorflow as tf\r\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\r\n",
    "\r\n",
    "if len(physical_devices) > 0:\r\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\r\n",
    "from absl import app\r\n",
    "import core.utils as utils\r\n",
    "from core.yolov4 import filter_boxes\r\n",
    "from tensorflow.python.saved_model import tag_constants\r\n",
    "from PIL import Image\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "\r\n",
    "framework = 'tf' #'tflite' # tf, tflite, trt\r\n",
    "# weights = './checkpoints/yolov4-416' #'./checkpoints/yolov4-416.tflite'\r\n",
    "size = 416 # resize images to\r\n",
    "tiny = False  # 'yolo or yolo-tiny'\r\n",
    "model = 'yolov4' # yolov3 or yolov4\r\n",
    "iou = 0.45 # iou threshold\r\n",
    "score = 0.25 # score threshold\r\n",
    "\r\n",
    "def main(_argv):\r\n",
    "\r\n",
    "    input_size = 416\r\n",
    "\r\n",
    "    vid = cv2.VideoCapture(0)\r\n",
    "\r\n",
    "    if framework == 'tflite':\r\n",
    "        interpreter = tf.lite.Interpreter(model_path=weights)\r\n",
    "        interpreter.allocate_tensors()\r\n",
    "        input_details = interpreter.get_input_details()\r\n",
    "        output_details = interpreter.get_output_details()\r\n",
    "        print(input_details)\r\n",
    "        print(output_details)\r\n",
    "    else:\r\n",
    "        saved_model_loaded = tf.saved_model.load(weights, tags=[tag_constants.SERVING])\r\n",
    "        infer = saved_model_loaded.signatures['serving_default']\r\n",
    "    \r\n",
    "    frame_id = 0\r\n",
    "    while True:\r\n",
    "        return_value, frame = vid.read()\r\n",
    "        if return_value:\r\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\r\n",
    "            image = Image.fromarray(frame)\r\n",
    "        else:\r\n",
    "            if frame_id == vid.get(cv2.CAP_PROP_FRAME_COUNT):\r\n",
    "                print(\"Video processing complete\")\r\n",
    "                break\r\n",
    "            raise ValueError(\"No image! Try with another video format\")\r\n",
    "        \r\n",
    "        frame_size = frame.shape[:2]\r\n",
    "        image_data = cv2.resize(frame, (input_size, input_size))\r\n",
    "        image_data = image_data / 255.\r\n",
    "        image_data = image_data[np.newaxis, ...].astype(np.float32)\r\n",
    "        prev_time = time.time()\r\n",
    "\r\n",
    "\r\n",
    "        if framework == 'tflite':\r\n",
    "            interpreter.set_tensor(input_details[0]['index'], image_data)\r\n",
    "            interpreter.invoke()\r\n",
    "            pred = [interpreter.get_tensor(output_details[i]['index']) for i in range(len(output_details))]\r\n",
    " \r\n",
    "            boxes, pred_conf = filter_boxes(pred[0], pred[1], score_threshold=0.25,\r\n",
    "                                            input_shape=tf.constant([input_size, input_size]))\r\n",
    "        else:\r\n",
    "            batch_data = tf.constant(image_data)\r\n",
    "            pred_bbox = infer(batch_data)\r\n",
    "            for key, value in pred_bbox.items():\r\n",
    "                boxes = value[:, :, 0:4]\r\n",
    "                pred_conf = value[:, :, 4:]\r\n",
    "\r\n",
    "        boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\r\n",
    "            boxes=tf.reshape(boxes, (tf.shape(boxes)[0], -1, 1, 4)),\r\n",
    "            scores=tf.reshape(\r\n",
    "                pred_conf, (tf.shape(pred_conf)[0], -1, tf.shape(pred_conf)[-1])),\r\n",
    "            max_output_size_per_class=50,\r\n",
    "            max_total_size=50,\r\n",
    "            iou_threshold=iou,\r\n",
    "            score_threshold=score\r\n",
    "        )\r\n",
    "        pred_bbox = [boxes.numpy(), scores.numpy(), classes.numpy(), valid_detections.numpy()]\r\n",
    "        image = utils.draw_bbox(frame, pred_bbox)\r\n",
    "        curr_time = time.time()\r\n",
    "        exec_time = curr_time - prev_time\r\n",
    "        result = np.asarray(image)\r\n",
    "        info = \"time: %.2f ms\" %(1000*exec_time)\r\n",
    "        print(info)\r\n",
    "\r\n",
    "        result = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\r\n",
    "\r\n",
    "        cv2.namedWindow(\"result\", cv2.WINDOW_AUTOSIZE)\r\n",
    "        cv2.imshow(\"result\", result)\r\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): break\r\n",
    "\r\n",
    "        frame_id += 1\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    try:\r\n",
    "        app.run(main)\r\n",
    "    except SystemExit:\r\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'net'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-00771c195006>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0myolo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m640\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m480\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0myolo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0myolo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"yolov4.weights\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"yolo\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# yolo.load_weights(\"yolov4-tiny.weights\", weights_type=\"yolo\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\maskrcnn\\lib\\site-packages\\yolov4\\tf\\__init__.py\u001b[0m in \u001b[0;36mmake_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0m_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mYOLOv4Model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\maskrcnn\\lib\\site-packages\\yolov4\\common\\config.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, metalayer)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetalayer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_metalayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmetalayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'net'"
     ]
    }
   ],
   "source": [
    "yolo = YOLOv4()\r\n",
    "# yolo = YOLOv4(tiny=True)\r\n",
    "\r\n",
    "yolo.classes = \"coco.names\"\r\n",
    "yolo.input_size = (640, 480)\r\n",
    "\r\n",
    "yolo.make_model()\r\n",
    "yolo.load_weights(\"yolov4.weights\", weights_type=\"yolo\")\r\n",
    "# yolo.load_weights(\"yolov4-tiny.weights\", weights_type=\"yolo\")\r\n",
    "\r\n",
    "yolo.inference(media_path=\"kite.jpg\")\r\n",
    "\r\n",
    "yolo.inference(media_path=\"road.mp4\", is_image=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('maskrcnn': conda)",
   "name": "python3710jvsc74a57bd0c2bf580a363e2949648b0aa348a41058d2b6eb02d1c845c054f13615076cff3a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "c2bf580a363e2949648b0aa348a41058d2b6eb02d1c845c054f13615076cff3a"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}